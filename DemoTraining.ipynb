{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeXGLNC4alVU",
        "outputId": "2fc5021e-2213-475c-d8ac-5861b3729fc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.10/site-packages (4.1.1.post0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: wrds in /usr/local/lib/python3.10/site-packages (3.1.6)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/site-packages (from wrds) (2.9.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from wrds) (1.26.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from wrds) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.10/site-packages (from wrds) (1.4.50)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from wrds) (2.1.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/site-packages (from sqlalchemy<2->wrds) (3.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas->wrds) (2023.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->wrds) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->wrds) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pyportfolioopt in /usr/local/lib/python3.10/site-packages (1.5.5)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/site-packages (from pyportfolioopt) (2.1.3)\n",
            "Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.10/site-packages (from pyportfolioopt) (1.11.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.10/site-packages (from pyportfolioopt) (1.26.2)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /usr/local/lib/python3.10/site-packages (from pyportfolioopt) (1.4.1)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.6.0)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (2.11.1)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (2.0.12)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.6.3)\n",
            "Requirement already satisfied: scs>=3.0 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (3.2.4.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=0.19->pyportfolioopt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=0.19->pyportfolioopt) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas>=0.19->pyportfolioopt) (2023.3)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/site-packages (from osqp>=0.6.2->cvxpy<2.0.0,>=1.1.19->pyportfolioopt) (0.1.7.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.19->pyportfolioopt) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m‚ú®üç∞‚ú® Everything looks OK!\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-q9n_f58a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-q9n_f58a\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 1410c340ded1a2fb49b16caf972e55b3d1d6efbb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-3cwg28r4/elegantrl_bf60e347218b41999f8664b4549ef51c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-3cwg28r4/elegantrl_bf60e347218b41999f8664b4549ef51c\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit b4b9d662b9f9cb7cc368ac2b1036b5119eb20be4\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyportfolioopt<2,>=1 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (1.5.5)\n",
            "Requirement already satisfied: stockstats<0.6,>=0.5 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (0.5.4)\n",
            "Requirement already satisfied: yfinance<0.3,>=0.2 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (0.2.32)\n",
            "Requirement already satisfied: alpaca-trade-api<4,>=3 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (3.0.2)\n",
            "Requirement already satisfied: jqdatasdk<2,>=1 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (1.9.2)\n",
            "Requirement already satisfied: ccxt<4,>=3 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (3.1.60)\n",
            "Requirement already satisfied: exchange-calendars<5,>=4 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (4.5)\n",
            "Requirement already satisfied: pyfolio<0.10,>=0.9 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (0.9.2)\n",
            "Requirement already satisfied: scikit-learn<2,>=1 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (1.3.2)\n",
            "Requirement already satisfied: ray[default,tune]<3,>=2 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (2.8.1)\n",
            "Requirement already satisfied: wrds<4,>=3 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (3.1.6)\n",
            "Requirement already satisfied: stable-baselines3[extra]>=2.0.0a5 in /usr/local/lib/python3.10/site-packages (from finrl==0.3.6) (2.2.1)\n",
            "Requirement already satisfied: msgpack==1.0.3 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.0.3)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.0)\n",
            "Requirement already satisfied: websockets<11,>=9.0 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (10.4)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.7.0)\n",
            "Requirement already satisfied: aiohttp==3.8.2 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.31.0)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.3)\n",
            "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (6.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.2)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (1.26.15)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/site-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (2.1.1)\n",
            "Requirement already satisfied: multidict<6.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (5.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (23.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp==3.8.2->alpaca-trade-api<4,>=3->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6) (23.2)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (2022.12.7)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (40.0.1)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (65.6.3)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (3.1.1)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2023.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2.8.2)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.10/site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.3.1)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.10/site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (2.2.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/site-packages (from exchange-calendars<5,>=4->finrl==0.3.6) (0.12.0)\n",
            "Requirement already satisfied: thriftpy2>=0.3.9 in /usr/local/lib/python3.10/site-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (0.4.17)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.10/site-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.16.0)\n",
            "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.10/site-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.4.50)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (1.11.4)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.10/site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (8.18.1)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.10/site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.5.5)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.10/site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (0.13.0)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.10/site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (2023.3.post1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (3.8.2)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /usr/local/lib/python3.10/site-packages (from pyportfolioopt<2,>=1->finrl==0.3.6) (1.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (3.13.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (8.1.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (4.23.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (4.20.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (14.0.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (2023.12.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.5.5)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.3.14)\n",
            "Requirement already satisfied: virtualenv<20.21.1,>=20.0.24 in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (20.21.0)\n",
            "Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.1.1)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.19.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (6.4.0)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.10.13)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (1.59.3)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.10/site-packages (from ray[default,tune]<3,>=2->finrl==0.3.6) (0.11.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn<2,>=1->finrl==0.3.6) (3.2.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/site-packages (from scikit-learn<2,>=1->finrl==0.3.6) (1.3.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.0)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.29.1)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.1)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.6.1 in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.6.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (10.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.65.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (13.7.0)\n",
            "Requirement already satisfied: shimmy[atari]~=1.3.0 in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.9.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.8.1.78)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.15.1)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/site-packages (from wrds<4,>=3->finrl==0.3.6) (2.9.9)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (1.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (2.3.10)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.9.3)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (1.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (3.17.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (0.0.11)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.12.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/site-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (0.26.2)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.10/site-packages (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.6) (4.4.0)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.6.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.6) (2.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/site-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (1.15.1)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.6.3)\n",
            "Requirement already satisfied: scs>=3.0 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (3.2.4.post1)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (2.0.12)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (2.11.1)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.10/site-packages (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.6.0)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.10/site-packages (from empyrical>=0.5.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.10.0)\n",
            "Requirement already satisfied: nvidia-ml-py>=11.450.129 in /usr/local/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (12.535.133)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (1.20.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.8.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/site-packages (from html5lib>=1.1->yfinance<0.3,>=0.2->finrl==0.3.6) (0.5.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.1.6)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.6.3)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.0.41)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.17.2)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.14.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (1.4.5)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.46.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.12.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.4)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/site-packages (from shimmy[atari]~=1.3.0->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.8.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/site-packages (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.6) (3.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.0.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.24.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.7.2)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.10/site-packages (from thriftpy2>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6) (3.11)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (12.1.105)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.12)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.18.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (12.1.105)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (12.3.101)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.10/site-packages (from virtualenv<20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6) (3.11.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/site-packages (from virtualenv<20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6) (0.3.7)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/site-packages (from gym->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (0.0.8)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/site-packages (from gym->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (4.1.1.post0)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/site-packages (from gym->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6) (2.3.5)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/site-packages (from jsonschema->ray[default,tune]<3,>=2->finrl==0.3.6) (0.31.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/site-packages (from jsonschema->ray[default,tune]<3,>=2->finrl==0.3.6) (2023.11.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/site-packages (from jsonschema->ray[default,tune]<3,>=2->finrl==0.3.6) (0.13.2)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/site-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/site-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (6.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]<3,>=2->finrl==0.3.6) (0.2.12)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (2.21)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6) (1.61.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.8.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.1.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/site-packages (from osqp>=0.6.2->cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6) (0.1.7.post0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (2.1.3)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/site-packages (from stack-data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=1.13->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (3.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "## install required packages\n",
        "!pip install swig\n",
        "!pip install wrds\n",
        "!pip install pyportfolioopt\n",
        "## install finrl library\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import itertools\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import gymnasium as gym\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
        "from stable_baselines3.common.logger import configure\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "sys.path.append(\"../FinRL\")\n",
        "\n",
        "from finrl import config, config_tickers\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent, TensorboardCallback\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR, INDICATORS, TRAIN_START_DATE, TRAIN_END_DATE,\n",
        "    TEST_START_DATE, TEST_END_DATE, TRADE_START_DATE, TRADE_END_DATE\n",
        ")\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "from gymnasium.utils import seeding\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ],
      "metadata": {
        "id": "961nWu2ZbaI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed65800-3fa7-401a-948f-0ec480ce171a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StockEnvMine(gym.Env):\n",
        "\n",
        "    metadata = {\"render.modes\": [\"human\"]}\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            df,\n",
        "            hmax,\n",
        "            initial_amount,\n",
        "            num_stock_shares,\n",
        "            buy_cost_pct,\n",
        "            sell_cost_pct,\n",
        "            state_space,\n",
        "            stock_dim,\n",
        "            tech_indicator_list,\n",
        "            reward_scaling,\n",
        "            action_space,\n",
        "            initial=True,\n",
        "            last_state=[],\n",
        "            turbulence_th=None,\n",
        "            plots=False,\n",
        "            risk_indicator = 'turbulence',\n",
        "            mode=\"\",\n",
        "            model_name=\"\",\n",
        "            iteration=\"\",\n",
        "    ):\n",
        "        self.df = df\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day, :]\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.num_stock_shares = num_stock_shares\n",
        "        self.buy_cost_pct = buy_cost_pct\n",
        "        self.sell_cost_pct = sell_cost_pct\n",
        "        self.state_space = state_space\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(state_space,))\n",
        "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(action_space,))\n",
        "        self.stock_dim = stock_dim\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.turbulence_th = turbulence_th\n",
        "        self.plots = plots\n",
        "        self.initial = initial\n",
        "        self.terminal = False\n",
        "        self.risk_indicator = risk_indicator\n",
        "        self.state = self.initilize_state()\n",
        "        self.log_every = 1\n",
        "        self.mode = mode\n",
        "        self.model_name = model_name\n",
        "        self.iteration = iteration\n",
        "\n",
        "        self.reward = 0\n",
        "        self.turbulence= 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.episode = 0\n",
        "        self.asset_memory = [self.initial_amount + np.sum(np.array(self.num_stock_shares) * np.array(self.state[1:self.stock_dim+1]))]\n",
        "        self.reward_memory = []\n",
        "        self.actions_memory = []\n",
        "        self.state_memory = ([])\n",
        "        self.date_memory = [self.getDate()]\n",
        "        self.seed()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def initilize_state(self):\n",
        "        if self.initial:\n",
        "            state = ([self.initial_amount] + self.data.close.values.tolist() + self.num_stock_shares + sum((self.data[tech].values.tolist() for tech in self.tech_indicator_list), []))\n",
        "        else:\n",
        "            state = ([self.last_state[0]] + self.data.close.values.tolist() + self.last_state[(self.stock_dim + 1) : (self.stock_dim * 2 + 1)] + sum((self.data[tech].values.tolist() for tech in self.tech_indicator_list),[]))\n",
        "        return state\n",
        "\n",
        "    def getDate(self):\n",
        "        return self.data.date.unique()[0]\n",
        "\n",
        "    def render(self, mode=\"human\", close=False):\n",
        "        return self.state\n",
        "\n",
        "    def reset(self, *, seed=None, options=None,):\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day, :]\n",
        "        self.state = self.initilize_state()\n",
        "        self.asset_memory = [self.initial_amount + np.sum(np.array(self.num_stock_shares) * np.array(self.state[1:self.stock_dim+1]))]\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.terminal = False\n",
        "        self.reward_memory = []\n",
        "        self.actions_memory = []\n",
        "        self.date_memory = [self.getDate()]\n",
        "        self.episode += 1\n",
        "        return self.state, {}\n",
        "\n",
        "    def update(self):\n",
        "        state = ([self.state[0]] + self.data.close.values.tolist() + list(self.state[(self.stock_dim + 1) : (2 * self.stock_dim + 1)]) + sum((self.data[tech].values.tolist() for tech in self.tech_indicator_list), []))\n",
        "        return state\n",
        "\n",
        "    def buy(self, index, action):\n",
        "        if self.state[index + 2 * self.stock_dim + 1] != True:\n",
        "            nums_can_buy = self.state[0] // (self.state[index + 1] * (1 + self.buy_cost_pct[index]))\n",
        "            nums = min(nums_can_buy, action)\n",
        "            amount = self.state[index + 1] * (1 + self.buy_cost_pct[index]) * nums\n",
        "            self.state[0] -= amount\n",
        "            self.state[index + self.stock_dim + 1] += nums\n",
        "            self.cost += amount\n",
        "            self.trades += 1\n",
        "        else:\n",
        "            nums = 0\n",
        "        return nums\n",
        "\n",
        "    def Action_Buy(self, index, action):\n",
        "        if self.turbulence_th is None:\n",
        "            nums = self.buy(index, action)\n",
        "        else:\n",
        "            if self.turbulence < self.turbulence_th:\n",
        "                nums = self.buy(index, action)\n",
        "            else:\n",
        "                nums = 0\n",
        "        return nums\n",
        "\n",
        "    def sell(self, index, action):\n",
        "        if self.state[index + 2 * self.stock_dim + 1] != True:\n",
        "            if self.state[index + self.stock_dim + 1] > 0:\n",
        "                nums_can_sell = self.state[index + self.stock_dim + 1]\n",
        "                nums = min(nums_can_sell, abs(action))\n",
        "                amount = self.state[index + 1] * (1 - self.sell_cost_pct[index]) * nums\n",
        "                self.state[0] += amount\n",
        "                self.state[index + self.stock_dim + 1] -= nums\n",
        "                self.cost += self.state[index + 1] * self.sell_cost_pct[index] * nums\n",
        "                self.trades += 1\n",
        "            else:\n",
        "                nums = 0\n",
        "        else:\n",
        "            nums = 0\n",
        "        return nums\n",
        "\n",
        "    def Action_Sell(self, index, action):\n",
        "        if self.turbulence_th is None:\n",
        "            nums = self.sell(index, action)\n",
        "        else:\n",
        "            if self.turbulence < self.turbulence_th:\n",
        "                nums = self.sell(index, action)\n",
        "            else:\n",
        "                if self.state[index + 1] > 0:\n",
        "                    if self.state[index + self.stock_dim + 1] > 0:\n",
        "                        nums = self.state[index + self.stock_dim + 1]\n",
        "                        amount = self.state[index + 1] * (1 - self.sell_cost_pct[index]) * nums\n",
        "                        self.state[0] += amount\n",
        "                        self.state[index + self.stock_dim + 1] = 0\n",
        "                        self.cost += self.state[index + 1] * self.sell_cost_pct[index] * nums\n",
        "                        self.trades += 1\n",
        "                    else:\n",
        "                        nums = 0\n",
        "                else:\n",
        "                    nums = 0\n",
        "        return nums\n",
        "\n",
        "    def makePlot(self):\n",
        "        plt.plot(self.asset_memory, \"r\")\n",
        "        plt.savefig(f\"results/account_value_trade_{self.episode}.png\")\n",
        "        plt.close()\n",
        "\n",
        "    def getDummyEnv(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs\n",
        "\n",
        "    def saveAssetMemory(self):\n",
        "        date_list = self.date_memory\n",
        "        asset_list = self.asset_memory\n",
        "        df_account_value = pd.DataFrame({\"date\": date_list, \"account_value\": asset_list})\n",
        "        return df_account_value\n",
        "\n",
        "    def saveActionMemory(self):\n",
        "        date_list = self.date_memory[:-1]\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = [\"date\"]\n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        return df_actions\n",
        "\n",
        "    def step(self, actions):\n",
        "        self.terminal = (self.day >= len(self.df.index.unique()) - 1 or self.state[0] <= 0)\n",
        "        if self.terminal:\n",
        "            if self.plots:\n",
        "                self.makePlot()\n",
        "            end_asset = self.state[0] + sum(np.array(self.state[1 : (self.stock_dim + 1)]) * np.array(self.state[(self.stock_dim + 1) : (2 * self.stock_dim + 1)]))\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            total_reward = self.state[0] + sum(np.array(self.state[1 : (self.stock_dim + 1)]) * np.array(self.state[(self.stock_dim + 1) : (2 * self.stock_dim + 1)])) - self.initial_amount\n",
        "            df_total_value.columns = [\"account_value\"]\n",
        "            df_total_value[\"date\"] = self.date_memory\n",
        "            df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(1)\n",
        "            if df_total_value[\"daily_return\"].std() != 0:\n",
        "                sharpe = (252 ** 0.5) * df_total_value[\"daily_return\"].mean() / df_total_value[\"daily_return\"].std()\n",
        "            df_rewards = pd.DataFrame(self.reward_memory)\n",
        "            df_rewards.columns = [\"account_rewards\"]\n",
        "            df_rewards[\"date\"] = self.date_memory[:-1]\n",
        "            if self.episode % self.log_every == 0:\n",
        "                print(f\"day: {self.day}, episode: {self.episode}\")\n",
        "                print(f\"begin_total_asset: {self.asset_memory[0]:0.2f}\")\n",
        "                print(f\"end_total_asset: {end_asset:0.2f}\")\n",
        "                print(f\"total_reward: {total_reward:0.2f}\")\n",
        "                print(f\"total_cost: {self.cost:0.2f}\")\n",
        "                print(f\"total_trades: {self.trades}\")\n",
        "                if df_total_value[\"daily_return\"].std() != 0:\n",
        "                    print(f\"Sharpe: {sharpe:0.3f}\")\n",
        "                print(\"=================================\")\n",
        "\n",
        "            if (self.model_name != \"\") and (self.mode != \"\"):\n",
        "                df_total_value.to_csv(\"results/account_value_{}_{}_{}.csv\".format(self.mode, self.model_name, self.iteration),index=False,)\n",
        "                df_rewards.to_csv(\"results/account_rewards_{}_{}_{}.csv\".format(self.mode, self.model_name, self.iteration), index=False,)\n",
        "                plt.plot(self.asset_memory, \"r\")\n",
        "                plt.savefig(\"results/account_value_{}_{}_{}.png\".format(self.mode, self.model_name, self.iteration))\n",
        "                plt.close()\n",
        "            return self.state, self.reward, self.terminal, False, {}\n",
        "        else:\n",
        "            actions = (actions * self.hmax).astype(int)\n",
        "            if self.turbulence_th is not None:\n",
        "                if self.turbulence >= self.turbulence_th:\n",
        "                    actions = np.array([-self.hmax] * self.stock_dim)\n",
        "            begin_asset = self.state[0] + sum(np.array(self.state[1 : (self.stock_dim + 1)]) * np.array(self.state[(self.stock_dim + 1) : (2 * self.stock_dim + 1)]))\n",
        "            sort_action = np.argsort(actions)\n",
        "            sell_index = sort_action[:np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = sort_action[::-1][:np.where(actions > 0)[0].shape[0]]\n",
        "            for index in sell_index:\n",
        "                actions[index] = self.Action_Sell(index, actions[index]) * (-1)\n",
        "            for index in buy_index:\n",
        "                actions[index] = self.Action_Buy(index, actions[index])\n",
        "            self.actions_memory.append(actions)\n",
        "\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day, :]\n",
        "            if self.turbulence_th is not None:\n",
        "                self.turbulence = self.data[self.risk_indicator].values[0]\n",
        "            self.state = self.update()\n",
        "            end_total_asset = self.state[0] + sum(np.array(self.state[1 : (self.stock_dim + 1)]) * np.array(self.state[(self.stock_dim + 1) : (2 * self.stock_dim + 1)]))\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            self.date_memory.append(self.getDate())\n",
        "            # Reward Function\n",
        "            self.reward = end_total_asset - begin_asset\n",
        "            self.reward_memory.append(self.reward)\n",
        "            self.reward = self.reward * self.reward_scaling\n",
        "            self.state_memory.append(self.state)\n",
        "            return self.state, self.reward, self.terminal, False, {}\n"
      ],
      "metadata": {
        "id": "8UZJLGxEbiyx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, env, model_name, iter_num=0, policy=\"MlpPolicy\", policy_kwargs=None, model_kwargs=None, verbose=1, seed=None, tensorboard_log=None):\n",
        "        self.models = {\"a2c\": A2C, \"ddpg\": DDPG, \"ppo\": PPO, \"a2c_ensemble\": A2C, \"ddpg_ensemble\": DDPG, \"ppo_ensemble\": PPO}\n",
        "        model_kwargs_dict = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in [\"a2c\", \"ddpg\", \"ppo\"]}\n",
        "        model_kwargs_dict_ensemble = {x + \"_ensemble\": config.__dict__[f\"{x.upper()}_PARAMS\"] for x in [\"a2c\", \"ddpg\", \"ppo\"]}\n",
        "        model_kwargs_dict.update(model_kwargs_dict_ensemble)\n",
        "        self.model_name = model_name\n",
        "        self.iter_num = iter_num\n",
        "        if model_kwargs is None:\n",
        "            self.model_kwargs = model_kwargs_dict[model_name]\n",
        "        else:\n",
        "            self.model_kwargs = model_kwargs\n",
        "        self.model = self.models[model_name](policy=policy, env=env, verbose=verbose, seed=seed, tensorboard_log=tensorboard_log, policy_kwargs=policy_kwargs, **self.model_kwargs)\n",
        "\n",
        "    def train(self, total_timesteps=5000):\n",
        "        model = self.model.learn(total_timesteps=total_timesteps, tb_log_name=\"{}_{}\".format(self.model_name, self.iter_num), callback=TensorboardCallback())\n",
        "        model.save(f\"{config.TRAINED_MODEL_DIR}/{self.model_name.upper()}_{total_timesteps // 1000}k_{self.iter_num}\")\n",
        "        return model\n",
        "\n",
        "    def predict(self, env_new, deterministic=True):\n",
        "        env, obs = env_new.getDummyEnv()\n",
        "        account_memory = None\n",
        "        actions_memory = None\n",
        "\n",
        "        env.reset()\n",
        "        max_step = len(env_new.df.index.unique()) - 1\n",
        "\n",
        "        for i in range(max_step + 1):\n",
        "            action, states = self.model.predict(obs, deterministic=deterministic)\n",
        "            obs, rewards, dones, info = env.step(action)\n",
        "            if i == max_step - 1:\n",
        "                account_memory = env.env_method(method_name=\"saveAssetMemory\")\n",
        "                actions_memory = env.env_method(method_name=\"saveActionMemory\")\n",
        "            if dones[0]:\n",
        "                print(\"Finished\")\n",
        "                break\n",
        "        return account_memory[0], actions_memory[0]\n",
        "\n",
        "    def predictLoadFromFile(self, env_new, cwd, deterministic=True):\n",
        "        try:\n",
        "            model = self.model.load(cwd)\n",
        "            print(\"Model loaded from file\")\n",
        "        except BaseException as error:\n",
        "            raise ValueError(f\"Failed to load agent. Error: {str(error)}\") from error\n",
        "\n",
        "        state = env_new.reset()\n",
        "        episode_returns = []\n",
        "        episode_total_assets = [env_new.initial_amount]\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = model.predict(state, deterministic=deterministic)[0]\n",
        "            state, reward, done, _ = env_new.step(action)\n",
        "            episode_total_assets.append(state[0])\n",
        "            episode_return = state[0] / env_new.initial_amount\n",
        "            episode_returns.append(episode_return)\n",
        "        print(f\"Finish Trading. The final amount of money is: {episode_total_assets[-1]}. The total return is: {episode_returns[-1]}\")\n",
        "        return episode_total_assets, episode_returns"
      ],
      "metadata": {
        "id": "6-Nb_xNNb_gX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnsembleAgent:\n",
        "    def __init__(self, df, train_period, val_period, rebalance_window, validation_window, env_args):\n",
        "        self.df = df\n",
        "        self.train_period = train_period\n",
        "        self.val_period = val_period\n",
        "        self.rebalance_window = rebalance_window\n",
        "        self.validation_window = validation_window\n",
        "        self.env_args = env_args\n",
        "        self.unique_trade_date = df[(df.date > val_period[0]) & (df.date <= val_period[1])].date.unique()\n",
        "        self.train_env = None\n",
        "\n",
        "    def val(self, model, val_data, val_env, val_obs):\n",
        "        for _ in range(len(val_data.index.unique())):\n",
        "            action, _states = model.predict(val_obs)\n",
        "            val_obs, rewards, dones, info = val_env.step(action)\n",
        "\n",
        "    def predict(self, model, name, last_state, iter, tur_th, initial):\n",
        "        trade_data = data_split(self.df, start=self.unique_trade_date[iter - self.rebalance_window], end=self.unique_trade_date[iter],)\n",
        "        trade_env = DummyVecEnv([lambda: StockEnvMine(df=trade_data, turbulence_th=tur_th, iteration=iter, mode=\"trade\", model_name=name, last_state=last_state, initial=initial, **self.env_args)])\n",
        "        trade_obs = trade_env.reset()\n",
        "        for i in range(len(trade_data.index.unique())):\n",
        "            action, _ = model.predict(trade_obs)\n",
        "            trade_obs, _, _, _ = trade_env.step(action)\n",
        "            if i == (len(trade_data.index.unique()) - 2):\n",
        "                last_state = trade_env.envs[0].render()\n",
        "\n",
        "        df_last_state = pd.DataFrame({\"last_state\": last_state})\n",
        "        df_last_state.to_csv(f\"results/last_state_{name}_{i}.csv\", index=False)\n",
        "        return last_state\n",
        "\n",
        "    def getSharpe(self, iter, model_name):\n",
        "        df_total_value = pd.read_csv(f\"results/account_value_validation_{model_name}_{iter}.csv\")\n",
        "        if df_total_value[\"daily_return\"].var() == 0:\n",
        "            if df_total_value[\"daily_return\"].mean() > 0:\n",
        "                return np.inf\n",
        "            else:\n",
        "                return 0\n",
        "        else:\n",
        "            return df_total_value[\"daily_return\"].mean() / df_total_value[\"daily_return\"].std() * np.sqrt(4)\n",
        "\n",
        "    def train(self, A2C_kwargs=None, PPO_kwargs=None, DDPG_kwargs=None, timesteps={\"a2c\": 50000, \"ppo\": 50000, \"ddpg\": 50000}):\n",
        "        tell = True\n",
        "        a2c_sharpe = []\n",
        "        ddpg_sharpe = []\n",
        "        ppo_sharpe = []\n",
        "        last_state = []\n",
        "\n",
        "        model_order = []\n",
        "        val_start_date = []\n",
        "        val_end_date = []\n",
        "        iteration_list = []\n",
        "\n",
        "        insample_turbulence = self.df[(self.df.date >= self.train_period[0]) & (self.df.date < self.train_period[1])]\n",
        "        insample_tur_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
        "        for i in range(self.rebalance_window + self.validation_window, len(self.unique_trade_date) + self.rebalance_window + self.validation_window, self.rebalance_window):\n",
        "            val_start = self.unique_trade_date[i - self.rebalance_window - self.validation_window]\n",
        "            if i > len(self.unique_trade_date):\n",
        "              tell = False\n",
        "            if i - self.rebalance_window > len(self.unique_trade_date):\n",
        "              end_index = -1\n",
        "            else:\n",
        "              end_index = i - self.rebalance_window\n",
        "            val_end = self.unique_trade_date[end_index]\n",
        "            # val_start = self.unique_trade_date[i]\n",
        "            # val_end = self.unique_trade_date[i + self.rebalance_window]\n",
        "            val_start_date.append(val_start)\n",
        "            val_end_date.append(val_end)\n",
        "            iteration_list.append(i)\n",
        "            initial = (i - self.rebalance_window - self.validation_window == 0)\n",
        "            end_date = self.df.index[self.df[\"date\"] == self.unique_trade_date[i - self.rebalance_window - self.validation_window]].to_list()[-1]\n",
        "            start_date = end_date - 63 + 1\n",
        "            history_tur_mean = np.mean(self.df.iloc[start_date : (end_date + 1), :].drop_duplicates(subset=[\"date\"]).turbulence.values)\n",
        "            if history_tur_mean > insample_tur_threshold:\n",
        "                tur_threshold = insample_tur_threshold\n",
        "            else:\n",
        "                tur_threshold = np.quantile(insample_turbulence.turbulence.values, 0.99)\n",
        "            print(\"Turbulence threshold: \", tur_threshold)\n",
        "\n",
        "            train = data_split(self.df, start=self.train_period[0], end=self.unique_trade_date[i - self.rebalance_window - self.validation_window],)\n",
        "            validation = data_split(self.df, start=self.unique_trade_date[i - self.rebalance_window - self.validation_window], end=self.unique_trade_date[end_index],)\n",
        "            self.train_env = DummyVecEnv([lambda: StockEnvMine(df=train, **self.env_args)])\n",
        "            print(\"Model training from: {} to {}\".format(self.train_period[0], self.unique_trade_date[i - self.rebalance_window - self.validation_window]))\n",
        "            print(\"A2C Training: \")\n",
        "            agent_a2c = Agent(env=self.train_env, iter_num=i, model_name=\"a2c_ensemble\", model_kwargs=A2C_kwargs)\n",
        "            trained_a2c = agent_a2c.train(total_timesteps=timesteps[\"a2c\"])\n",
        "            agent_a2c.model = trained_a2c\n",
        "            print(\"A2C Validation from {} to {}\".format(val_start, val_end))\n",
        "            val_env_a2c = DummyVecEnv([lambda: StockEnvMine(df=validation, turbulence_th=tur_threshold, iteration=i, mode=\"validation\", model_name=\"a2c_ensemble\", **self.env_args)])\n",
        "            val_obs_a2c = val_env_a2c.reset()\n",
        "            self.val(agent_a2c.model, validation, val_env_a2c, val_obs_a2c)\n",
        "            sharpe_a2c = self.getSharpe(i, model_name=\"a2c_ensemble\")\n",
        "            a2c_sharpe.append(sharpe_a2c)\n",
        "\n",
        "            print(\"DDPG Training: \")\n",
        "            agent_ddpg = Agent(env=self.train_env, iter_num=i, model_name=\"ddpg_ensemble\", model_kwargs=DDPG_kwargs)\n",
        "            trained_ddpg = agent_ddpg.train(total_timesteps=timesteps[\"ddpg\"])\n",
        "            agent_ddpg.model = trained_ddpg\n",
        "            print(\"DDPG Validation from {} to {}\".format(val_start, val_end))\n",
        "            val_env_ddpg = DummyVecEnv([lambda: StockEnvMine(df=validation, turbulence_th=tur_threshold, iteration=i, mode=\"validation\", model_name=\"ddpg_ensemble\", **self.env_args)])\n",
        "            val_obs_ddpg = val_env_ddpg.reset()\n",
        "            self.val(agent_ddpg.model, validation, val_env_ddpg, val_obs_ddpg)\n",
        "            sharpe_ddpg = self.getSharpe(i, model_name=\"ddpg_ensemble\")\n",
        "            ddpg_sharpe.append(sharpe_ddpg)\n",
        "\n",
        "            print(\"PPO Training: \")\n",
        "            agent_ppo = Agent(env=self.train_env, iter_num=i, model_name=\"ppo_ensemble\", model_kwargs=PPO_kwargs)\n",
        "            trained_ppo = agent_ppo.train(total_timesteps=timesteps[\"ppo\"])\n",
        "            agent_ppo.model = trained_ppo\n",
        "            print(\"PPO Validation from {} to {}\".format(val_start, val_end))\n",
        "            val_env_ppo = DummyVecEnv([lambda: StockEnvMine(df=validation, turbulence_th=tur_threshold, iteration=i, mode=\"validation\", model_name=\"ppo_ensemble\", **self.env_args)])\n",
        "            val_obs_ppo = val_env_ppo.reset()\n",
        "            self.val(agent_ppo.model, validation, val_env_ppo, val_obs_ppo)\n",
        "            sharpe_ppo = self.getSharpe(i, model_name=\"ppo_ensemble\")\n",
        "            ppo_sharpe.append(sharpe_ppo)\n",
        "\n",
        "            print(\"Ensemble Model Training: \")\n",
        "            if (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n",
        "                model_order.append(\"a2c\")\n",
        "                model_ensemble = agent_a2c.model\n",
        "            elif (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n",
        "                model_order.append(\"ppo\")\n",
        "                model_ensemble = agent_ppo.model\n",
        "            else:\n",
        "                model_order.append(\"ddpg\")\n",
        "                model_ensemble = agent_ddpg.model\n",
        "\n",
        "            if tell:\n",
        "                last_state = self.predict(model=model_ensemble, name=\"ensemble\", last_state=last_state, iter=i, tur_th=tur_threshold, initial=initial)\n",
        "\n",
        "        df_summary = pd.DataFrame({\"iteration\": iteration_list, \"Start Date\": val_start_date, \"End Date\": val_end_date, \"model_order\": model_order, \"a2c_sharpe\": a2c_sharpe, \"ddpg_sharpe\": ddpg_sharpe, \"ppo_sharpe\": ppo_sharpe})\n",
        "        return df_summary\n"
      ],
      "metadata": {
        "id": "75qiD12kcFvh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_START_DATE = '2021-01-01'\n",
        "TRAIN_END_DATE = '2023-01-01'\n",
        "TRADE_START_DATE = '2023-01-01'\n",
        "TRADE_END_DATE = '2023-09-01'"
      ],
      "metadata": {
        "id": "kh54OzxhcMJs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TRADE_END_DATE,\n",
        "                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnWkeurPdrEk",
        "outputId": "f5aac4fc-dbff-4f94-d11f-060d2bf81042"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (20100, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(['date','tic'],ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7ewu8gf-dxEW",
        "outputId": "62133e0f-22c8-4e28-ab11-30a7d20c3789"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             date        open        high         low       close     volume  \\\n",
              "0      2021-01-04  133.520004  133.610001  126.760002  127.164146  143301900   \n",
              "1      2021-01-04  231.250000  231.250000  223.669998  205.987122    3088200   \n",
              "2      2021-01-04  121.300003  121.800003  116.849998  113.507057    3472100   \n",
              "3      2021-01-04  210.000000  210.199997  202.490005  202.720001   21225600   \n",
              "4      2021-01-04  183.000000  185.979996  180.250000  170.827774    4078300   \n",
              "...           ...         ...         ...         ...         ...        ...   \n",
              "20095  2023-08-31  492.359985  493.820007  476.290009  473.117889    4927700   \n",
              "20096  2023-08-31  245.589996  248.020004  245.449997  245.158066    5532600   \n",
              "20097  2023-08-31   34.849998   35.139999   34.759998   34.248959   24333200   \n",
              "20098  2023-08-31   25.590000   25.760000   25.180000   24.724798   10794500   \n",
              "20099  2023-08-31  161.119995  162.990005  160.960007  162.610001    6527600   \n",
              "\n",
              "        tic  day  \n",
              "0      AAPL    0  \n",
              "1      AMGN    0  \n",
              "2       AXP    0  \n",
              "3        BA    0  \n",
              "4       CAT    0  \n",
              "...     ...  ...  \n",
              "20095   UNH    3  \n",
              "20096     V    3  \n",
              "20097    VZ    3  \n",
              "20098   WBA    3  \n",
              "20099   WMT    3  \n",
              "\n",
              "[20100 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bce873a-d659-4a37-99f6-cfecb63fafe5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>133.520004</td>\n",
              "      <td>133.610001</td>\n",
              "      <td>126.760002</td>\n",
              "      <td>127.164146</td>\n",
              "      <td>143301900</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>231.250000</td>\n",
              "      <td>231.250000</td>\n",
              "      <td>223.669998</td>\n",
              "      <td>205.987122</td>\n",
              "      <td>3088200</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>121.300003</td>\n",
              "      <td>121.800003</td>\n",
              "      <td>116.849998</td>\n",
              "      <td>113.507057</td>\n",
              "      <td>3472100</td>\n",
              "      <td>AXP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.199997</td>\n",
              "      <td>202.490005</td>\n",
              "      <td>202.720001</td>\n",
              "      <td>21225600</td>\n",
              "      <td>BA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>183.000000</td>\n",
              "      <td>185.979996</td>\n",
              "      <td>180.250000</td>\n",
              "      <td>170.827774</td>\n",
              "      <td>4078300</td>\n",
              "      <td>CAT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20095</th>\n",
              "      <td>2023-08-31</td>\n",
              "      <td>492.359985</td>\n",
              "      <td>493.820007</td>\n",
              "      <td>476.290009</td>\n",
              "      <td>473.117889</td>\n",
              "      <td>4927700</td>\n",
              "      <td>UNH</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20096</th>\n",
              "      <td>2023-08-31</td>\n",
              "      <td>245.589996</td>\n",
              "      <td>248.020004</td>\n",
              "      <td>245.449997</td>\n",
              "      <td>245.158066</td>\n",
              "      <td>5532600</td>\n",
              "      <td>V</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20097</th>\n",
              "      <td>2023-08-31</td>\n",
              "      <td>34.849998</td>\n",
              "      <td>35.139999</td>\n",
              "      <td>34.759998</td>\n",
              "      <td>34.248959</td>\n",
              "      <td>24333200</td>\n",
              "      <td>VZ</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20098</th>\n",
              "      <td>2023-08-31</td>\n",
              "      <td>25.590000</td>\n",
              "      <td>25.760000</td>\n",
              "      <td>25.180000</td>\n",
              "      <td>24.724798</td>\n",
              "      <td>10794500</td>\n",
              "      <td>WBA</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20099</th>\n",
              "      <td>2023-08-31</td>\n",
              "      <td>161.119995</td>\n",
              "      <td>162.990005</td>\n",
              "      <td>160.960007</td>\n",
              "      <td>162.610001</td>\n",
              "      <td>6527600</td>\n",
              "      <td>WMT</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20100 rows √ó 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bce873a-d659-4a37-99f6-cfecb63fafe5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8bce873a-d659-4a37-99f6-cfecb63fafe5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8bce873a-d659-4a37-99f6-cfecb63fafe5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ca3def09-6821-410b-8051-043fde1bc2c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca3def09-6821-410b-8051-043fde1bc2c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ca3def09-6821-410b-8051-043fde1bc2c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = INDICATORS,\n",
        "                    use_vix=True,\n",
        "                    use_turbulence=True,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1h1Ikl1d2by",
        "outputId": "fe3070ed-9e74-438a-aa90-50379a45f183"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n",
            "\r[*********************100%%**********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (669, 8)\n",
            "Successfully added vix\n",
            "Successfully added turbulence index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_ticker = processed[\"tic\"].unique().tolist()\n",
        "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
        "combination = list(itertools.product(list_date,list_ticker))\n",
        "\n",
        "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
        "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
        "processed_full = processed_full.sort_values(['date','tic'])\n",
        "\n",
        "processed_full = processed_full.fillna(0)\n",
        "processed_full.sort_values(['date','tic'],ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "8xRxIzKAd9H5",
        "outputId": "841f156f-7b05-401c-88e5-ddf7a878c2b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             date   tic        open        high         low       close  \\\n",
              "0      2021-01-04  AAPL  133.520004  133.610001  126.760002  127.164146   \n",
              "1      2021-01-04  AMGN  231.250000  231.250000  223.669998  205.987122   \n",
              "2      2021-01-04   AXP  121.300003  121.800003  116.849998  113.507057   \n",
              "3      2021-01-04    BA  210.000000  210.199997  202.490005  202.720001   \n",
              "4      2021-01-04   CAT  183.000000  185.979996  180.250000  170.827774   \n",
              "...           ...   ...         ...         ...         ...         ...   \n",
              "20065  2023-08-30   UNH  493.989990  496.709991  490.290009  487.959259   \n",
              "20066  2023-08-30     V  246.419998  248.229996  246.050003  245.706894   \n",
              "20067  2023-08-30    VZ   34.889999   34.950001   34.549999   33.916065   \n",
              "20068  2023-08-30   WBA   25.629999   25.770000   25.450001   25.008093   \n",
              "20069  2023-08-30   WMT  160.399994  161.289993  159.919998  161.199997   \n",
              "\n",
              "            volume  day      macd     boll_ub     boll_lb      rsi_30  \\\n",
              "0      143301900.0  0.0  0.000000  130.173726  125.726795  100.000000   \n",
              "1        3088200.0  0.0  0.000000  130.173726  125.726795  100.000000   \n",
              "2        3472100.0  0.0  0.000000  130.173726  125.726795  100.000000   \n",
              "3       21225600.0  0.0  0.000000  130.173726  125.726795  100.000000   \n",
              "4        4078300.0  0.0  0.000000  130.173726  125.726795  100.000000   \n",
              "...            ...  ...       ...         ...         ...         ...   \n",
              "20065    2283400.0  2.0 -1.366175  510.656663  480.459697   49.573602   \n",
              "20066    4573300.0  2.0  1.805050  245.028929  235.307544   59.424616   \n",
              "20067   15021400.0  2.0  0.042518   33.674198   31.455613   52.358194   \n",
              "20068    5883700.0  2.0 -1.042668   29.841717   23.664549   34.911832   \n",
              "20069    3655900.0  2.0  0.545948  161.911589  155.852143   59.052620   \n",
              "\n",
              "           cci_30       dx_30  close_30_sma  close_60_sma        vix  \\\n",
              "0       66.666667  100.000000    127.164146    127.164146  26.969999   \n",
              "1       66.666667  100.000000    205.987122    205.987122  26.969999   \n",
              "2       66.666667  100.000000    113.507057    113.507057  26.969999   \n",
              "3       66.666667  100.000000    202.720001    202.720001  26.969999   \n",
              "4       66.666667  100.000000    170.827774    170.827774  26.969999   \n",
              "...           ...         ...           ...           ...        ...   \n",
              "20065 -100.696843    5.966966    497.893923    485.160452  13.880000   \n",
              "20066  241.957110   16.612777    239.150281    235.436313  13.880000   \n",
              "20067  184.246607   24.916800     32.757136     33.562109  13.880000   \n",
              "20068 -117.483862   52.212555     27.544158     28.400918  13.880000   \n",
              "20069  109.591486   26.770831    158.777343    156.531765  13.880000   \n",
              "\n",
              "       turbulence  \n",
              "0        0.000000  \n",
              "1        0.000000  \n",
              "2        0.000000  \n",
              "3        0.000000  \n",
              "4        0.000000  \n",
              "...           ...  \n",
              "20065    7.527189  \n",
              "20066    7.527189  \n",
              "20067    7.527189  \n",
              "20068    7.527189  \n",
              "20069    7.527189  \n",
              "\n",
              "[20070 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae908a8e-af8e-44cf-9aaf-8779b4e58b49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>tic</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>vix</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>133.520004</td>\n",
              "      <td>133.610001</td>\n",
              "      <td>126.760002</td>\n",
              "      <td>127.164146</td>\n",
              "      <td>143301900.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>130.173726</td>\n",
              "      <td>125.726795</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>127.164146</td>\n",
              "      <td>127.164146</td>\n",
              "      <td>26.969999</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>231.250000</td>\n",
              "      <td>231.250000</td>\n",
              "      <td>223.669998</td>\n",
              "      <td>205.987122</td>\n",
              "      <td>3088200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>130.173726</td>\n",
              "      <td>125.726795</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>205.987122</td>\n",
              "      <td>205.987122</td>\n",
              "      <td>26.969999</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>AXP</td>\n",
              "      <td>121.300003</td>\n",
              "      <td>121.800003</td>\n",
              "      <td>116.849998</td>\n",
              "      <td>113.507057</td>\n",
              "      <td>3472100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>130.173726</td>\n",
              "      <td>125.726795</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>113.507057</td>\n",
              "      <td>113.507057</td>\n",
              "      <td>26.969999</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>BA</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>210.199997</td>\n",
              "      <td>202.490005</td>\n",
              "      <td>202.720001</td>\n",
              "      <td>21225600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>130.173726</td>\n",
              "      <td>125.726795</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>202.720001</td>\n",
              "      <td>202.720001</td>\n",
              "      <td>26.969999</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>CAT</td>\n",
              "      <td>183.000000</td>\n",
              "      <td>185.979996</td>\n",
              "      <td>180.250000</td>\n",
              "      <td>170.827774</td>\n",
              "      <td>4078300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>130.173726</td>\n",
              "      <td>125.726795</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>170.827774</td>\n",
              "      <td>170.827774</td>\n",
              "      <td>26.969999</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20065</th>\n",
              "      <td>2023-08-30</td>\n",
              "      <td>UNH</td>\n",
              "      <td>493.989990</td>\n",
              "      <td>496.709991</td>\n",
              "      <td>490.290009</td>\n",
              "      <td>487.959259</td>\n",
              "      <td>2283400.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.366175</td>\n",
              "      <td>510.656663</td>\n",
              "      <td>480.459697</td>\n",
              "      <td>49.573602</td>\n",
              "      <td>-100.696843</td>\n",
              "      <td>5.966966</td>\n",
              "      <td>497.893923</td>\n",
              "      <td>485.160452</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>7.527189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20066</th>\n",
              "      <td>2023-08-30</td>\n",
              "      <td>V</td>\n",
              "      <td>246.419998</td>\n",
              "      <td>248.229996</td>\n",
              "      <td>246.050003</td>\n",
              "      <td>245.706894</td>\n",
              "      <td>4573300.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.805050</td>\n",
              "      <td>245.028929</td>\n",
              "      <td>235.307544</td>\n",
              "      <td>59.424616</td>\n",
              "      <td>241.957110</td>\n",
              "      <td>16.612777</td>\n",
              "      <td>239.150281</td>\n",
              "      <td>235.436313</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>7.527189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20067</th>\n",
              "      <td>2023-08-30</td>\n",
              "      <td>VZ</td>\n",
              "      <td>34.889999</td>\n",
              "      <td>34.950001</td>\n",
              "      <td>34.549999</td>\n",
              "      <td>33.916065</td>\n",
              "      <td>15021400.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.042518</td>\n",
              "      <td>33.674198</td>\n",
              "      <td>31.455613</td>\n",
              "      <td>52.358194</td>\n",
              "      <td>184.246607</td>\n",
              "      <td>24.916800</td>\n",
              "      <td>32.757136</td>\n",
              "      <td>33.562109</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>7.527189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20068</th>\n",
              "      <td>2023-08-30</td>\n",
              "      <td>WBA</td>\n",
              "      <td>25.629999</td>\n",
              "      <td>25.770000</td>\n",
              "      <td>25.450001</td>\n",
              "      <td>25.008093</td>\n",
              "      <td>5883700.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.042668</td>\n",
              "      <td>29.841717</td>\n",
              "      <td>23.664549</td>\n",
              "      <td>34.911832</td>\n",
              "      <td>-117.483862</td>\n",
              "      <td>52.212555</td>\n",
              "      <td>27.544158</td>\n",
              "      <td>28.400918</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>7.527189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20069</th>\n",
              "      <td>2023-08-30</td>\n",
              "      <td>WMT</td>\n",
              "      <td>160.399994</td>\n",
              "      <td>161.289993</td>\n",
              "      <td>159.919998</td>\n",
              "      <td>161.199997</td>\n",
              "      <td>3655900.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.545948</td>\n",
              "      <td>161.911589</td>\n",
              "      <td>155.852143</td>\n",
              "      <td>59.052620</td>\n",
              "      <td>109.591486</td>\n",
              "      <td>26.770831</td>\n",
              "      <td>158.777343</td>\n",
              "      <td>156.531765</td>\n",
              "      <td>13.880000</td>\n",
              "      <td>7.527189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20070 rows √ó 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae908a8e-af8e-44cf-9aaf-8779b4e58b49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ae908a8e-af8e-44cf-9aaf-8779b4e58b49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ae908a8e-af8e-44cf-9aaf-8779b4e58b49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d787f19b-9aa7-4f63-a30a-197a94b892f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d787f19b-9aa7-4f63-a30a-197a94b892f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d787f19b-9aa7-4f63-a30a-197a94b892f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INDICATORS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucxjzp85eUPt",
        "outputId": "11510200-6f65-4696-e2e2-d392519f8e72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['macd',\n",
              " 'boll_ub',\n",
              " 'boll_lb',\n",
              " 'rsi_30',\n",
              " 'cci_30',\n",
              " 'dx_30',\n",
              " 'close_30_sma',\n",
              " 'close_60_sma']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_full = processed_full[processed_full['tic'] != 'DOW']"
      ],
      "metadata": {
        "id": "ldLiiae0e-sA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_dimension = len(processed_full.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVbQ_cakedMB",
        "outputId": "c395e25a-0207-4813-c6d0-22c2f55a9b68"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 29, State Space: 291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
        "num_stock_shares = [0] * stock_dimension\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"num_stock_shares\": num_stock_shares,\n",
        "    \"buy_cost_pct\": buy_cost_list,\n",
        "    \"sell_cost_pct\": sell_cost_list,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4\n",
        "}"
      ],
      "metadata": {
        "id": "cSZi0ZAxf-P5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble = EnsembleAgent(df=processed_full, train_period=[TRAIN_START_DATE, TRAIN_END_DATE], val_period=[TRADE_START_DATE, TRADE_END_DATE], rebalance_window=63, validation_window=63, env_args=env_kwargs)"
      ],
      "metadata": {
        "id": "_-ynaD1zgeaI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.01,\n",
        "    \"learning_rate\": 0.00025,\n",
        "    \"batch_size\": 128,\n",
        "}"
      ],
      "metadata": {
        "id": "WzBMEnXmgNP1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = ensemble.train(PPO_kwargs=PPO_PARAMS)"
      ],
      "metadata": {
        "id": "U5NS1Zm0hJ0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b1a283-4c5c-4464-be27-4d25e4423bb9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turbulence threshold:  139.63256139475178\n",
            "Model training from: 2021-01-01 to 2023-01-03\n",
            "A2C Training: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 160        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.00609   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -28.4      |\n",
            "|    reward             | -1.2829983 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.42       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1195332.41\n",
            "total_reward: 195332.41\n",
            "total_cost: 38057430.92\n",
            "total_trades: 11771\n",
            "Sharpe: 0.554\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 212         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -138        |\n",
            "|    reward             | -0.40600002 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 11.2        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 2\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1318079.32\n",
            "total_reward: 318079.32\n",
            "total_cost: 24671078.99\n",
            "total_trades: 10389\n",
            "Sharpe: 0.805\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 237        |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | 48.1       |\n",
            "|    reward             | -1.8238114 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 1.69       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 3\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1314289.95\n",
            "total_reward: 314289.95\n",
            "total_cost: 22675567.65\n",
            "total_trades: 10022\n",
            "Sharpe: 0.806\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 252       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0.101     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -155      |\n",
            "|    reward             | -1.289509 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 17.5      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 4\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1110865.71\n",
            "total_reward: 110865.71\n",
            "total_cost: 21764194.71\n",
            "total_trades: 9645\n",
            "Sharpe: 0.380\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 261          |\n",
            "|    iterations         | 500          |\n",
            "|    time_elapsed       | 9            |\n",
            "|    total_timesteps    | 2500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.2        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 499          |\n",
            "|    policy_loss        | 45.8         |\n",
            "|    reward             | -0.046533268 |\n",
            "|    std                | 1            |\n",
            "|    value_loss         | 2.85         |\n",
            "----------------------------------------\n",
            "day: 502, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 931919.01\n",
            "total_reward: -68080.99\n",
            "total_cost: 20628620.81\n",
            "total_trades: 9562\n",
            "Sharpe: -0.085\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 269       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -68.9     |\n",
            "|    reward             | -2.474757 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.78      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 6\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1224186.27\n",
            "total_reward: 224186.27\n",
            "total_cost: 13847082.46\n",
            "total_trades: 9062\n",
            "Sharpe: 0.623\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 274       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 130       |\n",
            "|    reward             | 0.2992386 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 12        |\n",
            "-------------------------------------\n",
            "day: 502, episode: 7\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 716324.52\n",
            "total_reward: -283675.48\n",
            "total_cost: 14194881.84\n",
            "total_trades: 9642\n",
            "Sharpe: -0.585\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 279        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 14         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.062     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -2.96      |\n",
            "|    reward             | -2.4292772 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.766      |\n",
            "--------------------------------------\n",
            "day: 502, episode: 8\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1057637.35\n",
            "total_reward: 57637.35\n",
            "total_cost: 9535955.61\n",
            "total_trades: 9257\n",
            "Sharpe: 0.242\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 283       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 88.4      |\n",
            "|    reward             | 0.6082924 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 10.1      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 9\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 790670.44\n",
            "total_reward: -209329.56\n",
            "total_cost: 7420597.54\n",
            "total_trades: 8858\n",
            "Sharpe: -0.382\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 285        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -24        |\n",
            "|    reward             | -1.9679322 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 5.44       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 581524.74\n",
            "total_reward: -418475.26\n",
            "total_cost: 7032835.72\n",
            "total_trades: 8970\n",
            "Sharpe: -0.813\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 288         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 19          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | -0.00119    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -105        |\n",
            "|    reward             | 0.043245096 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 16.3        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 11\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 589133.74\n",
            "total_reward: -410866.26\n",
            "total_cost: 5548916.09\n",
            "total_trades: 8983\n",
            "Sharpe: -0.736\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 290       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -174      |\n",
            "|    reward             | -4.837639 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 16        |\n",
            "-------------------------------------\n",
            "day: 502, episode: 12\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 829036.81\n",
            "total_reward: -170963.19\n",
            "total_cost: 8552640.78\n",
            "total_trades: 9723\n",
            "Sharpe: -0.317\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 291        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 63.6       |\n",
            "|    reward             | -1.2072817 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 3.13       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 13\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 752132.63\n",
            "total_reward: -247867.37\n",
            "total_cost: 7286081.62\n",
            "total_trades: 9317\n",
            "Sharpe: -0.422\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 293       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 163       |\n",
            "|    reward             | -0.457792 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 15.9      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 14\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 742297.84\n",
            "total_reward: -257702.16\n",
            "total_cost: 5943680.65\n",
            "total_trades: 8890\n",
            "Sharpe: -0.458\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 294         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 115         |\n",
            "|    reward             | -0.03905064 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 11.5        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 691947.81\n",
            "total_reward: -308052.19\n",
            "total_cost: 7807446.74\n",
            "total_trades: 9345\n",
            "Sharpe: -0.521\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 295        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 67.4       |\n",
            "|    reward             | 0.17109369 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 3.19       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 16\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 616126.51\n",
            "total_reward: -383873.49\n",
            "total_cost: 5727407.27\n",
            "total_trades: 8694\n",
            "Sharpe: -0.655\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 296         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 28          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | -136        |\n",
            "|    reward             | 0.114108555 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 16          |\n",
            "---------------------------------------\n",
            "day: 502, episode: 17\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 586653.59\n",
            "total_reward: -413346.41\n",
            "total_cost: 5716800.39\n",
            "total_trades: 8663\n",
            "Sharpe: -0.643\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 297        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -58.8      |\n",
            "|    reward             | -2.0937123 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 6.88       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 18\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 721559.55\n",
            "total_reward: -278440.45\n",
            "total_cost: 6194622.02\n",
            "total_trades: 8605\n",
            "Sharpe: -0.445\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 298        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -0.0178    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 92.3       |\n",
            "|    reward             | -1.2694553 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 8.52       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 19\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 738522.12\n",
            "total_reward: -261477.88\n",
            "total_cost: 5023575.75\n",
            "total_trades: 8096\n",
            "Sharpe: -0.373\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 299        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 33         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -2.38e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -210       |\n",
            "|    reward             | -0.6716443 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 24.1       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 910607.34\n",
            "total_reward: -89392.66\n",
            "total_cost: 4428953.46\n",
            "total_trades: 8140\n",
            "Sharpe: -0.032\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 300      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.4    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | -82      |\n",
            "|    reward             | 2.690061 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 5.51     |\n",
            "------------------------------------\n",
            "day: 502, episode: 21\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 925585.88\n",
            "total_reward: -74414.12\n",
            "total_cost: 4102032.26\n",
            "total_trades: 8206\n",
            "Sharpe: -0.035\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 301        |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 36         |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | -44        |\n",
            "|    reward             | -0.3567622 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.39       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 22\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 914670.61\n",
            "total_reward: -85329.39\n",
            "total_cost: 3792093.57\n",
            "total_trades: 8596\n",
            "Sharpe: -0.056\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 301        |\n",
            "|    iterations         | 2300       |\n",
            "|    time_elapsed       | 38         |\n",
            "|    total_timesteps    | 11500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0.0344     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2299       |\n",
            "|    policy_loss        | -153       |\n",
            "|    reward             | -1.4562616 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 20.8       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 23\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 892420.32\n",
            "total_reward: -107579.68\n",
            "total_cost: 2734475.55\n",
            "total_trades: 8373\n",
            "Sharpe: -0.114\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 302        |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 39         |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | -108       |\n",
            "|    reward             | 0.60107607 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 11.7       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 24\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 961957.23\n",
            "total_reward: -38042.77\n",
            "total_cost: 2901452.39\n",
            "total_trades: 7699\n",
            "Sharpe: 0.055\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 302        |\n",
            "|    iterations         | 2500       |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0.0606     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2499       |\n",
            "|    policy_loss        | 0.533      |\n",
            "|    reward             | -2.0405197 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.43       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 886050.51\n",
            "total_reward: -113949.49\n",
            "total_cost: 2893340.15\n",
            "total_trades: 7404\n",
            "Sharpe: -0.114\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 303       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | -80.7     |\n",
            "|    reward             | 1.2214651 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 4.56      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 26\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 901671.67\n",
            "total_reward: -98328.33\n",
            "total_cost: 3631959.65\n",
            "total_trades: 7258\n",
            "Sharpe: -0.097\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 304       |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 13500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0.0462    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | -179      |\n",
            "|    reward             | 1.3398682 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 22.7      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 27\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 924678.78\n",
            "total_reward: -75321.22\n",
            "total_cost: 3528717.09\n",
            "total_trades: 7203\n",
            "Sharpe: -0.053\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 304        |\n",
            "|    iterations         | 2800       |\n",
            "|    time_elapsed       | 45         |\n",
            "|    total_timesteps    | 14000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2799       |\n",
            "|    policy_loss        | -23.6      |\n",
            "|    reward             | 0.30066225 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 4.34       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 28\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 885588.07\n",
            "total_reward: -114411.93\n",
            "total_cost: 3883304.74\n",
            "total_trades: 7385\n",
            "Sharpe: -0.133\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 305       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0.189     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | -157      |\n",
            "|    reward             | -1.453416 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 16.4      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 29\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 868573.87\n",
            "total_reward: -131426.13\n",
            "total_cost: 3650713.41\n",
            "total_trades: 7163\n",
            "Sharpe: -0.167\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 305       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 49        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | 71.3      |\n",
            "|    reward             | 0.6275546 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 5.02      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 884751.41\n",
            "total_reward: -115248.59\n",
            "total_cost: 3316553.83\n",
            "total_trades: 7052\n",
            "Sharpe: -0.139\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 305        |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 50         |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | 162        |\n",
            "|    reward             | -1.9291413 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 17.7       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 31\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 916797.57\n",
            "total_reward: -83202.43\n",
            "total_cost: 3655639.71\n",
            "total_trades: 7210\n",
            "Sharpe: -0.028\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 305          |\n",
            "|    iterations         | 3200         |\n",
            "|    time_elapsed       | 52           |\n",
            "|    total_timesteps    | 16000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3199         |\n",
            "|    policy_loss        | 8.6          |\n",
            "|    reward             | -0.068451755 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 2.57         |\n",
            "----------------------------------------\n",
            "day: 502, episode: 32\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 955178.07\n",
            "total_reward: -44821.93\n",
            "total_cost: 3858889.50\n",
            "total_trades: 7168\n",
            "Sharpe: 0.050\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 305         |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 53          |\n",
            "|    total_timesteps    | 16500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | 120         |\n",
            "|    reward             | -0.19041386 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 13.6        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 33\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1002078.80\n",
            "total_reward: 2078.80\n",
            "total_cost: 2976643.13\n",
            "total_trades: 7205\n",
            "Sharpe: 0.140\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 306         |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 55          |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.5       |\n",
            "|    explained_variance | 0.0384      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | 145         |\n",
            "|    reward             | -0.13567726 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 17.8        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 34\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1030816.28\n",
            "total_reward: 30816.28\n",
            "total_cost: 2918471.98\n",
            "total_trades: 7441\n",
            "Sharpe: 0.187\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 306       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 17500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | -0.118    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 41.1      |\n",
            "|    reward             | 3.7108574 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2         |\n",
            "-------------------------------------\n",
            "day: 502, episode: 35\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1010984.62\n",
            "total_reward: 10984.62\n",
            "total_cost: 2856987.06\n",
            "total_trades: 7297\n",
            "Sharpe: 0.143\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 306       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 58        |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | -0.0707   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 89.2      |\n",
            "|    reward             | 2.8557472 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 9.58      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 36\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1087829.76\n",
            "total_reward: 87829.76\n",
            "total_cost: 3249860.81\n",
            "total_trades: 7140\n",
            "Sharpe: 0.296\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 307       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 60        |\n",
            "|    total_timesteps    | 18500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0.0195    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 143       |\n",
            "|    reward             | -1.715572 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 13.9      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 37\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1109976.45\n",
            "total_reward: 109976.45\n",
            "total_cost: 2526696.56\n",
            "total_trades: 7176\n",
            "Sharpe: 0.353\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 307       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 61        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | -0.0673   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | -17       |\n",
            "|    reward             | 1.5290825 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.669     |\n",
            "-------------------------------------\n",
            "day: 502, episode: 38\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1039685.03\n",
            "total_reward: 39685.03\n",
            "total_cost: 2490580.33\n",
            "total_trades: 7136\n",
            "Sharpe: 0.200\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 307         |\n",
            "|    iterations         | 3900        |\n",
            "|    time_elapsed       | 63          |\n",
            "|    total_timesteps    | 19500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3899        |\n",
            "|    policy_loss        | 2.36        |\n",
            "|    reward             | -0.97138137 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 1.72        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 39\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 991071.78\n",
            "total_reward: -8928.22\n",
            "total_cost: 2240415.75\n",
            "total_trades: 7237\n",
            "Sharpe: 0.097\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 307         |\n",
            "|    iterations         | 4000        |\n",
            "|    time_elapsed       | 64          |\n",
            "|    total_timesteps    | 20000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.7       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3999        |\n",
            "|    policy_loss        | 61.2        |\n",
            "|    reward             | -0.30336145 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 2.72        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 40\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1039958.37\n",
            "total_reward: 39958.37\n",
            "total_cost: 2316725.73\n",
            "total_trades: 7288\n",
            "Sharpe: 0.201\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 308         |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 66          |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | -82.8       |\n",
            "|    reward             | -0.11569263 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 5.13        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 41\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1051534.95\n",
            "total_reward: 51534.95\n",
            "total_cost: 2169487.64\n",
            "total_trades: 7038\n",
            "Sharpe: 0.225\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 308       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 68        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | -0.0169   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 115       |\n",
            "|    reward             | 1.1805886 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 10.3      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 42\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1116052.90\n",
            "total_reward: 116052.90\n",
            "total_cost: 2621740.16\n",
            "total_trades: 7355\n",
            "Sharpe: 0.368\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 308       |\n",
            "|    iterations         | 4300      |\n",
            "|    time_elapsed       | 69        |\n",
            "|    total_timesteps    | 21500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4299      |\n",
            "|    policy_loss        | -36       |\n",
            "|    reward             | 0.6054563 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.01      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 43\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1080589.15\n",
            "total_reward: 80589.15\n",
            "total_cost: 2866586.28\n",
            "total_trades: 7636\n",
            "Sharpe: 0.286\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 308       |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 71        |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | -219      |\n",
            "|    reward             | 2.6671119 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 33.4      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 44\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1097884.50\n",
            "total_reward: 97884.50\n",
            "total_cost: 3663561.50\n",
            "total_trades: 7959\n",
            "Sharpe: 0.330\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 308       |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 72        |\n",
            "|    total_timesteps    | 22500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | -297      |\n",
            "|    reward             | 1.6874037 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 56        |\n",
            "-------------------------------------\n",
            "day: 502, episode: 45\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1026630.06\n",
            "total_reward: 26630.06\n",
            "total_cost: 4582374.54\n",
            "total_trades: 7811\n",
            "Sharpe: 0.167\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 308       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 74        |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 16.4      |\n",
            "|    reward             | 0.6404936 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.691     |\n",
            "-------------------------------------\n",
            "day: 502, episode: 46\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1075498.59\n",
            "total_reward: 75498.59\n",
            "total_cost: 4183219.92\n",
            "total_trades: 7685\n",
            "Sharpe: 0.278\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 309       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 76        |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | 0.0173    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | -39.7     |\n",
            "|    reward             | -3.519358 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 3.31      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 47\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1097857.47\n",
            "total_reward: 97857.47\n",
            "total_cost: 3170363.30\n",
            "total_trades: 7627\n",
            "Sharpe: 0.316\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 309       |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 77        |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.9     |\n",
            "|    explained_variance | 4.08e-05  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | 144       |\n",
            "|    reward             | 1.5753967 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 14.5      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 48\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1017287.85\n",
            "total_reward: 17287.85\n",
            "total_cost: 3096739.94\n",
            "total_trades: 7402\n",
            "Sharpe: 0.153\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 309      |\n",
            "|    iterations         | 4900     |\n",
            "|    time_elapsed       | 79       |\n",
            "|    total_timesteps    | 24500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4899     |\n",
            "|    policy_loss        | 21.6     |\n",
            "|    reward             | 2.007375 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 2.4      |\n",
            "------------------------------------\n",
            "day: 502, episode: 49\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1017036.28\n",
            "total_reward: 17036.28\n",
            "total_cost: 3140860.03\n",
            "total_trades: 7265\n",
            "Sharpe: 0.157\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 309      |\n",
            "|    iterations         | 5000     |\n",
            "|    time_elapsed       | 80       |\n",
            "|    total_timesteps    | 25000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4999     |\n",
            "|    policy_loss        | -227     |\n",
            "|    reward             | 3.89255  |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 34.9     |\n",
            "------------------------------------\n",
            "day: 502, episode: 50\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1017545.45\n",
            "total_reward: 17545.45\n",
            "total_cost: 2886432.50\n",
            "total_trades: 7341\n",
            "Sharpe: 0.163\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 309       |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 82        |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.9     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | 93.4      |\n",
            "|    reward             | -1.655807 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 9.57      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 51\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1003544.12\n",
            "total_reward: 3544.12\n",
            "total_cost: 2765570.78\n",
            "total_trades: 7577\n",
            "Sharpe: 0.131\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 83         |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | -286       |\n",
            "|    reward             | -2.6085138 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 46         |\n",
            "--------------------------------------\n",
            "day: 502, episode: 52\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 988379.58\n",
            "total_reward: -11620.42\n",
            "total_cost: 2571522.01\n",
            "total_trades: 7599\n",
            "Sharpe: 0.104\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 85          |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | -213        |\n",
            "|    reward             | -0.79145575 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 35.4        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 53\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1011916.53\n",
            "total_reward: 11916.53\n",
            "total_cost: 2611351.76\n",
            "total_trades: 7601\n",
            "Sharpe: 0.148\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 5400      |\n",
            "|    time_elapsed       | 87        |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.9     |\n",
            "|    explained_variance | 0.0953    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5399      |\n",
            "|    policy_loss        | 177       |\n",
            "|    reward             | -4.961829 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 19.6      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 54\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 994021.90\n",
            "total_reward: -5978.10\n",
            "total_cost: 2591660.59\n",
            "total_trades: 7279\n",
            "Sharpe: 0.122\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 88         |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | -88.5      |\n",
            "|    reward             | -0.5275017 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 9.36       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 55\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 952490.94\n",
            "total_reward: -47509.06\n",
            "total_cost: 2796505.98\n",
            "total_trades: 7220\n",
            "Sharpe: 0.038\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 90         |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.8      |\n",
            "|    explained_variance | 0.0522     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | -260       |\n",
            "|    reward             | 0.34344044 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 42.4       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 56\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 926660.10\n",
            "total_reward: -73339.90\n",
            "total_cost: 3065113.23\n",
            "total_trades: 7122\n",
            "Sharpe: -0.028\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | -5.02     |\n",
            "|    reward             | 4.8760624 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.06      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 57\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 982452.83\n",
            "total_reward: -17547.17\n",
            "total_cost: 2863669.11\n",
            "total_trades: 7002\n",
            "Sharpe: 0.097\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5800       |\n",
            "|    time_elapsed       | 93         |\n",
            "|    total_timesteps    | 29000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5799       |\n",
            "|    policy_loss        | -58.5      |\n",
            "|    reward             | 0.51420593 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.59       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 58\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 871845.95\n",
            "total_reward: -128154.05\n",
            "total_cost: 3188611.62\n",
            "total_trades: 6814\n",
            "Sharpe: -0.159\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | -113        |\n",
            "|    reward             | -0.77805644 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 10.9        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 59\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 905421.63\n",
            "total_reward: -94578.37\n",
            "total_cost: 3206012.54\n",
            "total_trades: 6809\n",
            "Sharpe: -0.070\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 6000       |\n",
            "|    time_elapsed       | 96         |\n",
            "|    total_timesteps    | 30000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5999       |\n",
            "|    policy_loss        | -99.1      |\n",
            "|    reward             | -1.1442947 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 8.03       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 60\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 944369.15\n",
            "total_reward: -55630.85\n",
            "total_cost: 3058166.06\n",
            "total_trades: 7060\n",
            "Sharpe: 0.020\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | 3.86       |\n",
            "|    reward             | -2.6131754 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.26       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 61\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 984514.45\n",
            "total_reward: -15485.55\n",
            "total_cost: 3120691.59\n",
            "total_trades: 7220\n",
            "Sharpe: 0.092\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 6200      |\n",
            "|    time_elapsed       | 99        |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6199      |\n",
            "|    policy_loss        | 20.9      |\n",
            "|    reward             | -2.190097 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.39      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 62\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1074368.72\n",
            "total_reward: 74368.72\n",
            "total_cost: 3205929.38\n",
            "total_trades: 7353\n",
            "Sharpe: 0.274\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 6300       |\n",
            "|    time_elapsed       | 101        |\n",
            "|    total_timesteps    | 31500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6299       |\n",
            "|    policy_loss        | -48.4      |\n",
            "|    reward             | 0.07007629 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.96       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 63\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1075120.03\n",
            "total_reward: 75120.03\n",
            "total_cost: 3575696.02\n",
            "total_trades: 7445\n",
            "Sharpe: 0.280\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 311      |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 102      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.9    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | 27.5     |\n",
            "|    reward             | 1.348814 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 2.6      |\n",
            "------------------------------------\n",
            "day: 502, episode: 64\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1068047.29\n",
            "total_reward: 68047.29\n",
            "total_cost: 2559593.69\n",
            "total_trades: 7024\n",
            "Sharpe: 0.262\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 311          |\n",
            "|    iterations         | 6500         |\n",
            "|    time_elapsed       | 104          |\n",
            "|    total_timesteps    | 32500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -42          |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6499         |\n",
            "|    policy_loss        | 120          |\n",
            "|    reward             | -0.020775257 |\n",
            "|    std                | 1.03         |\n",
            "|    value_loss         | 11.1         |\n",
            "----------------------------------------\n",
            "day: 502, episode: 65\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1026301.64\n",
            "total_reward: 26301.64\n",
            "total_cost: 2687261.60\n",
            "total_trades: 6913\n",
            "Sharpe: 0.167\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 105        |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -48.8      |\n",
            "|    reward             | -2.4345412 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.7        |\n",
            "--------------------------------------\n",
            "day: 502, episode: 66\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1018364.52\n",
            "total_reward: 18364.52\n",
            "total_cost: 3505124.73\n",
            "total_trades: 6776\n",
            "Sharpe: 0.150\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 6700      |\n",
            "|    time_elapsed       | 107       |\n",
            "|    total_timesteps    | 33500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6699      |\n",
            "|    policy_loss        | -71.6     |\n",
            "|    reward             | 1.3721007 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 6.43      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 67\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 995416.73\n",
            "total_reward: -4583.27\n",
            "total_cost: 3254176.49\n",
            "total_trades: 6875\n",
            "Sharpe: 0.096\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 6800       |\n",
            "|    time_elapsed       | 109        |\n",
            "|    total_timesteps    | 34000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6799       |\n",
            "|    policy_loss        | -44.3      |\n",
            "|    reward             | -0.7318722 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.8        |\n",
            "--------------------------------------\n",
            "day: 502, episode: 68\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 927157.61\n",
            "total_reward: -72842.39\n",
            "total_cost: 3904492.34\n",
            "total_trades: 7119\n",
            "Sharpe: -0.064\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 6900       |\n",
            "|    time_elapsed       | 110        |\n",
            "|    total_timesteps    | 34500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6899       |\n",
            "|    policy_loss        | 59.2       |\n",
            "|    reward             | -1.6266308 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 2.92       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 69\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1083547.60\n",
            "total_reward: 83547.60\n",
            "total_cost: 2985436.94\n",
            "total_trades: 6973\n",
            "Sharpe: 0.291\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 7000        |\n",
            "|    time_elapsed       | 112         |\n",
            "|    total_timesteps    | 35000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6999        |\n",
            "|    policy_loss        | -195        |\n",
            "|    reward             | -0.89943814 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 40.8        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 70\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1026716.89\n",
            "total_reward: 26716.89\n",
            "total_cost: 2925193.21\n",
            "total_trades: 7076\n",
            "Sharpe: 0.169\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 7100       |\n",
            "|    time_elapsed       | 113        |\n",
            "|    total_timesteps    | 35500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7099       |\n",
            "|    policy_loss        | -82.5      |\n",
            "|    reward             | -0.8736828 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 4.12       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 71\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1113558.03\n",
            "total_reward: 113558.03\n",
            "total_cost: 2030499.57\n",
            "total_trades: 6771\n",
            "Sharpe: 0.362\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 7200       |\n",
            "|    time_elapsed       | 115        |\n",
            "|    total_timesteps    | 36000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7199       |\n",
            "|    policy_loss        | -1.9       |\n",
            "|    reward             | -2.0955079 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 2.67       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 72\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1104536.53\n",
            "total_reward: 104536.53\n",
            "total_cost: 1914513.94\n",
            "total_trades: 6839\n",
            "Sharpe: 0.342\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 7300       |\n",
            "|    time_elapsed       | 116        |\n",
            "|    total_timesteps    | 36500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7299       |\n",
            "|    policy_loss        | -4.07      |\n",
            "|    reward             | -2.2990732 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.3        |\n",
            "--------------------------------------\n",
            "day: 502, episode: 73\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1108827.00\n",
            "total_reward: 108827.00\n",
            "total_cost: 1474536.64\n",
            "total_trades: 6795\n",
            "Sharpe: 0.349\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 7400        |\n",
            "|    time_elapsed       | 118         |\n",
            "|    total_timesteps    | 37000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7399        |\n",
            "|    policy_loss        | -42.7       |\n",
            "|    reward             | 0.042854052 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 2.06        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 74\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1062436.96\n",
            "total_reward: 62436.96\n",
            "total_cost: 1694280.41\n",
            "total_trades: 6965\n",
            "Sharpe: 0.248\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 312       |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 120       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | 129       |\n",
            "|    reward             | 1.9457773 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 13        |\n",
            "-------------------------------------\n",
            "day: 502, episode: 75\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1123413.15\n",
            "total_reward: 123413.15\n",
            "total_cost: 1814227.15\n",
            "total_trades: 6865\n",
            "Sharpe: 0.379\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 7600       |\n",
            "|    time_elapsed       | 121        |\n",
            "|    total_timesteps    | 38000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.2      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7599       |\n",
            "|    policy_loss        | 137        |\n",
            "|    reward             | 0.30035803 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 12         |\n",
            "--------------------------------------\n",
            "day: 502, episode: 76\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1039125.68\n",
            "total_reward: 39125.68\n",
            "total_cost: 2003412.96\n",
            "total_trades: 6635\n",
            "Sharpe: 0.198\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 312       |\n",
            "|    iterations         | 7700      |\n",
            "|    time_elapsed       | 123       |\n",
            "|    total_timesteps    | 38500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7699      |\n",
            "|    policy_loss        | -39.3     |\n",
            "|    reward             | 0.7160809 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 5.18      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 77\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1088497.46\n",
            "total_reward: 88497.46\n",
            "total_cost: 2110029.79\n",
            "total_trades: 6523\n",
            "Sharpe: 0.305\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 7800       |\n",
            "|    time_elapsed       | 124        |\n",
            "|    total_timesteps    | 39000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7799       |\n",
            "|    policy_loss        | -209       |\n",
            "|    reward             | 0.39047006 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 31.5       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 78\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1001871.64\n",
            "total_reward: 1871.64\n",
            "total_cost: 1917595.21\n",
            "total_trades: 6591\n",
            "Sharpe: 0.117\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 312       |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 126       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | -149      |\n",
            "|    reward             | 1.8007746 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 15.8      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 79\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1034758.53\n",
            "total_reward: 34758.53\n",
            "total_cost: 1902394.11\n",
            "total_trades: 6554\n",
            "Sharpe: 0.187\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 127        |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7999       |\n",
            "|    policy_loss        | -84.9      |\n",
            "|    reward             | -1.5317245 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 6.28       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 80\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1047396.73\n",
            "total_reward: 47396.73\n",
            "total_cost: 2018043.28\n",
            "total_trades: 6718\n",
            "Sharpe: 0.216\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 8100       |\n",
            "|    time_elapsed       | 129        |\n",
            "|    total_timesteps    | 40500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.5      |\n",
            "|    explained_variance | -0.0836    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8099       |\n",
            "|    policy_loss        | -78.5      |\n",
            "|    reward             | -1.9462638 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 4.15       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 81\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1028904.23\n",
            "total_reward: 28904.23\n",
            "total_cost: 1955313.43\n",
            "total_trades: 6998\n",
            "Sharpe: 0.174\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 8200        |\n",
            "|    time_elapsed       | 131         |\n",
            "|    total_timesteps    | 41000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8199        |\n",
            "|    policy_loss        | -9.64       |\n",
            "|    reward             | -0.96673673 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.0882      |\n",
            "---------------------------------------\n",
            "day: 502, episode: 82\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1031256.30\n",
            "total_reward: 31256.30\n",
            "total_cost: 1955544.66\n",
            "total_trades: 7214\n",
            "Sharpe: 0.179\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 132        |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.5      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | 74.4       |\n",
            "|    reward             | -3.2516928 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 5.24       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 83\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1035074.17\n",
            "total_reward: 35074.17\n",
            "total_cost: 1833106.36\n",
            "total_trades: 7365\n",
            "Sharpe: 0.188\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 134         |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | 62.1        |\n",
            "|    reward             | -0.20720161 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 4.08        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 84\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1114948.60\n",
            "total_reward: 114948.60\n",
            "total_cost: 2420360.56\n",
            "total_trades: 7486\n",
            "Sharpe: 0.398\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 312       |\n",
            "|    iterations         | 8500      |\n",
            "|    time_elapsed       | 135       |\n",
            "|    total_timesteps    | 42500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.5     |\n",
            "|    explained_variance | -0.000353 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8499      |\n",
            "|    policy_loss        | -127      |\n",
            "|    reward             | 0.4026543 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 9.36      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 85\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1102159.28\n",
            "total_reward: 102159.28\n",
            "total_cost: 2048442.22\n",
            "total_trades: 7370\n",
            "Sharpe: 0.389\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 312       |\n",
            "|    iterations         | 8600      |\n",
            "|    time_elapsed       | 137       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.5     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8599      |\n",
            "|    policy_loss        | 11.6      |\n",
            "|    reward             | 0.7740752 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.121     |\n",
            "-------------------------------------\n",
            "day: 502, episode: 86\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1068548.43\n",
            "total_reward: 68548.43\n",
            "total_cost: 2995586.46\n",
            "total_trades: 7666\n",
            "Sharpe: 0.298\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 8700       |\n",
            "|    time_elapsed       | 139        |\n",
            "|    total_timesteps    | 43500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.5      |\n",
            "|    explained_variance | -2.38e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8699       |\n",
            "|    policy_loss        | 61.3       |\n",
            "|    reward             | -2.7543344 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 3.88       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 87\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1151956.94\n",
            "total_reward: 151956.94\n",
            "total_cost: 3649146.77\n",
            "total_trades: 7674\n",
            "Sharpe: 0.557\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 312       |\n",
            "|    iterations         | 8800      |\n",
            "|    time_elapsed       | 140       |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8799      |\n",
            "|    policy_loss        | 148       |\n",
            "|    reward             | 1.0881904 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 13.8      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 88\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1248978.90\n",
            "total_reward: 248978.90\n",
            "total_cost: 3261545.78\n",
            "total_trades: 7580\n",
            "Sharpe: 0.829\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 8900       |\n",
            "|    time_elapsed       | 142        |\n",
            "|    total_timesteps    | 44500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8899       |\n",
            "|    policy_loss        | -40.4      |\n",
            "|    reward             | 0.66292554 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 3.2        |\n",
            "--------------------------------------\n",
            "day: 502, episode: 89\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1193106.86\n",
            "total_reward: 193106.86\n",
            "total_cost: 3574048.49\n",
            "total_trades: 8049\n",
            "Sharpe: 0.681\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 312       |\n",
            "|    iterations         | 9000      |\n",
            "|    time_elapsed       | 143       |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8999      |\n",
            "|    policy_loss        | -38.2     |\n",
            "|    reward             | 2.1036625 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 1.37      |\n",
            "-------------------------------------\n",
            "day: 502, episode: 90\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1216843.57\n",
            "total_reward: 216843.57\n",
            "total_cost: 4177429.40\n",
            "total_trades: 8141\n",
            "Sharpe: 0.745\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 312       |\n",
            "|    iterations         | 9100      |\n",
            "|    time_elapsed       | 145       |\n",
            "|    total_timesteps    | 45500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.6     |\n",
            "|    explained_variance | -0.0261   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9099      |\n",
            "|    policy_loss        | 1.76      |\n",
            "|    reward             | 0.7775773 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.184     |\n",
            "-------------------------------------\n",
            "day: 502, episode: 91\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1249199.24\n",
            "total_reward: 249199.24\n",
            "total_cost: 3273223.19\n",
            "total_trades: 8198\n",
            "Sharpe: 0.846\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 312       |\n",
            "|    iterations         | 9200      |\n",
            "|    time_elapsed       | 147       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9199      |\n",
            "|    policy_loss        | 53.8      |\n",
            "|    reward             | -2.131491 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 2.2       |\n",
            "-------------------------------------\n",
            "day: 502, episode: 92\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1200762.65\n",
            "total_reward: 200762.65\n",
            "total_cost: 3273885.78\n",
            "total_trades: 8309\n",
            "Sharpe: 0.698\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 9300        |\n",
            "|    time_elapsed       | 148         |\n",
            "|    total_timesteps    | 46500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9299        |\n",
            "|    policy_loss        | -16.3       |\n",
            "|    reward             | -0.07920968 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.286       |\n",
            "---------------------------------------\n",
            "day: 502, episode: 93\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1194990.14\n",
            "total_reward: 194990.14\n",
            "total_cost: 2338790.70\n",
            "total_trades: 8330\n",
            "Sharpe: 0.684\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 9400       |\n",
            "|    time_elapsed       | 150        |\n",
            "|    total_timesteps    | 47000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.7      |\n",
            "|    explained_variance | 7.15e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9399       |\n",
            "|    policy_loss        | 0.0822     |\n",
            "|    reward             | 0.22168343 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.129      |\n",
            "--------------------------------------\n",
            "day: 502, episode: 94\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1245764.90\n",
            "total_reward: 245764.90\n",
            "total_cost: 2565344.92\n",
            "total_trades: 8683\n",
            "Sharpe: 0.842\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 312       |\n",
            "|    iterations         | 9500      |\n",
            "|    time_elapsed       | 151       |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9499      |\n",
            "|    policy_loss        | 3.61      |\n",
            "|    reward             | 0.8282424 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.145     |\n",
            "-------------------------------------\n",
            "day: 502, episode: 95\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1246666.04\n",
            "total_reward: 246666.04\n",
            "total_cost: 2652506.58\n",
            "total_trades: 8744\n",
            "Sharpe: 0.860\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 9600        |\n",
            "|    time_elapsed       | 153         |\n",
            "|    total_timesteps    | 48000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9599        |\n",
            "|    policy_loss        | 35.3        |\n",
            "|    reward             | -0.14767367 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.727       |\n",
            "---------------------------------------\n",
            "day: 502, episode: 96\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1224642.46\n",
            "total_reward: 224642.46\n",
            "total_cost: 3229927.10\n",
            "total_trades: 9053\n",
            "Sharpe: 0.800\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 155        |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | 29.1       |\n",
            "|    reward             | 0.38848346 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.633      |\n",
            "--------------------------------------\n",
            "day: 502, episode: 97\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1254970.29\n",
            "total_reward: 254970.29\n",
            "total_cost: 3740157.51\n",
            "total_trades: 9388\n",
            "Sharpe: 0.902\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 9800       |\n",
            "|    time_elapsed       | 156        |\n",
            "|    total_timesteps    | 49000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9799       |\n",
            "|    policy_loss        | 79.5       |\n",
            "|    reward             | 0.38815954 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 4.78       |\n",
            "--------------------------------------\n",
            "day: 502, episode: 98\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1128463.68\n",
            "total_reward: 128463.68\n",
            "total_cost: 5073514.83\n",
            "total_trades: 9127\n",
            "Sharpe: 0.449\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 158         |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.9       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | 52.9        |\n",
            "|    reward             | -0.09070003 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 2.96        |\n",
            "---------------------------------------\n",
            "day: 502, episode: 99\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1148526.21\n",
            "total_reward: 148526.21\n",
            "total_cost: 3089582.94\n",
            "total_trades: 8062\n",
            "Sharpe: 0.476\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 10000       |\n",
            "|    time_elapsed       | 159         |\n",
            "|    total_timesteps    | 50000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9999        |\n",
            "|    policy_loss        | 90.8        |\n",
            "|    reward             | 0.016723825 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 4.88        |\n",
            "---------------------------------------\n",
            "A2C Validation from 2023-01-03 to 2023-04-04\n",
            "day: 62, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1021803.09\n",
            "total_reward: 21803.09\n",
            "total_cost: 1608353.02\n",
            "total_trades: 994\n",
            "Sharpe: 0.623\n",
            "=================================\n",
            "DDPG Training: \n",
            "Using cuda device\n",
            "day: 502, episode: 101\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1158376.57\n",
            "total_reward: 158376.57\n",
            "total_cost: 10297268.27\n",
            "total_trades: 8486\n",
            "Sharpe: 0.568\n",
            "=================================\n",
            "day: 502, episode: 102\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 103\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 104\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 167        |\n",
            "|    time_elapsed    | 12         |\n",
            "|    total_timesteps | 2012       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 43.6       |\n",
            "|    critic_loss     | 704        |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 1509       |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 105\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 106\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 107\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 108\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 8          |\n",
            "|    fps             | 149        |\n",
            "|    time_elapsed    | 26         |\n",
            "|    total_timesteps | 4024       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 31.5       |\n",
            "|    critic_loss     | 104        |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 3521       |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 109\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 110\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 111\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 112\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 12         |\n",
            "|    fps             | 142        |\n",
            "|    time_elapsed    | 42         |\n",
            "|    total_timesteps | 6036       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 27         |\n",
            "|    critic_loss     | 631        |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 5533       |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 113\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 114\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 115\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 116\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 16         |\n",
            "|    fps             | 140        |\n",
            "|    time_elapsed    | 57         |\n",
            "|    total_timesteps | 8048       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 23.9       |\n",
            "|    critic_loss     | 0.539      |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 7545       |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 117\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 118\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 119\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 120\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 20         |\n",
            "|    fps             | 139        |\n",
            "|    time_elapsed    | 72         |\n",
            "|    total_timesteps | 10060      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 21         |\n",
            "|    critic_loss     | 8.16       |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 9557       |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 121\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 122\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 123\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 124\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 24         |\n",
            "|    fps             | 138        |\n",
            "|    time_elapsed    | 87         |\n",
            "|    total_timesteps | 12072      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 18.4       |\n",
            "|    critic_loss     | 0.358      |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 11569      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 125\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 126\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 127\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 128\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 28         |\n",
            "|    fps             | 137        |\n",
            "|    time_elapsed    | 102        |\n",
            "|    total_timesteps | 14084      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 16.4       |\n",
            "|    critic_loss     | 0.666      |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 13581      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 129\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 130\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 131\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 132\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 32         |\n",
            "|    fps             | 137        |\n",
            "|    time_elapsed    | 117        |\n",
            "|    total_timesteps | 16096      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 14.4       |\n",
            "|    critic_loss     | 0.223      |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 15593      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 133\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 134\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 135\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 136\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 36         |\n",
            "|    fps             | 136        |\n",
            "|    time_elapsed    | 132        |\n",
            "|    total_timesteps | 18108      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 12.4       |\n",
            "|    critic_loss     | 0.137      |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 17605      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 137\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 138\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 139\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 140\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 40         |\n",
            "|    fps             | 136        |\n",
            "|    time_elapsed    | 147        |\n",
            "|    total_timesteps | 20120      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 10.6       |\n",
            "|    critic_loss     | 0.0781     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 19617      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 141\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 142\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 143\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 144\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 44         |\n",
            "|    fps             | 136        |\n",
            "|    time_elapsed    | 162        |\n",
            "|    total_timesteps | 22132      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 9.18       |\n",
            "|    critic_loss     | 0.0389     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 21629      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 145\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 146\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 147\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 148\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 48         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 177        |\n",
            "|    total_timesteps | 24144      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 7.81       |\n",
            "|    critic_loss     | 0.0364     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 23641      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 149\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 150\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 151\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 152\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 52         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 192        |\n",
            "|    total_timesteps | 26156      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 6.68       |\n",
            "|    critic_loss     | 0.042      |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 25653      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 153\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 154\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 155\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 156\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 56         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 207        |\n",
            "|    total_timesteps | 28168      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 5.57       |\n",
            "|    critic_loss     | 0.03       |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 27665      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 157\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 158\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 159\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 160\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 60         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 222        |\n",
            "|    total_timesteps | 30180      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 4.65       |\n",
            "|    critic_loss     | 0.0269     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 29677      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 161\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 162\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 163\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 164\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 64         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 237        |\n",
            "|    total_timesteps | 32192      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 3.81       |\n",
            "|    critic_loss     | 0.028      |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 31689      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 165\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 166\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 167\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 168\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 68         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 252        |\n",
            "|    total_timesteps | 34204      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 3.1        |\n",
            "|    critic_loss     | 0.0684     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 33701      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 169\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 170\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 171\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 172\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 72         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 267        |\n",
            "|    total_timesteps | 36216      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 2.58       |\n",
            "|    critic_loss     | 0.0236     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 35713      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 173\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 174\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 175\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 176\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 76         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 282        |\n",
            "|    total_timesteps | 38228      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 1.99       |\n",
            "|    critic_loss     | 0.0213     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 37725      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 177\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 178\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 179\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 180\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 80         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 297        |\n",
            "|    total_timesteps | 40240      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 1.4        |\n",
            "|    critic_loss     | 0.019      |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 39737      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 181\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 182\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 183\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 184\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 84         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 312        |\n",
            "|    total_timesteps | 42252      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 0.967      |\n",
            "|    critic_loss     | 0.0159     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 41749      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 185\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 186\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 187\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 188\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 88         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 327        |\n",
            "|    total_timesteps | 44264      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 0.577      |\n",
            "|    critic_loss     | 0.0215     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 43761      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 189\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 190\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 191\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 192\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 92         |\n",
            "|    fps             | 135        |\n",
            "|    time_elapsed    | 342        |\n",
            "|    total_timesteps | 46276      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 0.489      |\n",
            "|    critic_loss     | 0.0181     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 45773      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 193\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 194\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 195\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 196\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 96         |\n",
            "|    fps             | 134        |\n",
            "|    time_elapsed    | 357        |\n",
            "|    total_timesteps | 48288      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 0.175      |\n",
            "|    critic_loss     | 0.0164     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 47785      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 197\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 198\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 199\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "day: 502, episode: 200\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178102.17\n",
            "total_reward: 178102.17\n",
            "total_cost: 1063317.27\n",
            "total_trades: 6536\n",
            "Sharpe: 0.646\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 100        |\n",
            "|    fps             | 134        |\n",
            "|    time_elapsed    | 372        |\n",
            "|    total_timesteps | 50300      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -0.0521    |\n",
            "|    critic_loss     | 0.0288     |\n",
            "|    learning_rate   | 0.001      |\n",
            "|    n_updates       | 49797      |\n",
            "|    reward          | -0.3806239 |\n",
            "-----------------------------------\n",
            "DDPG Validation from 2023-01-03 to 2023-04-04\n",
            "day: 62, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 997277.16\n",
            "total_reward: -2722.84\n",
            "total_cost: 1052440.21\n",
            "total_trades: 814\n",
            "Sharpe: -0.022\n",
            "=================================\n",
            "PPO Training: \n",
            "Using cuda device\n",
            "day: 502, episode: 202\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 999497.75\n",
            "total_reward: -502.25\n",
            "total_cost: 57814338.94\n",
            "total_trades: 13206\n",
            "Sharpe: 0.080\n",
            "=================================\n",
            "day: 502, episode: 203\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1062163.02\n",
            "total_reward: 62163.02\n",
            "total_cost: 56563987.95\n",
            "total_trades: 13130\n",
            "Sharpe: 0.264\n",
            "=================================\n",
            "day: 502, episode: 204\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 923697.16\n",
            "total_reward: -76302.84\n",
            "total_cost: 55276728.25\n",
            "total_trades: 13006\n",
            "Sharpe: -0.162\n",
            "=================================\n",
            "day: 502, episode: 205\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 926303.15\n",
            "total_reward: -73696.85\n",
            "total_cost: 54563181.01\n",
            "total_trades: 12999\n",
            "Sharpe: -0.143\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 428        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 4          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | -1.4476448 |\n",
            "-----------------------------------\n",
            "day: 502, episode: 206\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 967259.02\n",
            "total_reward: -32740.98\n",
            "total_cost: 56349100.77\n",
            "total_trades: 13069\n",
            "Sharpe: -0.008\n",
            "=================================\n",
            "day: 502, episode: 207\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1065625.03\n",
            "total_reward: 65625.03\n",
            "total_cost: 56920992.41\n",
            "total_trades: 13066\n",
            "Sharpe: 0.273\n",
            "=================================\n",
            "day: 502, episode: 208\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 931843.80\n",
            "total_reward: -68156.20\n",
            "total_cost: 56775141.29\n",
            "total_trades: 13031\n",
            "Sharpe: -0.126\n",
            "=================================\n",
            "day: 502, episode: 209\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1011450.43\n",
            "total_reward: 11450.43\n",
            "total_cost: 56855876.30\n",
            "total_trades: 13094\n",
            "Sharpe: 0.117\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 397         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016643927 |\n",
            "|    clip_fraction        | 0.206       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.1       |\n",
            "|    explained_variance   | -0.117      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.86        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0384     |\n",
            "|    reward               | -0.36231017 |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 7.43        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 210\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1070802.57\n",
            "total_reward: 70802.57\n",
            "total_cost: 55723876.73\n",
            "total_trades: 12955\n",
            "Sharpe: 0.288\n",
            "=================================\n",
            "day: 502, episode: 211\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1049393.58\n",
            "total_reward: 49393.58\n",
            "total_cost: 57239043.67\n",
            "total_trades: 13080\n",
            "Sharpe: 0.227\n",
            "=================================\n",
            "day: 502, episode: 212\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1023547.05\n",
            "total_reward: 23547.05\n",
            "total_cost: 54822952.99\n",
            "total_trades: 12973\n",
            "Sharpe: 0.153\n",
            "=================================\n",
            "day: 502, episode: 213\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1117482.33\n",
            "total_reward: 117482.33\n",
            "total_cost: 55514857.64\n",
            "total_trades: 12905\n",
            "Sharpe: 0.413\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 387         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014107086 |\n",
            "|    clip_fraction        | 0.161       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.1       |\n",
            "|    explained_variance   | 0.0149      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.7         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0291     |\n",
            "|    reward               | -0.426487   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 7.54        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 214\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 992577.92\n",
            "total_reward: -7422.08\n",
            "total_cost: 55861778.40\n",
            "total_trades: 13035\n",
            "Sharpe: 0.060\n",
            "=================================\n",
            "day: 502, episode: 215\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1009669.00\n",
            "total_reward: 9669.00\n",
            "total_cost: 56411380.62\n",
            "total_trades: 12972\n",
            "Sharpe: 0.111\n",
            "=================================\n",
            "day: 502, episode: 216\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 939518.91\n",
            "total_reward: -60481.09\n",
            "total_cost: 55926916.97\n",
            "total_trades: 12954\n",
            "Sharpe: -0.104\n",
            "=================================\n",
            "day: 502, episode: 217\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1082568.34\n",
            "total_reward: 82568.34\n",
            "total_cost: 57414634.38\n",
            "total_trades: 13071\n",
            "Sharpe: 0.323\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 383         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016630085 |\n",
            "|    clip_fraction        | 0.176       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.0494      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.24        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    reward               | -0.47106075 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 7.85        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 218\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1086522.51\n",
            "total_reward: 86522.51\n",
            "total_cost: 54360385.70\n",
            "total_trades: 13005\n",
            "Sharpe: 0.341\n",
            "=================================\n",
            "day: 502, episode: 219\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 960544.70\n",
            "total_reward: -39455.30\n",
            "total_cost: 54180579.31\n",
            "total_trades: 13019\n",
            "Sharpe: -0.037\n",
            "=================================\n",
            "day: 502, episode: 220\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1109496.96\n",
            "total_reward: 109496.96\n",
            "total_cost: 54942851.67\n",
            "total_trades: 13001\n",
            "Sharpe: 0.397\n",
            "=================================\n",
            "day: 502, episode: 221\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1176620.63\n",
            "total_reward: 176620.63\n",
            "total_cost: 55673387.88\n",
            "total_trades: 12915\n",
            "Sharpe: 0.593\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 380          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 26           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.01806711   |\n",
            "|    clip_fraction        | 0.198        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -41.3        |\n",
            "|    explained_variance   | 0.122        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.17         |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.0301      |\n",
            "|    reward               | -0.069189005 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 5.92         |\n",
            "------------------------------------------\n",
            "day: 502, episode: 222\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1053811.86\n",
            "total_reward: 53811.86\n",
            "total_cost: 55529367.58\n",
            "total_trades: 12995\n",
            "Sharpe: 0.243\n",
            "=================================\n",
            "day: 502, episode: 223\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1106597.03\n",
            "total_reward: 106597.03\n",
            "total_cost: 53475564.63\n",
            "total_trades: 12839\n",
            "Sharpe: 0.397\n",
            "=================================\n",
            "day: 502, episode: 224\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 971118.60\n",
            "total_reward: -28881.40\n",
            "total_cost: 56186807.73\n",
            "total_trades: 13061\n",
            "Sharpe: -0.012\n",
            "=================================\n",
            "day: 502, episode: 225\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1032057.64\n",
            "total_reward: 32057.64\n",
            "total_cost: 55493609.72\n",
            "total_trades: 13021\n",
            "Sharpe: 0.179\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 378         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018652987 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.112       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.79        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0267     |\n",
            "|    reward               | -0.4239348  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.3         |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 226\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1031826.03\n",
            "total_reward: 31826.03\n",
            "total_cost: 57214890.16\n",
            "total_trades: 12999\n",
            "Sharpe: 0.178\n",
            "=================================\n",
            "day: 502, episode: 227\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 895288.20\n",
            "total_reward: -104711.80\n",
            "total_cost: 53690088.25\n",
            "total_trades: 12736\n",
            "Sharpe: -0.224\n",
            "=================================\n",
            "day: 502, episode: 228\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1037715.75\n",
            "total_reward: 37715.75\n",
            "total_cost: 54258452.97\n",
            "total_trades: 12871\n",
            "Sharpe: 0.195\n",
            "=================================\n",
            "day: 502, episode: 229\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 978352.71\n",
            "total_reward: -21647.29\n",
            "total_cost: 55550030.68\n",
            "total_trades: 12995\n",
            "Sharpe: 0.020\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 377         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018359106 |\n",
            "|    clip_fraction        | 0.193       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | 0.158       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.37        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.029      |\n",
            "|    reward               | 0.7147357   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 5.76        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 230\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1147112.56\n",
            "total_reward: 147112.56\n",
            "total_cost: 54556714.63\n",
            "total_trades: 12897\n",
            "Sharpe: 0.502\n",
            "=================================\n",
            "day: 502, episode: 231\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1006892.27\n",
            "total_reward: 6892.27\n",
            "total_cost: 52954863.02\n",
            "total_trades: 12813\n",
            "Sharpe: 0.101\n",
            "=================================\n",
            "day: 502, episode: 232\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 931473.36\n",
            "total_reward: -68526.64\n",
            "total_cost: 54056524.48\n",
            "total_trades: 12900\n",
            "Sharpe: -0.136\n",
            "=================================\n",
            "day: 502, episode: 233\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1091109.70\n",
            "total_reward: 91109.70\n",
            "total_cost: 54475187.30\n",
            "total_trades: 12818\n",
            "Sharpe: 0.354\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 376         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022850769 |\n",
            "|    clip_fraction        | 0.25        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.5       |\n",
            "|    explained_variance   | 0.18        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.76        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0258     |\n",
            "|    reward               | 0.19992445  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 5.46        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 234\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 943861.76\n",
            "total_reward: -56138.24\n",
            "total_cost: 53940693.84\n",
            "total_trades: 12879\n",
            "Sharpe: -0.080\n",
            "=================================\n",
            "day: 502, episode: 235\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1106127.99\n",
            "total_reward: 106127.99\n",
            "total_cost: 52943106.78\n",
            "total_trades: 12880\n",
            "Sharpe: 0.401\n",
            "=================================\n",
            "day: 502, episode: 236\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1096285.18\n",
            "total_reward: 96285.18\n",
            "total_cost: 54598535.26\n",
            "total_trades: 12836\n",
            "Sharpe: 0.357\n",
            "=================================\n",
            "day: 502, episode: 237\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1072186.76\n",
            "total_reward: 72186.76\n",
            "total_cost: 53699435.05\n",
            "total_trades: 12854\n",
            "Sharpe: 0.289\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 375         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 49          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019718328 |\n",
            "|    clip_fraction        | 0.243       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.6       |\n",
            "|    explained_variance   | 0.116       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.21        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0278     |\n",
            "|    reward               | -0.10515117 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 5.97        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 238\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1047297.46\n",
            "total_reward: 47297.46\n",
            "total_cost: 56008747.74\n",
            "total_trades: 13070\n",
            "Sharpe: 0.221\n",
            "=================================\n",
            "day: 502, episode: 239\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 974664.69\n",
            "total_reward: -25335.31\n",
            "total_cost: 54176155.63\n",
            "total_trades: 12893\n",
            "Sharpe: 0.004\n",
            "=================================\n",
            "day: 502, episode: 240\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 989242.54\n",
            "total_reward: -10757.46\n",
            "total_cost: 53489048.97\n",
            "total_trades: 12793\n",
            "Sharpe: 0.050\n",
            "=================================\n",
            "day: 502, episode: 241\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1066970.51\n",
            "total_reward: 66970.51\n",
            "total_cost: 52222764.00\n",
            "total_trades: 12747\n",
            "Sharpe: 0.277\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 55          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020160854 |\n",
            "|    clip_fraction        | 0.268       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.6       |\n",
            "|    explained_variance   | 0.159       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.4         |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0277     |\n",
            "|    reward               | -0.59234864 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 5.75        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 242\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 998378.17\n",
            "total_reward: -1621.83\n",
            "total_cost: 54033943.31\n",
            "total_trades: 12794\n",
            "Sharpe: 0.082\n",
            "=================================\n",
            "day: 502, episode: 243\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1002525.70\n",
            "total_reward: 2525.70\n",
            "total_cost: 52398404.02\n",
            "total_trades: 12627\n",
            "Sharpe: 0.098\n",
            "=================================\n",
            "day: 502, episode: 244\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1014507.43\n",
            "total_reward: 14507.43\n",
            "total_cost: 53573331.37\n",
            "total_trades: 12694\n",
            "Sharpe: 0.128\n",
            "=================================\n",
            "day: 502, episode: 245\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1012247.65\n",
            "total_reward: 12247.65\n",
            "total_cost: 54248184.49\n",
            "total_trades: 12756\n",
            "Sharpe: 0.119\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 60          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021627132 |\n",
            "|    clip_fraction        | 0.243       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.7       |\n",
            "|    explained_variance   | 0.193       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.95        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0222     |\n",
            "|    reward               | -0.58369935 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 5.63        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 246\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 987185.11\n",
            "total_reward: -12814.89\n",
            "total_cost: 53828969.08\n",
            "total_trades: 12709\n",
            "Sharpe: 0.045\n",
            "=================================\n",
            "day: 502, episode: 247\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1047614.07\n",
            "total_reward: 47614.07\n",
            "total_cost: 53822222.18\n",
            "total_trades: 12891\n",
            "Sharpe: 0.224\n",
            "=================================\n",
            "day: 502, episode: 248\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1139384.56\n",
            "total_reward: 139384.56\n",
            "total_cost: 54985958.97\n",
            "total_trades: 12883\n",
            "Sharpe: 0.495\n",
            "=================================\n",
            "day: 502, episode: 249\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1136104.48\n",
            "total_reward: 136104.48\n",
            "total_cost: 53686851.01\n",
            "total_trades: 12778\n",
            "Sharpe: 0.463\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 371        |\n",
            "|    iterations           | 12         |\n",
            "|    time_elapsed         | 66         |\n",
            "|    total_timesteps      | 24576      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02329164 |\n",
            "|    clip_fraction        | 0.216      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.7      |\n",
            "|    explained_variance   | 0.163      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 2.41       |\n",
            "|    n_updates            | 110        |\n",
            "|    policy_gradient_loss | -0.0198    |\n",
            "|    reward               | -1.8076013 |\n",
            "|    std                  | 1.02       |\n",
            "|    value_loss           | 5.89       |\n",
            "----------------------------------------\n",
            "day: 502, episode: 250\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 977782.79\n",
            "total_reward: -22217.21\n",
            "total_cost: 52074896.60\n",
            "total_trades: 12628\n",
            "Sharpe: 0.023\n",
            "=================================\n",
            "day: 502, episode: 251\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1082123.31\n",
            "total_reward: 82123.31\n",
            "total_cost: 52305357.37\n",
            "total_trades: 12732\n",
            "Sharpe: 0.333\n",
            "=================================\n",
            "day: 502, episode: 252\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1010755.78\n",
            "total_reward: 10755.78\n",
            "total_cost: 52323970.16\n",
            "total_trades: 12695\n",
            "Sharpe: 0.115\n",
            "=================================\n",
            "day: 502, episode: 253\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1141647.29\n",
            "total_reward: 141647.29\n",
            "total_cost: 54950907.45\n",
            "total_trades: 12810\n",
            "Sharpe: 0.482\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 71          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020440884 |\n",
            "|    clip_fraction        | 0.239       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.8       |\n",
            "|    explained_variance   | 0.11        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.88        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0198     |\n",
            "|    reward               | 3.1691685   |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 6.36        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 254\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1095810.68\n",
            "total_reward: 95810.68\n",
            "total_cost: 54529951.51\n",
            "total_trades: 12758\n",
            "Sharpe: 0.360\n",
            "=================================\n",
            "day: 502, episode: 255\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 998853.17\n",
            "total_reward: -1146.83\n",
            "total_cost: 55325178.34\n",
            "total_trades: 12896\n",
            "Sharpe: 0.084\n",
            "=================================\n",
            "day: 502, episode: 256\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1095218.69\n",
            "total_reward: 95218.69\n",
            "total_cost: 51608467.05\n",
            "total_trades: 12559\n",
            "Sharpe: 0.357\n",
            "=================================\n",
            "day: 502, episode: 257\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1078273.62\n",
            "total_reward: 78273.62\n",
            "total_cost: 52439550.36\n",
            "total_trades: 12714\n",
            "Sharpe: 0.308\n",
            "=================================\n",
            "day: 502, episode: 258\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 998950.74\n",
            "total_reward: -1049.26\n",
            "total_cost: 50399326.54\n",
            "total_trades: 12630\n",
            "Sharpe: 0.087\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.02385631  |\n",
            "|    clip_fraction        | 0.284       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.9       |\n",
            "|    explained_variance   | 0.151       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.03        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.021      |\n",
            "|    reward               | 0.103695415 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 6.37        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 259\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1041757.57\n",
            "total_reward: 41757.57\n",
            "total_cost: 52126623.90\n",
            "total_trades: 12647\n",
            "Sharpe: 0.205\n",
            "=================================\n",
            "day: 502, episode: 260\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1146236.52\n",
            "total_reward: 146236.52\n",
            "total_cost: 52458804.63\n",
            "total_trades: 12609\n",
            "Sharpe: 0.479\n",
            "=================================\n",
            "day: 502, episode: 261\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 875703.28\n",
            "total_reward: -124296.72\n",
            "total_cost: 52831132.16\n",
            "total_trades: 12694\n",
            "Sharpe: -0.303\n",
            "=================================\n",
            "day: 502, episode: 262\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1022106.44\n",
            "total_reward: 22106.44\n",
            "total_cost: 51708658.12\n",
            "total_trades: 12632\n",
            "Sharpe: 0.149\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 82          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022645254 |\n",
            "|    clip_fraction        | 0.279       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.9       |\n",
            "|    explained_variance   | 0.175       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.22        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0242     |\n",
            "|    reward               | -1.663977   |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 6.06        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 263\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1079125.68\n",
            "total_reward: 79125.68\n",
            "total_cost: 54251406.81\n",
            "total_trades: 12810\n",
            "Sharpe: 0.313\n",
            "=================================\n",
            "day: 502, episode: 264\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1011188.55\n",
            "total_reward: 11188.55\n",
            "total_cost: 52114078.58\n",
            "total_trades: 12559\n",
            "Sharpe: 0.120\n",
            "=================================\n",
            "day: 502, episode: 265\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1079309.98\n",
            "total_reward: 79309.98\n",
            "total_cost: 51331630.54\n",
            "total_trades: 12604\n",
            "Sharpe: 0.315\n",
            "=================================\n",
            "day: 502, episode: 266\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1042948.21\n",
            "total_reward: 42948.21\n",
            "total_cost: 52421010.88\n",
            "total_trades: 12689\n",
            "Sharpe: 0.210\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 88          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019059727 |\n",
            "|    clip_fraction        | 0.223       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42         |\n",
            "|    explained_variance   | 0.269       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.43        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0215     |\n",
            "|    reward               | -1.3248047  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 5.61        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 267\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1131091.22\n",
            "total_reward: 131091.22\n",
            "total_cost: 50951893.73\n",
            "total_trades: 12543\n",
            "Sharpe: 0.438\n",
            "=================================\n",
            "day: 502, episode: 268\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1175838.40\n",
            "total_reward: 175838.40\n",
            "total_cost: 50249892.40\n",
            "total_trades: 12465\n",
            "Sharpe: 0.563\n",
            "=================================\n",
            "day: 502, episode: 269\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1014045.38\n",
            "total_reward: 14045.38\n",
            "total_cost: 50632182.96\n",
            "total_trades: 12483\n",
            "Sharpe: 0.133\n",
            "=================================\n",
            "day: 502, episode: 270\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1060302.89\n",
            "total_reward: 60302.89\n",
            "total_cost: 47607602.87\n",
            "total_trades: 12226\n",
            "Sharpe: 0.252\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 93           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0252388    |\n",
            "|    clip_fraction        | 0.26         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -42          |\n",
            "|    explained_variance   | 0.266        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.71         |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.0152      |\n",
            "|    reward               | -0.047895327 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 6.04         |\n",
            "------------------------------------------\n",
            "day: 502, episode: 271\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1114991.05\n",
            "total_reward: 114991.05\n",
            "total_cost: 54710067.54\n",
            "total_trades: 12878\n",
            "Sharpe: 0.412\n",
            "=================================\n",
            "day: 502, episode: 272\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1065392.07\n",
            "total_reward: 65392.07\n",
            "total_cost: 51069503.81\n",
            "total_trades: 12433\n",
            "Sharpe: 0.267\n",
            "=================================\n",
            "day: 502, episode: 273\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 964584.33\n",
            "total_reward: -35415.67\n",
            "total_cost: 54152835.24\n",
            "total_trades: 12741\n",
            "Sharpe: -0.014\n",
            "=================================\n",
            "day: 502, episode: 274\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1175092.94\n",
            "total_reward: 175092.94\n",
            "total_cost: 53099711.21\n",
            "total_trades: 12747\n",
            "Sharpe: 0.561\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 99          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020314468 |\n",
            "|    clip_fraction        | 0.248       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.1       |\n",
            "|    explained_variance   | 0.305       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.99        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0202     |\n",
            "|    reward               | -0.4109612  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 6.8         |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 275\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1052954.71\n",
            "total_reward: 52954.71\n",
            "total_cost: 50700527.01\n",
            "total_trades: 12561\n",
            "Sharpe: 0.233\n",
            "=================================\n",
            "day: 502, episode: 276\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1122347.08\n",
            "total_reward: 122347.08\n",
            "total_cost: 53039586.64\n",
            "total_trades: 12721\n",
            "Sharpe: 0.419\n",
            "=================================\n",
            "day: 502, episode: 277\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1092461.14\n",
            "total_reward: 92461.14\n",
            "total_cost: 52803647.04\n",
            "total_trades: 12768\n",
            "Sharpe: 0.328\n",
            "=================================\n",
            "day: 502, episode: 278\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1039845.18\n",
            "total_reward: 39845.18\n",
            "total_cost: 52840456.41\n",
            "total_trades: 12671\n",
            "Sharpe: 0.199\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 104         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018617257 |\n",
            "|    clip_fraction        | 0.225       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.1       |\n",
            "|    explained_variance   | 0.277       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.43        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0197     |\n",
            "|    reward               | 1.2204992   |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 6.71        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 279\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1175198.75\n",
            "total_reward: 175198.75\n",
            "total_cost: 51328884.25\n",
            "total_trades: 12565\n",
            "Sharpe: 0.558\n",
            "=================================\n",
            "day: 502, episode: 280\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 990337.93\n",
            "total_reward: -9662.07\n",
            "total_cost: 50821361.03\n",
            "total_trades: 12556\n",
            "Sharpe: 0.062\n",
            "=================================\n",
            "day: 502, episode: 281\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1145806.80\n",
            "total_reward: 145806.80\n",
            "total_cost: 51477027.27\n",
            "total_trades: 12648\n",
            "Sharpe: 0.478\n",
            "=================================\n",
            "day: 502, episode: 282\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1165770.32\n",
            "total_reward: 165770.32\n",
            "total_cost: 52079244.62\n",
            "total_trades: 12674\n",
            "Sharpe: 0.535\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 110         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024942048 |\n",
            "|    clip_fraction        | 0.258       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.1       |\n",
            "|    explained_variance   | 0.285       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.4         |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0124     |\n",
            "|    reward               | -0.37832236 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 7.39        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 283\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1121779.06\n",
            "total_reward: 121779.06\n",
            "total_cost: 52100610.28\n",
            "total_trades: 12698\n",
            "Sharpe: 0.409\n",
            "=================================\n",
            "day: 502, episode: 284\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1026229.54\n",
            "total_reward: 26229.54\n",
            "total_cost: 50579529.39\n",
            "total_trades: 12570\n",
            "Sharpe: 0.163\n",
            "=================================\n",
            "day: 502, episode: 285\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1016161.94\n",
            "total_reward: 16161.94\n",
            "total_cost: 49769144.84\n",
            "total_trades: 12595\n",
            "Sharpe: 0.134\n",
            "=================================\n",
            "day: 502, episode: 286\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1006221.83\n",
            "total_reward: 6221.83\n",
            "total_cost: 52551016.53\n",
            "total_trades: 12716\n",
            "Sharpe: 0.103\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 370        |\n",
            "|    iterations           | 21         |\n",
            "|    time_elapsed         | 115        |\n",
            "|    total_timesteps      | 43008      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02170243 |\n",
            "|    clip_fraction        | 0.25       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -42.2      |\n",
            "|    explained_variance   | 0.35       |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 3.61       |\n",
            "|    n_updates            | 200        |\n",
            "|    policy_gradient_loss | -0.0133    |\n",
            "|    reward               | 1.9422221  |\n",
            "|    std                  | 1.04       |\n",
            "|    value_loss           | 6.38       |\n",
            "----------------------------------------\n",
            "day: 502, episode: 287\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 956713.21\n",
            "total_reward: -43286.79\n",
            "total_cost: 49505146.87\n",
            "total_trades: 12507\n",
            "Sharpe: -0.013\n",
            "=================================\n",
            "day: 502, episode: 288\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1019632.02\n",
            "total_reward: 19632.02\n",
            "total_cost: 51047860.73\n",
            "total_trades: 12483\n",
            "Sharpe: 0.146\n",
            "=================================\n",
            "day: 502, episode: 289\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1074933.35\n",
            "total_reward: 74933.35\n",
            "total_cost: 47152863.90\n",
            "total_trades: 12308\n",
            "Sharpe: 0.279\n",
            "=================================\n",
            "day: 502, episode: 290\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 921770.54\n",
            "total_reward: -78229.46\n",
            "total_cost: 53030089.57\n",
            "total_trades: 12675\n",
            "Sharpe: -0.141\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 121         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025002776 |\n",
            "|    clip_fraction        | 0.268       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.3       |\n",
            "|    explained_variance   | 0.334       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.15        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0239     |\n",
            "|    reward               | 3.2076073   |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 5.93        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 291\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1051836.45\n",
            "total_reward: 51836.45\n",
            "total_cost: 54131183.59\n",
            "total_trades: 12742\n",
            "Sharpe: 0.232\n",
            "=================================\n",
            "day: 502, episode: 292\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1105528.33\n",
            "total_reward: 105528.33\n",
            "total_cost: 52374993.45\n",
            "total_trades: 12760\n",
            "Sharpe: 0.383\n",
            "=================================\n",
            "day: 502, episode: 293\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1045986.80\n",
            "total_reward: 45986.80\n",
            "total_cost: 51240240.17\n",
            "total_trades: 12666\n",
            "Sharpe: 0.215\n",
            "=================================\n",
            "day: 502, episode: 294\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1045334.30\n",
            "total_reward: 45334.30\n",
            "total_cost: 49671780.76\n",
            "total_trades: 12574\n",
            "Sharpe: 0.214\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 127         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020161185 |\n",
            "|    clip_fraction        | 0.217       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.3       |\n",
            "|    explained_variance   | 0.319       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.87        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.0218     |\n",
            "|    reward               | 1.4912238   |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 6.77        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 295\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 986598.98\n",
            "total_reward: -13401.02\n",
            "total_cost: 49497957.15\n",
            "total_trades: 12350\n",
            "Sharpe: 0.047\n",
            "=================================\n",
            "day: 502, episode: 296\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1034392.47\n",
            "total_reward: 34392.47\n",
            "total_cost: 51225290.05\n",
            "total_trades: 12459\n",
            "Sharpe: 0.185\n",
            "=================================\n",
            "day: 502, episode: 297\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1026461.17\n",
            "total_reward: 26461.17\n",
            "total_cost: 54668484.23\n",
            "total_trades: 12754\n",
            "Sharpe: 0.162\n",
            "=================================\n",
            "day: 502, episode: 298\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1024612.51\n",
            "total_reward: 24612.51\n",
            "total_cost: 47986522.17\n",
            "total_trades: 12338\n",
            "Sharpe: 0.158\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 132         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026940167 |\n",
            "|    clip_fraction        | 0.254       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.4       |\n",
            "|    explained_variance   | 0.379       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.14        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    reward               | -2.3985636  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 5.38        |\n",
            "-----------------------------------------\n",
            "day: 502, episode: 299\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1016129.84\n",
            "total_reward: 16129.84\n",
            "total_cost: 49443084.91\n",
            "total_trades: 12326\n",
            "Sharpe: 0.136\n",
            "=================================\n",
            "day: 502, episode: 300\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1041077.49\n",
            "total_reward: 41077.49\n",
            "total_cost: 49291894.67\n",
            "total_trades: 12493\n",
            "Sharpe: 0.201\n",
            "=================================\n",
            "day: 502, episode: 301\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 994553.49\n",
            "total_reward: -5446.51\n",
            "total_cost: 49178688.31\n",
            "total_trades: 12409\n",
            "Sharpe: 0.075\n",
            "=================================\n",
            "day: 502, episode: 302\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1053851.74\n",
            "total_reward: 53851.74\n",
            "total_cost: 50810143.25\n",
            "total_trades: 12415\n",
            "Sharpe: 0.236\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 137         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021969883 |\n",
            "|    clip_fraction        | 0.241       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.5       |\n",
            "|    explained_variance   | 0.44        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.91        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0242     |\n",
            "|    reward               | -1.1018178  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 5.23        |\n",
            "-----------------------------------------\n",
            "PPO Validation from 2023-01-03 to 2023-04-04\n",
            "day: 62, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1011812.27\n",
            "total_reward: 11812.27\n",
            "total_cost: 7554324.91\n",
            "total_trades: 1544\n",
            "Sharpe: 0.424\n",
            "=================================\n",
            "Ensemble Model Training: \n",
            "day: 62, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1057757.87\n",
            "total_reward: 57757.87\n",
            "total_cost: 1698021.72\n",
            "total_trades: 1037\n",
            "Sharpe: 1.840\n",
            "=================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turbulence threshold:  139.63256139475178\n",
            "Model training from: 2021-01-01 to 2023-04-04\n",
            "A2C Training: \n",
            "Using cuda device\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0841    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -53.8      |\n",
            "|    reward             | -1.1451061 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 3.15       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 978460.09\n",
            "total_reward: -21539.91\n",
            "total_cost: 24543454.64\n",
            "total_trades: 11289\n",
            "Sharpe: 0.016\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 3          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0207    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -25.2      |\n",
            "|    reward             | -1.2500705 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.63       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 2\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1229617.34\n",
            "total_reward: 229617.34\n",
            "total_cost: 16557002.52\n",
            "total_trades: 10878\n",
            "Sharpe: 0.676\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -158     |\n",
            "|    reward             | 2.876484 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 15.1     |\n",
            "------------------------------------\n",
            "day: 565, episode: 3\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1209370.21\n",
            "total_reward: 209370.21\n",
            "total_cost: 17485038.06\n",
            "total_trades: 10975\n",
            "Sharpe: 0.652\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 309       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -53.4     |\n",
            "|    reward             | 0.7758305 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.11      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 4\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 992432.87\n",
            "total_reward: -7567.13\n",
            "total_cost: 18462003.25\n",
            "total_trades: 11268\n",
            "Sharpe: 0.057\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.04      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -105       |\n",
            "|    reward             | 0.72031957 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 11         |\n",
            "--------------------------------------\n",
            "day: 565, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1062899.10\n",
            "total_reward: 62899.10\n",
            "total_cost: 28560284.71\n",
            "total_trades: 12028\n",
            "Sharpe: 0.255\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 308        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0071    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -12.6      |\n",
            "|    reward             | -0.9064325 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.533      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 6\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 978928.17\n",
            "total_reward: -21071.83\n",
            "total_cost: 21130068.23\n",
            "total_trades: 11291\n",
            "Sharpe: 0.037\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 308          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.3        |\n",
            "|    explained_variance | -0.671       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | 34.7         |\n",
            "|    reward             | -0.022461489 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.907        |\n",
            "----------------------------------------\n",
            "day: 565, episode: 7\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1037896.08\n",
            "total_reward: 37896.08\n",
            "total_cost: 29144240.46\n",
            "total_trades: 11871\n",
            "Sharpe: 0.183\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 308       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0.0901    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -55.3     |\n",
            "|    reward             | 1.6257786 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.11      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 14         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -0.0476    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 77         |\n",
            "|    reward             | -1.6030159 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 5.43       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 8\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1080395.10\n",
            "total_reward: 80395.10\n",
            "total_cost: 12953001.77\n",
            "total_trades: 10320\n",
            "Sharpe: 0.288\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 16         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -68.1      |\n",
            "|    reward             | 0.84637505 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.3        |\n",
            "--------------------------------------\n",
            "day: 565, episode: 9\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1184859.33\n",
            "total_reward: 184859.33\n",
            "total_cost: 9998974.43\n",
            "total_trades: 10358\n",
            "Sharpe: 0.480\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 309       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -64.3     |\n",
            "|    reward             | 0.314647  |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 8.18      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1180419.84\n",
            "total_reward: 180419.84\n",
            "total_cost: 4582596.85\n",
            "total_trades: 9681\n",
            "Sharpe: 0.470\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -3.58e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -56.9      |\n",
            "|    reward             | -1.5728693 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.28       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 11\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1130442.47\n",
            "total_reward: 130442.47\n",
            "total_cost: 3923954.37\n",
            "total_trades: 9615\n",
            "Sharpe: 0.373\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 309       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0.00452   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -82.5     |\n",
            "|    reward             | 0.5206679 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 6.1       |\n",
            "-------------------------------------\n",
            "day: 565, episode: 12\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1209589.12\n",
            "total_reward: 209589.12\n",
            "total_cost: 4131725.66\n",
            "total_trades: 9372\n",
            "Sharpe: 0.541\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 134       |\n",
            "|    reward             | 0.6987966 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 12.4      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 13\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1121725.68\n",
            "total_reward: 121725.68\n",
            "total_cost: 3440132.19\n",
            "total_trades: 8952\n",
            "Sharpe: 0.361\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 24          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.5       |\n",
            "|    explained_variance | 0.0426      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | -16.5       |\n",
            "|    reward             | -0.49185687 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.206       |\n",
            "---------------------------------------\n",
            "day: 565, episode: 14\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1105209.52\n",
            "total_reward: 105209.52\n",
            "total_cost: 3178640.67\n",
            "total_trades: 8650\n",
            "Sharpe: 0.329\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -0.00612   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 37.8       |\n",
            "|    reward             | 0.30483797 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.14       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1161713.68\n",
            "total_reward: 161713.68\n",
            "total_cost: 2961700.92\n",
            "total_trades: 9134\n",
            "Sharpe: 0.448\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 310          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 27           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | 4.05         |\n",
            "|    reward             | -0.071721755 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.137        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 14.8       |\n",
            "|    reward             | -1.0311197 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.588      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 16\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1150902.45\n",
            "total_reward: 150902.45\n",
            "total_cost: 2720226.98\n",
            "total_trades: 9502\n",
            "Sharpe: 0.418\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 310      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -73.5    |\n",
            "|    reward             | -2.33889 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 3.92     |\n",
            "------------------------------------\n",
            "day: 565, episode: 17\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1144501.90\n",
            "total_reward: 144501.90\n",
            "total_cost: 2645087.81\n",
            "total_trades: 9451\n",
            "Sharpe: 0.410\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 310      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.4    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -33.4    |\n",
            "|    reward             | 0.651285 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 2.08     |\n",
            "------------------------------------\n",
            "day: 565, episode: 18\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1165116.73\n",
            "total_reward: 165116.73\n",
            "total_cost: 2708052.55\n",
            "total_trades: 9351\n",
            "Sharpe: 0.459\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -54.9     |\n",
            "|    reward             | 1.81839   |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.92      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 19\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1238503.22\n",
            "total_reward: 238503.22\n",
            "total_cost: 2374849.18\n",
            "total_trades: 9650\n",
            "Sharpe: 0.674\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 2200        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2199        |\n",
            "|    policy_loss        | 43          |\n",
            "|    reward             | -0.03405382 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.37        |\n",
            "---------------------------------------\n",
            "day: 565, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1182942.54\n",
            "total_reward: 182942.54\n",
            "total_cost: 2423881.91\n",
            "total_trades: 9803\n",
            "Sharpe: 0.540\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 2300       |\n",
            "|    time_elapsed       | 36         |\n",
            "|    total_timesteps    | 11500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2299       |\n",
            "|    policy_loss        | -37.6      |\n",
            "|    reward             | 0.14003547 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.13       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 21\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1183642.25\n",
            "total_reward: 183642.25\n",
            "total_cost: 3905963.86\n",
            "total_trades: 9395\n",
            "Sharpe: 0.531\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.5       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | -24.3       |\n",
            "|    reward             | -0.37872407 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.451       |\n",
            "---------------------------------------\n",
            "day: 565, episode: 22\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1241486.62\n",
            "total_reward: 241486.62\n",
            "total_cost: 3581379.77\n",
            "total_trades: 9214\n",
            "Sharpe: 0.658\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | 50.4      |\n",
            "|    reward             | 0.2716671 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 2.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 2600       |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 13000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0.0527     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2599       |\n",
            "|    policy_loss        | -17.8      |\n",
            "|    reward             | -1.9559076 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.617      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 23\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1192949.20\n",
            "total_reward: 192949.20\n",
            "total_cost: 3209979.44\n",
            "total_trades: 9169\n",
            "Sharpe: 0.567\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 43         |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | 79.4       |\n",
            "|    reward             | -0.5226528 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 4.7        |\n",
            "--------------------------------------\n",
            "day: 565, episode: 24\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1196408.46\n",
            "total_reward: 196408.46\n",
            "total_cost: 2443489.70\n",
            "total_trades: 9038\n",
            "Sharpe: 0.577\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 2800       |\n",
            "|    time_elapsed       | 45         |\n",
            "|    total_timesteps    | 14000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2799       |\n",
            "|    policy_loss        | -94.2      |\n",
            "|    reward             | 0.31537786 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 6.83       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1172552.39\n",
            "total_reward: 172552.39\n",
            "total_cost: 2328107.22\n",
            "total_trades: 9219\n",
            "Sharpe: 0.524\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 14500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0.0151    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | -158      |\n",
            "|    reward             | 0.8865929 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 11.9      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 26\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1147714.33\n",
            "total_reward: 147714.33\n",
            "total_cost: 2286039.53\n",
            "total_trades: 9061\n",
            "Sharpe: 0.459\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 3000       |\n",
            "|    time_elapsed       | 48         |\n",
            "|    total_timesteps    | 15000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2999       |\n",
            "|    policy_loss        | -64.1      |\n",
            "|    reward             | 0.74208766 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 2.66       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 27\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1188920.38\n",
            "total_reward: 188920.38\n",
            "total_cost: 2362428.14\n",
            "total_trades: 9262\n",
            "Sharpe: 0.547\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 49         |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | 17.3       |\n",
            "|    reward             | 0.04424176 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.282      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 28\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1226806.21\n",
            "total_reward: 226806.21\n",
            "total_cost: 2227276.20\n",
            "total_trades: 9535\n",
            "Sharpe: 0.633\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 51        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 8.85      |\n",
            "|    reward             | 0.3007623 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.227     |\n",
            "-------------------------------------\n",
            "day: 565, episode: 29\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1211630.71\n",
            "total_reward: 211630.71\n",
            "total_cost: 2157928.25\n",
            "total_trades: 9421\n",
            "Sharpe: 0.618\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 53         |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | 0.628      |\n",
            "|    reward             | 0.37930503 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.283      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1191136.85\n",
            "total_reward: 191136.85\n",
            "total_cost: 1992275.72\n",
            "total_trades: 9100\n",
            "Sharpe: 0.578\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 311      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 54       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | -38.2    |\n",
            "|    reward             | 1.570633 |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 1.21     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 3500       |\n",
            "|    time_elapsed       | 56         |\n",
            "|    total_timesteps    | 17500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.7      |\n",
            "|    explained_variance | 0.00707    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3499       |\n",
            "|    policy_loss        | -49.8      |\n",
            "|    reward             | 0.31096995 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 4.8        |\n",
            "--------------------------------------\n",
            "day: 565, episode: 31\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1182712.64\n",
            "total_reward: 182712.64\n",
            "total_cost: 2047235.73\n",
            "total_trades: 9013\n",
            "Sharpe: 0.549\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 16.7      |\n",
            "|    reward             | 2.6832476 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.713     |\n",
            "-------------------------------------\n",
            "day: 565, episode: 32\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1186667.83\n",
            "total_reward: 186667.83\n",
            "total_cost: 1805973.80\n",
            "total_trades: 8859\n",
            "Sharpe: 0.549\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 59          |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | -44.2       |\n",
            "|    reward             | -0.37448585 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 1.24        |\n",
            "---------------------------------------\n",
            "day: 565, episode: 33\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1151095.74\n",
            "total_reward: 151095.74\n",
            "total_cost: 1622113.45\n",
            "total_trades: 8976\n",
            "Sharpe: 0.464\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 61        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 38.4      |\n",
            "|    reward             | 1.2101752 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.37      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 34\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1172687.48\n",
            "total_reward: 172687.48\n",
            "total_cost: 1778272.74\n",
            "total_trades: 9377\n",
            "Sharpe: 0.525\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 3900        |\n",
            "|    time_elapsed       | 62          |\n",
            "|    total_timesteps    | 19500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.8       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3899        |\n",
            "|    policy_loss        | 42.9        |\n",
            "|    reward             | -0.92776126 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 1.87        |\n",
            "---------------------------------------\n",
            "day: 565, episode: 35\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1136656.91\n",
            "total_reward: 136656.91\n",
            "total_cost: 1657032.57\n",
            "total_trades: 9548\n",
            "Sharpe: 0.434\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 64        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | -73.7     |\n",
            "|    reward             | 1.1168413 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.27      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 36\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1141139.52\n",
            "total_reward: 141139.52\n",
            "total_cost: 1641527.44\n",
            "total_trades: 9733\n",
            "Sharpe: 0.447\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 65         |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 31.3       |\n",
            "|    reward             | 0.23099087 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.02       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 37\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1154593.66\n",
            "total_reward: 154593.66\n",
            "total_cost: 1846645.08\n",
            "total_trades: 9334\n",
            "Sharpe: 0.477\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 67        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.9     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 3.88      |\n",
            "|    reward             | 0.5189923 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.0279    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 4300       |\n",
            "|    time_elapsed       | 69         |\n",
            "|    total_timesteps    | 21500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4299       |\n",
            "|    policy_loss        | 31.9       |\n",
            "|    reward             | 0.25393146 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.679      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 38\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1168186.62\n",
            "total_reward: 168186.62\n",
            "total_cost: 1744090.40\n",
            "total_trades: 9259\n",
            "Sharpe: 0.510\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 70         |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -39.1      |\n",
            "|    reward             | -1.8791032 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.29       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 39\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1158777.25\n",
            "total_reward: 158777.25\n",
            "total_cost: 1738684.80\n",
            "total_trades: 9394\n",
            "Sharpe: 0.486\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 4500       |\n",
            "|    time_elapsed       | 72         |\n",
            "|    total_timesteps    | 22500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4499       |\n",
            "|    policy_loss        | -44.2      |\n",
            "|    reward             | -3.7656887 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.48       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 40\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1141670.13\n",
            "total_reward: 141670.13\n",
            "total_cost: 1576313.25\n",
            "total_trades: 8943\n",
            "Sharpe: 0.452\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 73         |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | -18.3      |\n",
            "|    reward             | -1.1370428 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.72       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 41\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1165123.20\n",
            "total_reward: 165123.20\n",
            "total_cost: 1921909.29\n",
            "total_trades: 8926\n",
            "Sharpe: 0.505\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 11.2      |\n",
            "|    reward             | 1.4281391 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 4.21      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 42\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1184726.31\n",
            "total_reward: 184726.31\n",
            "total_cost: 1879317.25\n",
            "total_trades: 9044\n",
            "Sharpe: 0.544\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 4800       |\n",
            "|    time_elapsed       | 77         |\n",
            "|    total_timesteps    | 24000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42        |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4799       |\n",
            "|    policy_loss        | -69.1      |\n",
            "|    reward             | 0.13484989 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 3.29       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 43\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1156372.31\n",
            "total_reward: 156372.31\n",
            "total_cost: 1728605.87\n",
            "total_trades: 8835\n",
            "Sharpe: 0.483\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 78          |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | -50.3       |\n",
            "|    reward             | -0.17035314 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 1.62        |\n",
            "---------------------------------------\n",
            "day: 565, episode: 44\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1156298.02\n",
            "total_reward: 156298.02\n",
            "total_cost: 1772706.87\n",
            "total_trades: 8569\n",
            "Sharpe: 0.485\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0.00312    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | -10.7      |\n",
            "|    reward             | 0.17074266 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 3.08       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 45\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1131003.28\n",
            "total_reward: 131003.28\n",
            "total_cost: 1596132.42\n",
            "total_trades: 8444\n",
            "Sharpe: 0.417\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 82        |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | 34.7      |\n",
            "|    reward             | 0.5788322 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.24      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 83         |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | -40.4      |\n",
            "|    reward             | 0.93461573 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.46       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 46\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1157574.02\n",
            "total_reward: 157574.02\n",
            "total_cost: 2066348.00\n",
            "total_trades: 8799\n",
            "Sharpe: 0.485\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 85         |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | 150        |\n",
            "|    reward             | 0.61142075 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 15.7       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 47\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134593.94\n",
            "total_reward: 134593.94\n",
            "total_cost: 1714169.54\n",
            "total_trades: 9038\n",
            "Sharpe: 0.428\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 86         |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 2.38e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -22.6      |\n",
            "|    reward             | 0.20735824 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 2.05       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 48\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1167599.14\n",
            "total_reward: 167599.14\n",
            "total_cost: 2007579.23\n",
            "total_trades: 9375\n",
            "Sharpe: 0.507\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | 42.1      |\n",
            "|    reward             | 2.3825598 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 2.09      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 49\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1128946.58\n",
            "total_reward: 128946.58\n",
            "total_cost: 1902904.66\n",
            "total_trades: 9441\n",
            "Sharpe: 0.416\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 90         |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | -8.72      |\n",
            "|    reward             | 0.21672904 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.108      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 50\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1143515.25\n",
            "total_reward: 143515.25\n",
            "total_cost: 1857505.75\n",
            "total_trades: 9744\n",
            "Sharpe: 0.455\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | -3.26     |\n",
            "|    reward             | 1.2749078 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.69      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 51\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1125061.41\n",
            "total_reward: 125061.41\n",
            "total_cost: 2030651.69\n",
            "total_trades: 9611\n",
            "Sharpe: 0.408\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 5800       |\n",
            "|    time_elapsed       | 93         |\n",
            "|    total_timesteps    | 29000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5799       |\n",
            "|    policy_loss        | 18.9       |\n",
            "|    reward             | -0.3317584 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.294      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 52\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1165189.46\n",
            "total_reward: 165189.46\n",
            "total_cost: 2231678.67\n",
            "total_trades: 9859\n",
            "Sharpe: 0.503\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.2       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | 43.5        |\n",
            "|    reward             | 0.003926494 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 1.68        |\n",
            "---------------------------------------\n",
            "day: 565, episode: 53\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1181320.84\n",
            "total_reward: 181320.84\n",
            "total_cost: 2401117.97\n",
            "total_trades: 10195\n",
            "Sharpe: 0.538\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 6000       |\n",
            "|    time_elapsed       | 96         |\n",
            "|    total_timesteps    | 30000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.2      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5999       |\n",
            "|    policy_loss        | 75.3       |\n",
            "|    reward             | 0.41240135 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 3.8        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 6100        |\n",
            "|    time_elapsed       | 97          |\n",
            "|    total_timesteps    | 30500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6099        |\n",
            "|    policy_loss        | -19.1       |\n",
            "|    reward             | -0.19055137 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.635       |\n",
            "---------------------------------------\n",
            "day: 565, episode: 54\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1133835.87\n",
            "total_reward: 133835.87\n",
            "total_cost: 2755874.95\n",
            "total_trades: 9949\n",
            "Sharpe: 0.426\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 6200        |\n",
            "|    time_elapsed       | 99          |\n",
            "|    total_timesteps    | 31000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6199        |\n",
            "|    policy_loss        | -15.6       |\n",
            "|    reward             | -0.36853603 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.203       |\n",
            "---------------------------------------\n",
            "day: 565, episode: 55\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1251901.06\n",
            "total_reward: 251901.06\n",
            "total_cost: 3306593.27\n",
            "total_trades: 9690\n",
            "Sharpe: 0.727\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 6300      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 31500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.4     |\n",
            "|    explained_variance | -8.34e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6299      |\n",
            "|    policy_loss        | -93.4     |\n",
            "|    reward             | 2.3399081 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 10.6      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 56\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1167570.46\n",
            "total_reward: 167570.46\n",
            "total_cost: 6796862.81\n",
            "total_trades: 10190\n",
            "Sharpe: 0.561\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 6400       |\n",
            "|    time_elapsed       | 102        |\n",
            "|    total_timesteps    | 32000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6399       |\n",
            "|    policy_loss        | -59.2      |\n",
            "|    reward             | 0.34232557 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 3.89       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 57\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1191435.15\n",
            "total_reward: 191435.15\n",
            "total_cost: 5670386.88\n",
            "total_trades: 10044\n",
            "Sharpe: 0.571\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 6500        |\n",
            "|    time_elapsed       | 104         |\n",
            "|    total_timesteps    | 32500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6499        |\n",
            "|    policy_loss        | 109         |\n",
            "|    reward             | -0.17192326 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 7.8         |\n",
            "---------------------------------------\n",
            "day: 565, episode: 58\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1223173.21\n",
            "total_reward: 223173.21\n",
            "total_cost: 5111970.29\n",
            "total_trades: 10165\n",
            "Sharpe: 0.633\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 6600        |\n",
            "|    time_elapsed       | 105         |\n",
            "|    total_timesteps    | 33000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6599        |\n",
            "|    policy_loss        | -11.1       |\n",
            "|    reward             | -0.52646077 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.165       |\n",
            "---------------------------------------\n",
            "day: 565, episode: 59\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1202909.57\n",
            "total_reward: 202909.57\n",
            "total_cost: 3740374.77\n",
            "total_trades: 10045\n",
            "Sharpe: 0.626\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 6700       |\n",
            "|    time_elapsed       | 107        |\n",
            "|    total_timesteps    | 33500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6699       |\n",
            "|    policy_loss        | 12.9       |\n",
            "|    reward             | -0.6869708 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.138      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 60\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1212778.73\n",
            "total_reward: 212778.73\n",
            "total_cost: 2456696.97\n",
            "total_trades: 9952\n",
            "Sharpe: 0.631\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 6800        |\n",
            "|    time_elapsed       | 108         |\n",
            "|    total_timesteps    | 34000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.5       |\n",
            "|    explained_variance | -0.000204   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6799        |\n",
            "|    policy_loss        | 3.93        |\n",
            "|    reward             | -0.37565172 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.523       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 6900        |\n",
            "|    time_elapsed       | 110         |\n",
            "|    total_timesteps    | 34500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6899        |\n",
            "|    policy_loss        | 26.8        |\n",
            "|    reward             | -0.44201478 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.782       |\n",
            "---------------------------------------\n",
            "day: 565, episode: 61\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1212819.92\n",
            "total_reward: 212819.92\n",
            "total_cost: 2652739.59\n",
            "total_trades: 9886\n",
            "Sharpe: 0.628\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 312      |\n",
            "|    iterations         | 7000     |\n",
            "|    time_elapsed       | 112      |\n",
            "|    total_timesteps    | 35000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42.6    |\n",
            "|    explained_variance | -0.00413 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 6999     |\n",
            "|    policy_loss        | -36.9    |\n",
            "|    reward             | 1.552068 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 2.15     |\n",
            "------------------------------------\n",
            "day: 565, episode: 62\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1151340.87\n",
            "total_reward: 151340.87\n",
            "total_cost: 2914059.59\n",
            "total_trades: 9721\n",
            "Sharpe: 0.507\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 7100        |\n",
            "|    time_elapsed       | 113         |\n",
            "|    total_timesteps    | 35500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7099        |\n",
            "|    policy_loss        | 31.5        |\n",
            "|    reward             | -0.31647986 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.608       |\n",
            "---------------------------------------\n",
            "day: 565, episode: 63\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1129060.51\n",
            "total_reward: 129060.51\n",
            "total_cost: 2646113.33\n",
            "total_trades: 9571\n",
            "Sharpe: 0.437\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 7200       |\n",
            "|    time_elapsed       | 115        |\n",
            "|    total_timesteps    | 36000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7199       |\n",
            "|    policy_loss        | -71.6      |\n",
            "|    reward             | 0.33316958 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 4.85       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 64\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1143050.72\n",
            "total_reward: 143050.72\n",
            "total_cost: 2210992.21\n",
            "total_trades: 9625\n",
            "Sharpe: 0.487\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 312         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 116         |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.7       |\n",
            "|    explained_variance | 0.000575    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | 83.8        |\n",
            "|    reward             | -0.32408196 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 4.06        |\n",
            "---------------------------------------\n",
            "day: 565, episode: 65\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1113522.80\n",
            "total_reward: 113522.80\n",
            "total_cost: 2317084.91\n",
            "total_trades: 9509\n",
            "Sharpe: 0.403\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 312        |\n",
            "|    iterations         | 7400       |\n",
            "|    time_elapsed       | 118        |\n",
            "|    total_timesteps    | 37000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.6      |\n",
            "|    explained_variance | -0.00117   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7399       |\n",
            "|    policy_loss        | 69.8       |\n",
            "|    reward             | 0.71731377 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 2.92       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 66\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1189187.88\n",
            "total_reward: 189187.88\n",
            "total_cost: 2167780.17\n",
            "total_trades: 9300\n",
            "Sharpe: 0.599\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 312           |\n",
            "|    iterations         | 7500          |\n",
            "|    time_elapsed       | 120           |\n",
            "|    total_timesteps    | 37500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -42.6         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7499          |\n",
            "|    policy_loss        | 45.2          |\n",
            "|    reward             | -0.0045051347 |\n",
            "|    std                | 1.05          |\n",
            "|    value_loss         | 1.98          |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 67\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1163512.35\n",
            "total_reward: 163512.35\n",
            "total_cost: 2209470.35\n",
            "total_trades: 9416\n",
            "Sharpe: 0.533\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 7600       |\n",
            "|    time_elapsed       | 122        |\n",
            "|    total_timesteps    | 38000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7599       |\n",
            "|    policy_loss        | 78.9       |\n",
            "|    reward             | -0.2610075 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 4.26       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 68\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1182761.13\n",
            "total_reward: 182761.13\n",
            "total_cost: 3545657.65\n",
            "total_trades: 9146\n",
            "Sharpe: 0.596\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 310      |\n",
            "|    iterations         | 7700     |\n",
            "|    time_elapsed       | 124      |\n",
            "|    total_timesteps    | 38500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42.7    |\n",
            "|    explained_variance | 0.364    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7699     |\n",
            "|    policy_loss        | -7.24    |\n",
            "|    reward             | 0.202304 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.0382   |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 7800       |\n",
            "|    time_elapsed       | 125        |\n",
            "|    total_timesteps    | 39000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.7      |\n",
            "|    explained_variance | -8.34e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7799       |\n",
            "|    policy_loss        | -79.3      |\n",
            "|    reward             | -1.0001855 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 3.71       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 69\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1164172.96\n",
            "total_reward: 164172.96\n",
            "total_cost: 2612710.99\n",
            "total_trades: 8549\n",
            "Sharpe: 0.546\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 7900      |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 39500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7899      |\n",
            "|    policy_loss        | 86        |\n",
            "|    reward             | 0.5004387 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 5.16      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 70\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1173866.03\n",
            "total_reward: 173866.03\n",
            "total_cost: 3612866.28\n",
            "total_trades: 8482\n",
            "Sharpe: 0.552\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 8000      |\n",
            "|    time_elapsed       | 128       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7999      |\n",
            "|    policy_loss        | -18.4     |\n",
            "|    reward             | 0.3229339 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.579     |\n",
            "-------------------------------------\n",
            "day: 565, episode: 71\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1267293.88\n",
            "total_reward: 267293.88\n",
            "total_cost: 3688926.57\n",
            "total_trades: 8414\n",
            "Sharpe: 0.757\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 130       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | 59        |\n",
            "|    reward             | 0.5598139 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 1.78      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 72\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1204070.13\n",
            "total_reward: 204070.13\n",
            "total_cost: 2858118.99\n",
            "total_trades: 7874\n",
            "Sharpe: 0.620\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 132        |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | -64        |\n",
            "|    reward             | 0.52781034 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 3.55       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 73\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1189343.12\n",
            "total_reward: 189343.12\n",
            "total_cost: 3127393.69\n",
            "total_trades: 7862\n",
            "Sharpe: 0.597\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 310      |\n",
            "|    iterations         | 8300     |\n",
            "|    time_elapsed       | 133      |\n",
            "|    total_timesteps    | 41500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42.8    |\n",
            "|    explained_variance | 1.79e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 8299     |\n",
            "|    policy_loss        | -9.55    |\n",
            "|    reward             | 2.003876 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.389    |\n",
            "------------------------------------\n",
            "day: 565, episode: 74\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1229114.35\n",
            "total_reward: 229114.35\n",
            "total_cost: 3676101.01\n",
            "total_trades: 7858\n",
            "Sharpe: 0.583\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 8400      |\n",
            "|    time_elapsed       | 135       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8399      |\n",
            "|    policy_loss        | -22.3     |\n",
            "|    reward             | 1.9707589 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.274     |\n",
            "-------------------------------------\n",
            "day: 565, episode: 75\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1250009.85\n",
            "total_reward: 250009.85\n",
            "total_cost: 3548682.77\n",
            "total_trades: 7432\n",
            "Sharpe: 0.635\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 8500        |\n",
            "|    time_elapsed       | 136         |\n",
            "|    total_timesteps    | 42500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8499        |\n",
            "|    policy_loss        | 111         |\n",
            "|    reward             | -0.33278632 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 8.83        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 8600        |\n",
            "|    time_elapsed       | 138         |\n",
            "|    total_timesteps    | 43000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -43         |\n",
            "|    explained_variance | 0.12        |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8599        |\n",
            "|    policy_loss        | 82.7        |\n",
            "|    reward             | -0.55704075 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 4.32        |\n",
            "---------------------------------------\n",
            "day: 565, episode: 76\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1208551.26\n",
            "total_reward: 208551.26\n",
            "total_cost: 3592238.64\n",
            "total_trades: 8307\n",
            "Sharpe: 0.578\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 8700       |\n",
            "|    time_elapsed       | 139        |\n",
            "|    total_timesteps    | 43500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43        |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8699       |\n",
            "|    policy_loss        | 16.5       |\n",
            "|    reward             | -1.4752399 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.947      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 77\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1182501.47\n",
            "total_reward: 182501.47\n",
            "total_cost: 3993852.91\n",
            "total_trades: 8733\n",
            "Sharpe: 0.563\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 141         |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -43.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | -67.9       |\n",
            "|    reward             | -0.89566624 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 3.3         |\n",
            "---------------------------------------\n",
            "day: 565, episode: 78\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1117477.89\n",
            "total_reward: 117477.89\n",
            "total_cost: 3026500.41\n",
            "total_trades: 9115\n",
            "Sharpe: 0.410\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 8900      |\n",
            "|    time_elapsed       | 143       |\n",
            "|    total_timesteps    | 44500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -43.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8899      |\n",
            "|    policy_loss        | -110      |\n",
            "|    reward             | 0.6384046 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 7.68      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 79\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1123967.02\n",
            "total_reward: 123967.02\n",
            "total_cost: 2367395.74\n",
            "total_trades: 8969\n",
            "Sharpe: 0.435\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 144        |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | -137       |\n",
            "|    reward             | -1.3175814 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 10.9       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 80\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1138932.05\n",
            "total_reward: 138932.05\n",
            "total_cost: 2136439.30\n",
            "total_trades: 9148\n",
            "Sharpe: 0.470\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 9100        |\n",
            "|    time_elapsed       | 146         |\n",
            "|    total_timesteps    | 45500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -43.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9099        |\n",
            "|    policy_loss        | -31.2       |\n",
            "|    reward             | -0.39280137 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.537       |\n",
            "---------------------------------------\n",
            "day: 565, episode: 81\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1119952.72\n",
            "total_reward: 119952.72\n",
            "total_cost: 2663666.06\n",
            "total_trades: 8930\n",
            "Sharpe: 0.431\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 9200      |\n",
            "|    time_elapsed       | 147       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -43.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9199      |\n",
            "|    policy_loss        | 12.7      |\n",
            "|    reward             | 0.5216557 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.353     |\n",
            "-------------------------------------\n",
            "day: 565, episode: 82\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1097624.92\n",
            "total_reward: 97624.92\n",
            "total_cost: 2434796.77\n",
            "total_trades: 9133\n",
            "Sharpe: 0.361\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 9300       |\n",
            "|    time_elapsed       | 149        |\n",
            "|    total_timesteps    | 46500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9299       |\n",
            "|    policy_loss        | 79         |\n",
            "|    reward             | -1.3029593 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 4.03       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 83\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1108770.46\n",
            "total_reward: 108770.46\n",
            "total_cost: 2112377.44\n",
            "total_trades: 9257\n",
            "Sharpe: 0.390\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 9400       |\n",
            "|    time_elapsed       | 151        |\n",
            "|    total_timesteps    | 47000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9399       |\n",
            "|    policy_loss        | -48.8      |\n",
            "|    reward             | 0.75516963 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 2.76       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 9500      |\n",
            "|    time_elapsed       | 152       |\n",
            "|    total_timesteps    | 47500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -43.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9499      |\n",
            "|    policy_loss        | -0.213    |\n",
            "|    reward             | 1.4742385 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.624     |\n",
            "-------------------------------------\n",
            "day: 565, episode: 84\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1127263.50\n",
            "total_reward: 127263.50\n",
            "total_cost: 2096621.48\n",
            "total_trades: 8991\n",
            "Sharpe: 0.440\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 9600      |\n",
            "|    time_elapsed       | 154       |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -43.5     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9599      |\n",
            "|    policy_loss        | 88.4      |\n",
            "|    reward             | 0.4898487 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 6.05      |\n",
            "-------------------------------------\n",
            "day: 565, episode: 85\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1144952.28\n",
            "total_reward: 144952.28\n",
            "total_cost: 2523778.95\n",
            "total_trades: 9004\n",
            "Sharpe: 0.490\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 155        |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | 42.8       |\n",
            "|    reward             | 0.19904728 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 1.71       |\n",
            "--------------------------------------\n",
            "day: 565, episode: 86\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1058458.33\n",
            "total_reward: 58458.33\n",
            "total_cost: 2389759.99\n",
            "total_trades: 9285\n",
            "Sharpe: 0.248\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 9800        |\n",
            "|    time_elapsed       | 157         |\n",
            "|    total_timesteps    | 49000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -43.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9799        |\n",
            "|    policy_loss        | 46.3        |\n",
            "|    reward             | -0.93475807 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 2.1         |\n",
            "---------------------------------------\n",
            "day: 565, episode: 87\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1042079.27\n",
            "total_reward: 42079.27\n",
            "total_cost: 2514079.91\n",
            "total_trades: 8948\n",
            "Sharpe: 0.199\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 9900       |\n",
            "|    time_elapsed       | 159        |\n",
            "|    total_timesteps    | 49500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9899       |\n",
            "|    policy_loss        | 35.5       |\n",
            "|    reward             | -0.6931452 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.713      |\n",
            "--------------------------------------\n",
            "day: 565, episode: 88\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1060248.09\n",
            "total_reward: 60248.09\n",
            "total_cost: 2745479.87\n",
            "total_trades: 9215\n",
            "Sharpe: 0.252\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 10000     |\n",
            "|    time_elapsed       | 160       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -43.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9999      |\n",
            "|    policy_loss        | -88.7     |\n",
            "|    reward             | 1.0318872 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 5.51      |\n",
            "-------------------------------------\n",
            "A2C Validation from 2023-04-04 to 2023-07-06\n",
            "day: 62, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1039800.99\n",
            "total_reward: 39800.99\n",
            "total_cost: 1581745.25\n",
            "total_trades: 1100\n",
            "Sharpe: 1.654\n",
            "=================================\n",
            "DDPG Training: \n",
            "Using cuda device\n",
            "day: 565, episode: 90\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1186223.84\n",
            "total_reward: 186223.84\n",
            "total_cost: 11276906.30\n",
            "total_trades: 9819\n",
            "Sharpe: 0.494\n",
            "=================================\n",
            "day: 565, episode: 91\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 92\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 93\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 167       |\n",
            "|    time_elapsed    | 13        |\n",
            "|    total_timesteps | 2264      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.22     |\n",
            "|    critic_loss     | 670       |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 1698      |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 94\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 95\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 96\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 97\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 149       |\n",
            "|    time_elapsed    | 30        |\n",
            "|    total_timesteps | 4528      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -9.71     |\n",
            "|    critic_loss     | 1.29e+03  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 3962      |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 98\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 99\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 100\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 101\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 143       |\n",
            "|    time_elapsed    | 47        |\n",
            "|    total_timesteps | 6792      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -9.29     |\n",
            "|    critic_loss     | 6.52      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 6226      |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 102\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 103\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 104\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 105\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 140       |\n",
            "|    time_elapsed    | 64        |\n",
            "|    total_timesteps | 9056      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -7.78     |\n",
            "|    critic_loss     | 30.8      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 8490      |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 106\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 107\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 108\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 109\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 138       |\n",
            "|    time_elapsed    | 81        |\n",
            "|    total_timesteps | 11320     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -6.87     |\n",
            "|    critic_loss     | 2.87      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 10754     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 110\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 111\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 112\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 113\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 24        |\n",
            "|    fps             | 137       |\n",
            "|    time_elapsed    | 98        |\n",
            "|    total_timesteps | 13584     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -6.31     |\n",
            "|    critic_loss     | 0.151     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 13018     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 114\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 115\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 116\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 117\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 28        |\n",
            "|    fps             | 137       |\n",
            "|    time_elapsed    | 115       |\n",
            "|    total_timesteps | 15848     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -5.71     |\n",
            "|    critic_loss     | 0.105     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 15282     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 118\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 119\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 120\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 121\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 32        |\n",
            "|    fps             | 136       |\n",
            "|    time_elapsed    | 132       |\n",
            "|    total_timesteps | 18112     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -5.13     |\n",
            "|    critic_loss     | 0.15      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 17546     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 122\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 123\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 124\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 125\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 36        |\n",
            "|    fps             | 136       |\n",
            "|    time_elapsed    | 149       |\n",
            "|    total_timesteps | 20376     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -4.65     |\n",
            "|    critic_loss     | 0.072     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 19810     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 126\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 127\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 128\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 129\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 40        |\n",
            "|    fps             | 136       |\n",
            "|    time_elapsed    | 166       |\n",
            "|    total_timesteps | 22640     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -3.83     |\n",
            "|    critic_loss     | 0.243     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 22074     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 130\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 131\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 132\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 133\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 44        |\n",
            "|    fps             | 135       |\n",
            "|    time_elapsed    | 183       |\n",
            "|    total_timesteps | 24904     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -3.39     |\n",
            "|    critic_loss     | 0.226     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 24338     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 134\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 135\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 136\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 137\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 48        |\n",
            "|    fps             | 135       |\n",
            "|    time_elapsed    | 200       |\n",
            "|    total_timesteps | 27168     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -3.13     |\n",
            "|    critic_loss     | 0.211     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 26602     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 138\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 139\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 140\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 141\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 52        |\n",
            "|    fps             | 135       |\n",
            "|    time_elapsed    | 217       |\n",
            "|    total_timesteps | 29432     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.87     |\n",
            "|    critic_loss     | 1.46      |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 28866     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 142\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 143\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 144\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 145\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 56        |\n",
            "|    fps             | 135       |\n",
            "|    time_elapsed    | 234       |\n",
            "|    total_timesteps | 31696     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.59     |\n",
            "|    critic_loss     | 0.174     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 31130     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 146\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 147\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 148\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 149\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 60        |\n",
            "|    fps             | 134       |\n",
            "|    time_elapsed    | 251       |\n",
            "|    total_timesteps | 33960     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.47     |\n",
            "|    critic_loss     | 0.149     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 33394     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 150\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 151\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 152\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 153\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 64        |\n",
            "|    fps             | 134       |\n",
            "|    time_elapsed    | 268       |\n",
            "|    total_timesteps | 36224     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.25     |\n",
            "|    critic_loss     | 0.188     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 35658     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 154\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 155\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 156\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 157\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 68        |\n",
            "|    fps             | 134       |\n",
            "|    time_elapsed    | 285       |\n",
            "|    total_timesteps | 38488     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.11     |\n",
            "|    critic_loss     | 0.132     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 37922     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 158\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 159\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 160\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 161\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 72        |\n",
            "|    fps             | 134       |\n",
            "|    time_elapsed    | 302       |\n",
            "|    total_timesteps | 40752     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.93     |\n",
            "|    critic_loss     | 0.103     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 40186     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 162\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 163\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 164\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 165\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 76        |\n",
            "|    fps             | 134       |\n",
            "|    time_elapsed    | 319       |\n",
            "|    total_timesteps | 43016     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.88     |\n",
            "|    critic_loss     | 0.224     |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 42450     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 166\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 167\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 168\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 169\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 80        |\n",
            "|    fps             | 134       |\n",
            "|    time_elapsed    | 336       |\n",
            "|    total_timesteps | 45280     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.75     |\n",
            "|    critic_loss     | 0.0878    |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 44714     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 170\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 171\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 172\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 173\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 84        |\n",
            "|    fps             | 134       |\n",
            "|    time_elapsed    | 353       |\n",
            "|    total_timesteps | 47544     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.69     |\n",
            "|    critic_loss     | 0.0781    |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 46978     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 174\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 175\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 176\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "day: 565, episode: 177\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 88        |\n",
            "|    fps             | 134       |\n",
            "|    time_elapsed    | 370       |\n",
            "|    total_timesteps | 49808     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.63     |\n",
            "|    critic_loss     | 0.0743    |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 49242     |\n",
            "|    reward          | 0.8012898 |\n",
            "----------------------------------\n",
            "day: 565, episode: 178\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152817.20\n",
            "total_reward: 152817.20\n",
            "total_cost: 1140858.02\n",
            "total_trades: 9056\n",
            "Sharpe: 0.469\n",
            "=================================\n",
            "DDPG Validation from 2023-04-04 to 2023-07-06\n",
            "day: 62, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1042234.39\n",
            "total_reward: 42234.39\n",
            "total_cost: 1134306.22\n",
            "total_trades: 1006\n",
            "Sharpe: 1.614\n",
            "=================================\n",
            "PPO Training: \n",
            "Using cuda device\n",
            "day: 565, episode: 180\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1029206.45\n",
            "total_reward: 29206.45\n",
            "total_cost: 62990571.27\n",
            "total_trades: 14668\n",
            "Sharpe: 0.160\n",
            "=================================\n",
            "day: 565, episode: 181\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1116687.66\n",
            "total_reward: 116687.66\n",
            "total_cost: 63208179.86\n",
            "total_trades: 14729\n",
            "Sharpe: 0.395\n",
            "=================================\n",
            "day: 565, episode: 182\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 965071.17\n",
            "total_reward: -34928.83\n",
            "total_cost: 62279293.53\n",
            "total_trades: 14627\n",
            "Sharpe: -0.010\n",
            "=================================\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    fps             | 418      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 4        |\n",
            "|    total_timesteps | 2048     |\n",
            "| train/             |          |\n",
            "|    reward          | 0.315607 |\n",
            "---------------------------------\n",
            "day: 565, episode: 183\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 983407.84\n",
            "total_reward: -16592.16\n",
            "total_cost: 61964823.63\n",
            "total_trades: 14626\n",
            "Sharpe: 0.037\n",
            "=================================\n",
            "day: 565, episode: 184\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 978392.50\n",
            "total_reward: -21607.50\n",
            "total_cost: 62817479.24\n",
            "total_trades: 14658\n",
            "Sharpe: 0.021\n",
            "=================================\n",
            "day: 565, episode: 185\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1075555.75\n",
            "total_reward: 75555.75\n",
            "total_cost: 61464633.67\n",
            "total_trades: 14594\n",
            "Sharpe: 0.273\n",
            "=================================\n",
            "day: 565, episode: 186\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1043779.46\n",
            "total_reward: 43779.46\n",
            "total_cost: 61918583.51\n",
            "total_trades: 14695\n",
            "Sharpe: 0.197\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 391         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013649116 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.1       |\n",
            "|    explained_variance   | -0.0219     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.3         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.036      |\n",
            "|    reward               | -1.0064874  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 6.57        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 187\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1006418.69\n",
            "total_reward: 6418.69\n",
            "total_cost: 62564705.56\n",
            "total_trades: 14605\n",
            "Sharpe: 0.101\n",
            "=================================\n",
            "day: 565, episode: 188\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1007766.94\n",
            "total_reward: 7766.94\n",
            "total_cost: 59739036.48\n",
            "total_trades: 14415\n",
            "Sharpe: 0.110\n",
            "=================================\n",
            "day: 565, episode: 189\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1119586.53\n",
            "total_reward: 119586.53\n",
            "total_cost: 62772552.14\n",
            "total_trades: 14705\n",
            "Sharpe: 0.396\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 383         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017779995 |\n",
            "|    clip_fraction        | 0.204       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.00658     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.7         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0337     |\n",
            "|    reward               | -1.8561931  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 7.11        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 190\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 993428.09\n",
            "total_reward: -6571.91\n",
            "total_cost: 62691612.72\n",
            "total_trades: 14669\n",
            "Sharpe: 0.067\n",
            "=================================\n",
            "day: 565, episode: 191\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 909383.99\n",
            "total_reward: -90616.01\n",
            "total_cost: 62151389.39\n",
            "total_trades: 14675\n",
            "Sharpe: -0.162\n",
            "=================================\n",
            "day: 565, episode: 192\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 998303.64\n",
            "total_reward: -1696.36\n",
            "total_cost: 59412367.16\n",
            "total_trades: 14402\n",
            "Sharpe: 0.076\n",
            "=================================\n",
            "day: 565, episode: 193\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1085479.05\n",
            "total_reward: 85479.05\n",
            "total_cost: 60793144.01\n",
            "total_trades: 14552\n",
            "Sharpe: 0.301\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 379         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020443197 |\n",
            "|    clip_fraction        | 0.232       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.0314      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.45        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0365     |\n",
            "|    reward               | -0.4376645  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 8.08        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 194\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1010195.78\n",
            "total_reward: 10195.78\n",
            "total_cost: 61985657.99\n",
            "total_trades: 14684\n",
            "Sharpe: 0.109\n",
            "=================================\n",
            "day: 565, episode: 195\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1016546.50\n",
            "total_reward: 16546.50\n",
            "total_cost: 59373340.70\n",
            "total_trades: 14351\n",
            "Sharpe: 0.127\n",
            "=================================\n",
            "day: 565, episode: 196\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1092703.94\n",
            "total_reward: 92703.94\n",
            "total_cost: 60619832.49\n",
            "total_trades: 14488\n",
            "Sharpe: 0.336\n",
            "=================================\n",
            "day: 565, episode: 197\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1145138.97\n",
            "total_reward: 145138.97\n",
            "total_cost: 62693949.13\n",
            "total_trades: 14584\n",
            "Sharpe: 0.463\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 377         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 27          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019818304 |\n",
            "|    clip_fraction        | 0.23        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | 0.0519      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.14        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0258     |\n",
            "|    reward               | 0.02209917  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.18        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 198\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1071325.67\n",
            "total_reward: 71325.67\n",
            "total_cost: 62960372.98\n",
            "total_trades: 14693\n",
            "Sharpe: 0.272\n",
            "=================================\n",
            "day: 565, episode: 199\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1044997.20\n",
            "total_reward: 44997.20\n",
            "total_cost: 59974246.52\n",
            "total_trades: 14548\n",
            "Sharpe: 0.200\n",
            "=================================\n",
            "day: 565, episode: 200\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1042578.20\n",
            "total_reward: 42578.20\n",
            "total_cost: 60251307.39\n",
            "total_trades: 14499\n",
            "Sharpe: 0.194\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 375         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024845172 |\n",
            "|    clip_fraction        | 0.247       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | 0.0648      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.06        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0253     |\n",
            "|    reward               | 0.2537698   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.18        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 201\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1285971.27\n",
            "total_reward: 285971.27\n",
            "total_cost: 62347026.98\n",
            "total_trades: 14650\n",
            "Sharpe: 0.776\n",
            "=================================\n",
            "day: 565, episode: 202\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1012725.51\n",
            "total_reward: 12725.51\n",
            "total_cost: 60080759.23\n",
            "total_trades: 14403\n",
            "Sharpe: 0.117\n",
            "=================================\n",
            "day: 565, episode: 203\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 987384.82\n",
            "total_reward: -12615.18\n",
            "total_cost: 59286373.00\n",
            "total_trades: 14417\n",
            "Sharpe: 0.061\n",
            "=================================\n",
            "day: 565, episode: 204\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 917002.66\n",
            "total_reward: -82997.34\n",
            "total_cost: 59873860.09\n",
            "total_trades: 14382\n",
            "Sharpe: -0.120\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 363        |\n",
            "|    iterations           | 7          |\n",
            "|    time_elapsed         | 39         |\n",
            "|    total_timesteps      | 14336      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02135513 |\n",
            "|    clip_fraction        | 0.251      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.5      |\n",
            "|    explained_variance   | 0.111      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 3.05       |\n",
            "|    n_updates            | 60         |\n",
            "|    policy_gradient_loss | -0.0253    |\n",
            "|    reward               | 0.82602435 |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 6.53       |\n",
            "----------------------------------------\n",
            "day: 565, episode: 205\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1025484.21\n",
            "total_reward: 25484.21\n",
            "total_cost: 59477773.28\n",
            "total_trades: 14484\n",
            "Sharpe: 0.150\n",
            "=================================\n",
            "day: 565, episode: 206\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1002601.45\n",
            "total_reward: 2601.45\n",
            "total_cost: 59838185.58\n",
            "total_trades: 14549\n",
            "Sharpe: 0.091\n",
            "=================================\n",
            "day: 565, episode: 207\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 964405.42\n",
            "total_reward: -35594.58\n",
            "total_cost: 61304739.07\n",
            "total_trades: 14548\n",
            "Sharpe: -0.017\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 44          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021497602 |\n",
            "|    clip_fraction        | 0.262       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.6       |\n",
            "|    explained_variance   | 0.122       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.87        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0261     |\n",
            "|    reward               | -3.296985   |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 6.94        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 208\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1017785.56\n",
            "total_reward: 17785.56\n",
            "total_cost: 61186962.14\n",
            "total_trades: 14530\n",
            "Sharpe: 0.131\n",
            "=================================\n",
            "day: 565, episode: 209\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1016344.10\n",
            "total_reward: 16344.10\n",
            "total_cost: 60750751.29\n",
            "total_trades: 14563\n",
            "Sharpe: 0.124\n",
            "=================================\n",
            "day: 565, episode: 210\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1043651.05\n",
            "total_reward: 43651.05\n",
            "total_cost: 59700599.25\n",
            "total_trades: 14450\n",
            "Sharpe: 0.199\n",
            "=================================\n",
            "day: 565, episode: 211\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1068958.00\n",
            "total_reward: 68958.00\n",
            "total_cost: 61930287.65\n",
            "total_trades: 14577\n",
            "Sharpe: 0.262\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 50          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020944268 |\n",
            "|    clip_fraction        | 0.236       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.6       |\n",
            "|    explained_variance   | 0.201       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.79        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0239     |\n",
            "|    reward               | -2.08046    |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 5.82        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 212\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1060767.32\n",
            "total_reward: 60767.32\n",
            "total_cost: 56422875.59\n",
            "total_trades: 14191\n",
            "Sharpe: 0.244\n",
            "=================================\n",
            "day: 565, episode: 213\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1095715.68\n",
            "total_reward: 95715.68\n",
            "total_cost: 59548125.68\n",
            "total_trades: 14236\n",
            "Sharpe: 0.333\n",
            "=================================\n",
            "day: 565, episode: 214\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1138044.65\n",
            "total_reward: 138044.65\n",
            "total_cost: 64150291.70\n",
            "total_trades: 14677\n",
            "Sharpe: 0.450\n",
            "=================================\n",
            "day: 565, episode: 215\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134401.71\n",
            "total_reward: 134401.71\n",
            "total_cost: 59820819.92\n",
            "total_trades: 14400\n",
            "Sharpe: 0.423\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 55          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021699741 |\n",
            "|    clip_fraction        | 0.252       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.7       |\n",
            "|    explained_variance   | 0.155       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.77        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.022      |\n",
            "|    reward               | -0.4532333  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 5.25        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 216\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 982287.60\n",
            "total_reward: -17712.40\n",
            "total_cost: 60556717.44\n",
            "total_trades: 14415\n",
            "Sharpe: 0.044\n",
            "=================================\n",
            "day: 565, episode: 217\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1047936.48\n",
            "total_reward: 47936.48\n",
            "total_cost: 57684301.42\n",
            "total_trades: 14191\n",
            "Sharpe: 0.208\n",
            "=================================\n",
            "day: 565, episode: 218\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1105849.54\n",
            "total_reward: 105849.54\n",
            "total_cost: 64499445.46\n",
            "total_trades: 14526\n",
            "Sharpe: 0.351\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022194345 |\n",
            "|    clip_fraction        | 0.239       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.8       |\n",
            "|    explained_variance   | 0.171       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.5         |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0263     |\n",
            "|    reward               | 2.4646113   |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 5.2         |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 219\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1050904.01\n",
            "total_reward: 50904.01\n",
            "total_cost: 62071808.48\n",
            "total_trades: 14450\n",
            "Sharpe: 0.220\n",
            "=================================\n",
            "day: 565, episode: 220\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1067585.68\n",
            "total_reward: 67585.68\n",
            "total_cost: 61467656.15\n",
            "total_trades: 14571\n",
            "Sharpe: 0.257\n",
            "=================================\n",
            "day: 565, episode: 221\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1034900.64\n",
            "total_reward: 34900.64\n",
            "total_cost: 57406067.09\n",
            "total_trades: 14225\n",
            "Sharpe: 0.175\n",
            "=================================\n",
            "day: 565, episode: 222\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1035733.28\n",
            "total_reward: 35733.28\n",
            "total_cost: 57988824.35\n",
            "total_trades: 14362\n",
            "Sharpe: 0.177\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 67          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018454328 |\n",
            "|    clip_fraction        | 0.218       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.9       |\n",
            "|    explained_variance   | 0.143       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.17        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0224     |\n",
            "|    reward               | -1.0214573  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 6.46        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 223\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 979119.64\n",
            "total_reward: -20880.36\n",
            "total_cost: 62841777.88\n",
            "total_trades: 14572\n",
            "Sharpe: 0.029\n",
            "=================================\n",
            "day: 565, episode: 224\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 949598.59\n",
            "total_reward: -50401.41\n",
            "total_cost: 59579406.22\n",
            "total_trades: 14337\n",
            "Sharpe: -0.049\n",
            "=================================\n",
            "day: 565, episode: 225\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 954551.40\n",
            "total_reward: -45448.60\n",
            "total_cost: 60238614.20\n",
            "total_trades: 14389\n",
            "Sharpe: -0.044\n",
            "=================================\n",
            "day: 565, episode: 226\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1014624.22\n",
            "total_reward: 14624.22\n",
            "total_cost: 60550993.74\n",
            "total_trades: 14457\n",
            "Sharpe: 0.124\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021194855 |\n",
            "|    clip_fraction        | 0.238       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42         |\n",
            "|    explained_variance   | 0.128       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.71        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0226     |\n",
            "|    reward               | 1.4207395   |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 5.29        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 227\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1044263.79\n",
            "total_reward: 44263.79\n",
            "total_cost: 60684642.70\n",
            "total_trades: 14448\n",
            "Sharpe: 0.199\n",
            "=================================\n",
            "day: 565, episode: 228\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1008027.39\n",
            "total_reward: 8027.39\n",
            "total_cost: 57612798.55\n",
            "total_trades: 14149\n",
            "Sharpe: 0.102\n",
            "=================================\n",
            "day: 565, episode: 229\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 870231.77\n",
            "total_reward: -129768.23\n",
            "total_cost: 57535694.66\n",
            "total_trades: 14181\n",
            "Sharpe: -0.282\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 78          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020578623 |\n",
            "|    clip_fraction        | 0.238       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42         |\n",
            "|    explained_variance   | 0.2         |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.24        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0249     |\n",
            "|    reward               | -0.19808567 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 5.53        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 230\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1049972.98\n",
            "total_reward: 49972.98\n",
            "total_cost: 61843209.87\n",
            "total_trades: 14513\n",
            "Sharpe: 0.214\n",
            "=================================\n",
            "day: 565, episode: 231\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 996933.53\n",
            "total_reward: -3066.47\n",
            "total_cost: 61675984.33\n",
            "total_trades: 14405\n",
            "Sharpe: 0.075\n",
            "=================================\n",
            "day: 565, episode: 232\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1052108.98\n",
            "total_reward: 52108.98\n",
            "total_cost: 61301988.15\n",
            "total_trades: 14381\n",
            "Sharpe: 0.218\n",
            "=================================\n",
            "day: 565, episode: 233\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1047614.77\n",
            "total_reward: 47614.77\n",
            "total_cost: 59116148.21\n",
            "total_trades: 14323\n",
            "Sharpe: 0.207\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 83          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.035781138 |\n",
            "|    clip_fraction        | 0.321       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42         |\n",
            "|    explained_variance   | 0.201       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.59        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0211     |\n",
            "|    reward               | -1.2462975  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 5.5         |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 234\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1084857.03\n",
            "total_reward: 84857.03\n",
            "total_cost: 63491586.59\n",
            "total_trades: 14515\n",
            "Sharpe: 0.295\n",
            "=================================\n",
            "day: 565, episode: 235\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1021004.85\n",
            "total_reward: 21004.85\n",
            "total_cost: 62095081.49\n",
            "total_trades: 14467\n",
            "Sharpe: 0.138\n",
            "=================================\n",
            "day: 565, episode: 236\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 930599.63\n",
            "total_reward: -69400.37\n",
            "total_cost: 62472937.58\n",
            "total_trades: 14435\n",
            "Sharpe: -0.111\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 89          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024231698 |\n",
            "|    clip_fraction        | 0.279       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.1       |\n",
            "|    explained_variance   | 0.16        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.06        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0236     |\n",
            "|    reward               | 2.4988935   |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 6.17        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 237\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1002048.28\n",
            "total_reward: 2048.28\n",
            "total_cost: 61470061.41\n",
            "total_trades: 14458\n",
            "Sharpe: 0.087\n",
            "=================================\n",
            "day: 565, episode: 238\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1073890.94\n",
            "total_reward: 73890.94\n",
            "total_cost: 59630566.84\n",
            "total_trades: 14452\n",
            "Sharpe: 0.271\n",
            "=================================\n",
            "day: 565, episode: 239\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1141531.29\n",
            "total_reward: 141531.29\n",
            "total_cost: 61375772.70\n",
            "total_trades: 14344\n",
            "Sharpe: 0.435\n",
            "=================================\n",
            "day: 565, episode: 240\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 993598.82\n",
            "total_reward: -6401.18\n",
            "total_cost: 59510234.61\n",
            "total_trades: 14355\n",
            "Sharpe: 0.068\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 94          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021030258 |\n",
            "|    clip_fraction        | 0.273       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.2       |\n",
            "|    explained_variance   | 0.231       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.01        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0269     |\n",
            "|    reward               | -0.24728337 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 4.94        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 241\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1012716.34\n",
            "total_reward: 12716.34\n",
            "total_cost: 60800569.09\n",
            "total_trades: 14453\n",
            "Sharpe: 0.120\n",
            "=================================\n",
            "day: 565, episode: 242\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 929662.12\n",
            "total_reward: -70337.88\n",
            "total_cost: 55034438.48\n",
            "total_trades: 13953\n",
            "Sharpe: -0.110\n",
            "=================================\n",
            "day: 565, episode: 243\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1001185.15\n",
            "total_reward: 1185.15\n",
            "total_cost: 58901882.97\n",
            "total_trades: 14267\n",
            "Sharpe: 0.085\n",
            "=================================\n",
            "day: 565, episode: 244\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1079534.11\n",
            "total_reward: 79534.11\n",
            "total_cost: 58944004.69\n",
            "total_trades: 14447\n",
            "Sharpe: 0.292\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026294034 |\n",
            "|    clip_fraction        | 0.289       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.2       |\n",
            "|    explained_variance   | 0.227       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.07        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0202     |\n",
            "|    reward               | 1.1776711   |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 5.34        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 245\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1055375.93\n",
            "total_reward: 55375.93\n",
            "total_cost: 57845343.03\n",
            "total_trades: 14218\n",
            "Sharpe: 0.225\n",
            "=================================\n",
            "day: 565, episode: 246\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1064226.14\n",
            "total_reward: 64226.14\n",
            "total_cost: 60048510.42\n",
            "total_trades: 14454\n",
            "Sharpe: 0.247\n",
            "=================================\n",
            "day: 565, episode: 247\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1049949.37\n",
            "total_reward: 49949.37\n",
            "total_cost: 59864529.18\n",
            "total_trades: 14376\n",
            "Sharpe: 0.213\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 105         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018841444 |\n",
            "|    clip_fraction        | 0.257       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.3       |\n",
            "|    explained_variance   | 0.18        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.14        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0253     |\n",
            "|    reward               | 0.7930287   |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 5.22        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 248\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1059916.02\n",
            "total_reward: 59916.02\n",
            "total_cost: 62575125.03\n",
            "total_trades: 14438\n",
            "Sharpe: 0.245\n",
            "=================================\n",
            "day: 565, episode: 249\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1077207.98\n",
            "total_reward: 77207.98\n",
            "total_cost: 60946707.90\n",
            "total_trades: 14432\n",
            "Sharpe: 0.293\n",
            "=================================\n",
            "day: 565, episode: 250\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1164564.57\n",
            "total_reward: 164564.57\n",
            "total_cost: 59360518.39\n",
            "total_trades: 14261\n",
            "Sharpe: 0.486\n",
            "=================================\n",
            "day: 565, episode: 251\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1078234.21\n",
            "total_reward: 78234.21\n",
            "total_cost: 57167321.35\n",
            "total_trades: 14068\n",
            "Sharpe: 0.277\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 111         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027071338 |\n",
            "|    clip_fraction        | 0.287       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.3       |\n",
            "|    explained_variance   | 0.273       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.54        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0219     |\n",
            "|    reward               | 0.65907896  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 4.55        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 252\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 970912.03\n",
            "total_reward: -29087.97\n",
            "total_cost: 60250581.68\n",
            "total_trades: 14381\n",
            "Sharpe: 0.008\n",
            "=================================\n",
            "day: 565, episode: 253\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134368.09\n",
            "total_reward: 134368.09\n",
            "total_cost: 52590876.16\n",
            "total_trades: 13886\n",
            "Sharpe: 0.429\n",
            "=================================\n",
            "day: 565, episode: 254\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1032636.84\n",
            "total_reward: 32636.84\n",
            "total_cost: 59320162.80\n",
            "total_trades: 14345\n",
            "Sharpe: 0.169\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 116         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024707321 |\n",
            "|    clip_fraction        | 0.279       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.3       |\n",
            "|    explained_variance   | 0.0902      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.58        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.019      |\n",
            "|    reward               | 0.7802155   |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 5.65        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 255\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 932293.24\n",
            "total_reward: -67706.76\n",
            "total_cost: 59203894.27\n",
            "total_trades: 14182\n",
            "Sharpe: -0.091\n",
            "=================================\n",
            "day: 565, episode: 256\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 966228.54\n",
            "total_reward: -33771.46\n",
            "total_cost: 56804428.54\n",
            "total_trades: 13937\n",
            "Sharpe: -0.008\n",
            "=================================\n",
            "day: 565, episode: 257\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1046300.70\n",
            "total_reward: 46300.70\n",
            "total_cost: 59059435.76\n",
            "total_trades: 14117\n",
            "Sharpe: 0.204\n",
            "=================================\n",
            "day: 565, episode: 258\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1026315.62\n",
            "total_reward: 26315.62\n",
            "total_cost: 58821196.98\n",
            "total_trades: 14226\n",
            "Sharpe: 0.152\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 122         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022979202 |\n",
            "|    clip_fraction        | 0.282       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.3       |\n",
            "|    explained_variance   | 0.242       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.23        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0196     |\n",
            "|    reward               | -0.3724126  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 5.95        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 259\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1035796.83\n",
            "total_reward: 35796.83\n",
            "total_cost: 60403945.05\n",
            "total_trades: 14357\n",
            "Sharpe: 0.178\n",
            "=================================\n",
            "day: 565, episode: 260\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1145062.65\n",
            "total_reward: 145062.65\n",
            "total_cost: 50929557.75\n",
            "total_trades: 13646\n",
            "Sharpe: 0.445\n",
            "=================================\n",
            "day: 565, episode: 261\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 882622.72\n",
            "total_reward: -117377.28\n",
            "total_cost: 56698732.03\n",
            "total_trades: 14112\n",
            "Sharpe: -0.208\n",
            "=================================\n",
            "day: 565, episode: 262\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1015149.02\n",
            "total_reward: 15149.02\n",
            "total_cost: 56781559.43\n",
            "total_trades: 14182\n",
            "Sharpe: 0.122\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 368        |\n",
            "|    iterations           | 23         |\n",
            "|    time_elapsed         | 127        |\n",
            "|    total_timesteps      | 47104      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03453822 |\n",
            "|    clip_fraction        | 0.298      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -42.4      |\n",
            "|    explained_variance   | 0.273      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 1.54       |\n",
            "|    n_updates            | 220        |\n",
            "|    policy_gradient_loss | -0.0149    |\n",
            "|    reward               | -0.306357  |\n",
            "|    std                  | 1.04       |\n",
            "|    value_loss           | 5.11       |\n",
            "----------------------------------------\n",
            "day: 565, episode: 263\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1206206.95\n",
            "total_reward: 206206.95\n",
            "total_cost: 60741350.00\n",
            "total_trades: 14211\n",
            "Sharpe: 0.617\n",
            "=================================\n",
            "day: 565, episode: 264\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1012830.36\n",
            "total_reward: 12830.36\n",
            "total_cost: 55880364.77\n",
            "total_trades: 13949\n",
            "Sharpe: 0.115\n",
            "=================================\n",
            "day: 565, episode: 265\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1007624.70\n",
            "total_reward: 7624.70\n",
            "total_cost: 56872663.05\n",
            "total_trades: 14212\n",
            "Sharpe: 0.109\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 133         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.029051993 |\n",
            "|    clip_fraction        | 0.296       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.4       |\n",
            "|    explained_variance   | 0.223       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.82        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0202     |\n",
            "|    reward               | 1.0825787   |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 5.23        |\n",
            "-----------------------------------------\n",
            "day: 565, episode: 266\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1085953.51\n",
            "total_reward: 85953.51\n",
            "total_cost: 55446829.93\n",
            "total_trades: 13914\n",
            "Sharpe: 0.304\n",
            "=================================\n",
            "day: 565, episode: 267\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1211883.96\n",
            "total_reward: 211883.96\n",
            "total_cost: 59833853.33\n",
            "total_trades: 14306\n",
            "Sharpe: 0.619\n",
            "=================================\n",
            "day: 565, episode: 268\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1086303.71\n",
            "total_reward: 86303.71\n",
            "total_cost: 58720602.66\n",
            "total_trades: 14227\n",
            "Sharpe: 0.302\n",
            "=================================\n",
            "day: 565, episode: 269\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1102744.87\n",
            "total_reward: 102744.87\n",
            "total_cost: 51205343.54\n",
            "total_trades: 13673\n",
            "Sharpe: 0.351\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 139         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027276466 |\n",
            "|    clip_fraction        | 0.312       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.5       |\n",
            "|    explained_variance   | 0.286       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.07        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0223     |\n",
            "|    reward               | -0.6096283  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 5.56        |\n",
            "-----------------------------------------\n",
            "PPO Validation from 2023-04-04 to 2023-07-06\n",
            "day: 62, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1016943.32\n",
            "total_reward: 16943.32\n",
            "total_cost: 7416118.62\n",
            "total_trades: 1500\n",
            "Sharpe: 0.671\n",
            "=================================\n",
            "Ensemble Model Training: \n",
            "Turbulence threshold:  139.63256139475178\n",
            "Model training from: 2021-01-01 to 2023-07-06\n",
            "A2C Training: \n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 304        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | -46        |\n",
            "|    reward             | -1.3486509 |\n",
            "|    std                | 0.997      |\n",
            "|    value_loss         | 3.75       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1047006.13\n",
            "total_reward: 47006.13\n",
            "total_cost: 51335761.24\n",
            "total_trades: 14275\n",
            "Sharpe: 0.200\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 306       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -0.107    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -23.6     |\n",
            "|    reward             | 1.7474505 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 2.02      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 2\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1235836.64\n",
            "total_reward: 235836.64\n",
            "total_cost: 24041310.91\n",
            "total_trades: 11779\n",
            "Sharpe: 0.583\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 306        |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.19      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | 63.3       |\n",
            "|    reward             | -3.5676816 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.69       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 3\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1233036.19\n",
            "total_reward: 233036.19\n",
            "total_cost: 18353620.70\n",
            "total_trades: 11331\n",
            "Sharpe: 0.552\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 306        |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0669    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -36.7      |\n",
            "|    reward             | -1.6068106 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.892      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 308       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 80.1      |\n",
            "|    reward             | 0.7898231 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.32      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 4\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1239103.32\n",
            "total_reward: 239103.32\n",
            "total_cost: 9769530.00\n",
            "total_trades: 9406\n",
            "Sharpe: 0.563\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 308        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 27         |\n",
            "|    reward             | -1.4034537 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.877      |\n",
            "--------------------------------------\n",
            "day: 628, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1160149.89\n",
            "total_reward: 160149.89\n",
            "total_cost: 8458399.33\n",
            "total_trades: 9298\n",
            "Sharpe: 0.426\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 308        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.0347     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 13         |\n",
            "|    reward             | -2.3134348 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 12.8       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 6\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1305116.77\n",
            "total_reward: 305116.77\n",
            "total_cost: 7887345.68\n",
            "total_trades: 9046\n",
            "Sharpe: 0.664\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | -14.7    |\n",
            "|    reward             | 0.462448 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.361    |\n",
            "------------------------------------\n",
            "day: 628, episode: 7\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1351105.88\n",
            "total_reward: 351105.88\n",
            "total_cost: 5384707.61\n",
            "total_trades: 8647\n",
            "Sharpe: 0.708\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 308         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 14          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | -0.00554    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -2.45       |\n",
            "|    reward             | -0.07293555 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 1.16        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 309      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 28.5     |\n",
            "|    reward             | 1.531124 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 1.28     |\n",
            "------------------------------------\n",
            "day: 628, episode: 8\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1249265.31\n",
            "total_reward: 249265.31\n",
            "total_cost: 4778979.66\n",
            "total_trades: 8497\n",
            "Sharpe: 0.576\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 309      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -40.9    |\n",
            "|    reward             | 2.398964 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 1.43     |\n",
            "------------------------------------\n",
            "day: 628, episode: 9\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1235804.91\n",
            "total_reward: 235804.91\n",
            "total_cost: 4462384.75\n",
            "total_trades: 8182\n",
            "Sharpe: 0.543\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 19         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -94.3      |\n",
            "|    reward             | 0.08920934 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 6.65       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1261225.00\n",
            "total_reward: 261225.00\n",
            "total_cost: 4323468.74\n",
            "total_trades: 7725\n",
            "Sharpe: 0.599\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 23.3      |\n",
            "|    reward             | 0.4387001 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.821     |\n",
            "-------------------------------------\n",
            "day: 628, episode: 11\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1299040.85\n",
            "total_reward: 299040.85\n",
            "total_cost: 4789262.51\n",
            "total_trades: 7768\n",
            "Sharpe: 0.654\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 2.38e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | 17.4        |\n",
            "|    reward             | -0.80635995 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.305       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 24          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | 0.000337    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 90.1        |\n",
            "|    reward             | -0.03098666 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 5.95        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 12\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1392371.18\n",
            "total_reward: 392371.18\n",
            "total_cost: 5724856.76\n",
            "total_trades: 8600\n",
            "Sharpe: 0.716\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -0.0193    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -107       |\n",
            "|    reward             | -0.9009623 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 10.5       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 13\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1297170.28\n",
            "total_reward: 297170.28\n",
            "total_cost: 14158545.48\n",
            "total_trades: 10572\n",
            "Sharpe: 0.602\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.5       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | -18.1       |\n",
            "|    reward             | -0.22279368 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.399       |\n",
            "---------------------------------------\n",
            "day: 628, episode: 14\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1155964.77\n",
            "total_reward: 155964.77\n",
            "total_cost: 7992338.33\n",
            "total_trades: 10144\n",
            "Sharpe: 0.451\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -44        |\n",
            "|    reward             | -1.6294539 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.87       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1125338.13\n",
            "total_reward: 125338.13\n",
            "total_cost: 8287447.37\n",
            "total_trades: 10018\n",
            "Sharpe: 0.387\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 30        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 14.6      |\n",
            "|    reward             | 0.102092  |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.08      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 92.8       |\n",
            "|    reward             | 0.88829595 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 4.78       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 16\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1121241.12\n",
            "total_reward: 121241.12\n",
            "total_cost: 7609127.34\n",
            "total_trades: 9573\n",
            "Sharpe: 0.357\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 2100        |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 10500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2099        |\n",
            "|    policy_loss        | -49.6       |\n",
            "|    reward             | -0.50260395 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.06        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 17\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1092300.81\n",
            "total_reward: 92300.81\n",
            "total_cost: 5143929.21\n",
            "total_trades: 9753\n",
            "Sharpe: 0.302\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 35         |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 113        |\n",
            "|    reward             | -1.2376125 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 8.03       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 18\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1051512.86\n",
            "total_reward: 51512.86\n",
            "total_cost: 6130460.31\n",
            "total_trades: 10362\n",
            "Sharpe: 0.205\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 2300       |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 11500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2299       |\n",
            "|    policy_loss        | -54.5      |\n",
            "|    reward             | -0.5441397 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.07       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 19\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1103899.71\n",
            "total_reward: 103899.71\n",
            "total_cost: 6095045.85\n",
            "total_trades: 9973\n",
            "Sharpe: 0.331\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 38         |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -0.0293    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | 41.2       |\n",
            "|    reward             | 0.25474504 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.8        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 12500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.6       |\n",
            "|    explained_variance | 0.0767      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | 12.8        |\n",
            "|    reward             | -0.54133403 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.563       |\n",
            "---------------------------------------\n",
            "day: 628, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1124735.61\n",
            "total_reward: 124735.61\n",
            "total_cost: 8540911.95\n",
            "total_trades: 10185\n",
            "Sharpe: 0.380\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 2600       |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 13000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2599       |\n",
            "|    policy_loss        | -122       |\n",
            "|    reward             | -1.3697559 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 10.2       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 21\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1159081.86\n",
            "total_reward: 159081.86\n",
            "total_cost: 6494246.96\n",
            "total_trades: 10016\n",
            "Sharpe: 0.476\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 43        |\n",
            "|    total_timesteps    | 13500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | -149      |\n",
            "|    reward             | -1.370041 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 14.1      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 22\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1130273.18\n",
            "total_reward: 130273.18\n",
            "total_cost: 3982785.76\n",
            "total_trades: 9380\n",
            "Sharpe: 0.354\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 2800        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.6       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2799        |\n",
            "|    policy_loss        | -50.7       |\n",
            "|    reward             | -0.34277403 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 2.26        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 23\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1267185.86\n",
            "total_reward: 267185.86\n",
            "total_cost: 3588545.08\n",
            "total_trades: 9704\n",
            "Sharpe: 0.592\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 46          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | 6.51        |\n",
            "|    reward             | -0.42594177 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.0557      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 48        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | -0.0475   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | -9.05     |\n",
            "|    reward             | 0.5484737 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1         |\n",
            "-------------------------------------\n",
            "day: 628, episode: 24\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1228487.66\n",
            "total_reward: 228487.66\n",
            "total_cost: 3415610.12\n",
            "total_trades: 9303\n",
            "Sharpe: 0.549\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 49         |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.7      |\n",
            "|    explained_variance | -0.00529   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | 8.36       |\n",
            "|    reward             | -1.1830614 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.596      |\n",
            "--------------------------------------\n",
            "day: 628, episode: 25\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1141388.71\n",
            "total_reward: 141388.71\n",
            "total_cost: 2716639.21\n",
            "total_trades: 8974\n",
            "Sharpe: 0.425\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 310           |\n",
            "|    iterations         | 3200          |\n",
            "|    time_elapsed       | 51            |\n",
            "|    total_timesteps    | 16000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -41.7         |\n",
            "|    explained_variance | 0.0278        |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3199          |\n",
            "|    policy_loss        | 141           |\n",
            "|    reward             | -0.0028446745 |\n",
            "|    std                | 1.02          |\n",
            "|    value_loss         | 12.5          |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 26\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1182911.43\n",
            "total_reward: 182911.43\n",
            "total_cost: 3339036.62\n",
            "total_trades: 9092\n",
            "Sharpe: 0.497\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 53        |\n",
            "|    total_timesteps    | 16500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.7     |\n",
            "|    explained_variance | 0.000171  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 13.9      |\n",
            "|    reward             | 1.2645274 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.809     |\n",
            "-------------------------------------\n",
            "day: 628, episode: 27\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1109929.92\n",
            "total_reward: 109929.92\n",
            "total_cost: 9043959.47\n",
            "total_trades: 9439\n",
            "Sharpe: 0.348\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 78.1      |\n",
            "|    reward             | 0.8011745 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 3.51      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 56        |\n",
            "|    total_timesteps    | 17500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | -0.134    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 44.2      |\n",
            "|    reward             | 0.5435258 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.66      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 28\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1271350.91\n",
            "total_reward: 271350.91\n",
            "total_cost: 6837542.97\n",
            "total_trades: 9324\n",
            "Sharpe: 0.606\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 3600        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3599        |\n",
            "|    policy_loss        | -50.5       |\n",
            "|    reward             | -0.14202248 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 1.97        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 29\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1143667.91\n",
            "total_reward: 143667.91\n",
            "total_cost: 11496218.43\n",
            "total_trades: 9951\n",
            "Sharpe: 0.408\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 59        |\n",
            "|    total_timesteps    | 18500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.8     |\n",
            "|    explained_variance | 0.0322    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 11.6      |\n",
            "|    reward             | 0.2953771 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.873     |\n",
            "-------------------------------------\n",
            "day: 628, episode: 30\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1080593.61\n",
            "total_reward: 80593.61\n",
            "total_cost: 9574290.46\n",
            "total_trades: 10272\n",
            "Sharpe: 0.265\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 3800        |\n",
            "|    time_elapsed       | 61          |\n",
            "|    total_timesteps    | 19000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.9       |\n",
            "|    explained_variance | -0.0758     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3799        |\n",
            "|    policy_loss        | -64.7       |\n",
            "|    reward             | -0.09245451 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 2.25        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 31\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1114610.65\n",
            "total_reward: 114610.65\n",
            "total_cost: 7672519.12\n",
            "total_trades: 10054\n",
            "Sharpe: 0.331\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 62         |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | 106        |\n",
            "|    reward             | 0.13988511 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 5.3        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 64        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42       |\n",
            "|    explained_variance | -0.0371   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | -4.21     |\n",
            "|    reward             | 0.9468339 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 8.45      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 32\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1175190.84\n",
            "total_reward: 175190.84\n",
            "total_cost: 12906182.85\n",
            "total_trades: 10744\n",
            "Sharpe: 0.473\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 65         |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | -36.6      |\n",
            "|    reward             | 0.14462927 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 1.29       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 33\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1096557.10\n",
            "total_reward: 96557.10\n",
            "total_cost: 11301173.42\n",
            "total_trades: 10379\n",
            "Sharpe: 0.318\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 67          |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | -15.6       |\n",
            "|    reward             | -0.75840545 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.664       |\n",
            "---------------------------------------\n",
            "day: 628, episode: 34\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 914262.92\n",
            "total_reward: -85737.08\n",
            "total_cost: 12184604.37\n",
            "total_trades: 10605\n",
            "Sharpe: -0.141\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 69          |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42         |\n",
            "|    explained_variance | 0.0913      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | 29.4        |\n",
            "|    reward             | -0.13109195 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.534       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 70         |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | -0.338     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | 23.1       |\n",
            "|    reward             | 0.36642522 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.618      |\n",
            "--------------------------------------\n",
            "day: 628, episode: 35\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1015426.41\n",
            "total_reward: 15426.41\n",
            "total_cost: 10115979.32\n",
            "total_trades: 10434\n",
            "Sharpe: 0.113\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 4500       |\n",
            "|    time_elapsed       | 72         |\n",
            "|    total_timesteps    | 22500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4499       |\n",
            "|    policy_loss        | -11.1      |\n",
            "|    reward             | -1.4801443 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.618      |\n",
            "--------------------------------------\n",
            "day: 628, episode: 36\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 998701.54\n",
            "total_reward: -1298.46\n",
            "total_cost: 7226718.98\n",
            "total_trades: 10049\n",
            "Sharpe: 0.087\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 74        |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 46.4      |\n",
            "|    reward             | 1.8851722 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 1.99      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 37\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1044519.48\n",
            "total_reward: 44519.48\n",
            "total_cost: 6084037.91\n",
            "total_trades: 9875\n",
            "Sharpe: 0.188\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 75         |\n",
            "|    total_timesteps    | 23500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4699       |\n",
            "|    policy_loss        | 7.55       |\n",
            "|    reward             | -3.0488858 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.865      |\n",
            "--------------------------------------\n",
            "day: 628, episode: 38\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1028063.72\n",
            "total_reward: 28063.72\n",
            "total_cost: 7211680.25\n",
            "total_trades: 10526\n",
            "Sharpe: 0.158\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 77        |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | 48.8      |\n",
            "|    reward             | 0.3274321 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 2.06      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 310          |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 78           |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -42.2        |\n",
            "|    explained_variance | -0.675       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | -25.6        |\n",
            "|    reward             | -0.102087826 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.471        |\n",
            "----------------------------------------\n",
            "day: 628, episode: 39\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1081147.84\n",
            "total_reward: 81147.84\n",
            "total_cost: 5205858.62\n",
            "total_trades: 9683\n",
            "Sharpe: 0.286\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | -38.8      |\n",
            "|    reward             | -2.7999935 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 1.84       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 40\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1153871.91\n",
            "total_reward: 153871.91\n",
            "total_cost: 4675984.83\n",
            "total_trades: 9948\n",
            "Sharpe: 0.477\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 5100        |\n",
            "|    time_elapsed       | 82          |\n",
            "|    total_timesteps    | 25500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5099        |\n",
            "|    policy_loss        | -77.3       |\n",
            "|    reward             | -0.92160267 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 4.53        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 41\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1137307.57\n",
            "total_reward: 137307.57\n",
            "total_cost: 3542136.57\n",
            "total_trades: 9919\n",
            "Sharpe: 0.428\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 5200        |\n",
            "|    time_elapsed       | 83          |\n",
            "|    total_timesteps    | 26000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.4       |\n",
            "|    explained_variance | 0.0365      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5199        |\n",
            "|    policy_loss        | -10.6       |\n",
            "|    reward             | 0.088356316 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.508       |\n",
            "---------------------------------------\n",
            "day: 628, episode: 42\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1051090.93\n",
            "total_reward: 51090.93\n",
            "total_cost: 2798040.88\n",
            "total_trades: 9738\n",
            "Sharpe: 0.207\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 5300      |\n",
            "|    time_elapsed       | 85        |\n",
            "|    total_timesteps    | 26500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.4     |\n",
            "|    explained_variance | -0.0205   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5299      |\n",
            "|    policy_loss        | 22.4      |\n",
            "|    reward             | 0.7014557 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.566     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 5400      |\n",
            "|    time_elapsed       | 86        |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5399      |\n",
            "|    policy_loss        | 6.56      |\n",
            "|    reward             | 0.8665316 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.31      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 43\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1129117.06\n",
            "total_reward: 129117.06\n",
            "total_cost: 2799257.21\n",
            "total_trades: 9664\n",
            "Sharpe: 0.402\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 88         |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | 54.4       |\n",
            "|    reward             | 0.91823924 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 2.42       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 44\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1132308.53\n",
            "total_reward: 132308.53\n",
            "total_cost: 2384777.88\n",
            "total_trades: 9384\n",
            "Sharpe: 0.407\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 5600        |\n",
            "|    time_elapsed       | 90          |\n",
            "|    total_timesteps    | 28000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5599        |\n",
            "|    policy_loss        | 39.7        |\n",
            "|    reward             | -0.42115036 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 1.01        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 45\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1161114.95\n",
            "total_reward: 161114.95\n",
            "total_cost: 2710220.07\n",
            "total_trades: 9585\n",
            "Sharpe: 0.466\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 91         |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.5      |\n",
            "|    explained_variance | 0.00987    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5699       |\n",
            "|    policy_loss        | -10.9      |\n",
            "|    reward             | 0.53516847 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.56       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 46\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1056626.73\n",
            "total_reward: 56626.73\n",
            "total_cost: 2078665.85\n",
            "total_trades: 9270\n",
            "Sharpe: 0.215\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 5800       |\n",
            "|    time_elapsed       | 93         |\n",
            "|    total_timesteps    | 29000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5799       |\n",
            "|    policy_loss        | 3.95       |\n",
            "|    reward             | 0.34320885 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.288      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.5       |\n",
            "|    explained_variance | 0.0409      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | 22.6        |\n",
            "|    reward             | -0.29681984 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.878       |\n",
            "---------------------------------------\n",
            "day: 628, episode: 47\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1086876.52\n",
            "total_reward: 86876.52\n",
            "total_cost: 2332566.08\n",
            "total_trades: 9122\n",
            "Sharpe: 0.291\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 310       |\n",
            "|    iterations         | 6000      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5999      |\n",
            "|    policy_loss        | -67       |\n",
            "|    reward             | 1.7160616 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 2.79      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 48\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1123238.86\n",
            "total_reward: 123238.86\n",
            "total_cost: 2069138.67\n",
            "total_trades: 9187\n",
            "Sharpe: 0.384\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.5      |\n",
            "|    explained_variance | 0.11       |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | 106        |\n",
            "|    reward             | 0.59131974 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 7.36       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 49\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1155235.29\n",
            "total_reward: 155235.29\n",
            "total_cost: 2170656.26\n",
            "total_trades: 8774\n",
            "Sharpe: 0.465\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 310        |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 99         |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | -75.9      |\n",
            "|    reward             | -1.6419274 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 4.28       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 50\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1094398.05\n",
            "total_reward: 94398.05\n",
            "total_cost: 2248226.01\n",
            "total_trades: 9284\n",
            "Sharpe: 0.317\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 310          |\n",
            "|    iterations         | 6300         |\n",
            "|    time_elapsed       | 101          |\n",
            "|    total_timesteps    | 31500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -42.7        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6299         |\n",
            "|    policy_loss        | 122          |\n",
            "|    reward             | -0.114696786 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 8.37         |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 6400        |\n",
            "|    time_elapsed       | 102         |\n",
            "|    total_timesteps    | 32000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6399        |\n",
            "|    policy_loss        | 41.9        |\n",
            "|    reward             | -0.48250315 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 1.56        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 51\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1076362.25\n",
            "total_reward: 76362.25\n",
            "total_cost: 2272711.30\n",
            "total_trades: 9110\n",
            "Sharpe: 0.267\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 6500        |\n",
            "|    time_elapsed       | 104         |\n",
            "|    total_timesteps    | 32500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6499        |\n",
            "|    policy_loss        | -106        |\n",
            "|    reward             | -0.34236857 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 6.71        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 52\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1047902.69\n",
            "total_reward: 47902.69\n",
            "total_cost: 2462288.67\n",
            "total_trades: 8578\n",
            "Sharpe: 0.200\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 6600      |\n",
            "|    time_elapsed       | 106       |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6599      |\n",
            "|    policy_loss        | -124      |\n",
            "|    reward             | 1.4283026 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 10.5      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 53\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1084959.50\n",
            "total_reward: 84959.50\n",
            "total_cost: 2197605.58\n",
            "total_trades: 8367\n",
            "Sharpe: 0.288\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 6700        |\n",
            "|    time_elapsed       | 107         |\n",
            "|    total_timesteps    | 33500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6699        |\n",
            "|    policy_loss        | -45.9       |\n",
            "|    reward             | -0.50368136 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 1.36        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 54\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1140859.89\n",
            "total_reward: 140859.89\n",
            "total_cost: 2423881.58\n",
            "total_trades: 8726\n",
            "Sharpe: 0.421\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 310         |\n",
            "|    iterations         | 6800        |\n",
            "|    time_elapsed       | 109         |\n",
            "|    total_timesteps    | 34000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.8       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6799        |\n",
            "|    policy_loss        | 42.1        |\n",
            "|    reward             | -0.45973864 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 1.07        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 6900       |\n",
            "|    time_elapsed       | 110        |\n",
            "|    total_timesteps    | 34500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6899       |\n",
            "|    policy_loss        | -38.1      |\n",
            "|    reward             | -1.2529122 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.915      |\n",
            "--------------------------------------\n",
            "day: 628, episode: 55\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1129820.81\n",
            "total_reward: 129820.81\n",
            "total_cost: 2228472.87\n",
            "total_trades: 8793\n",
            "Sharpe: 0.397\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 112       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.9     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | -48.8     |\n",
            "|    reward             | 1.2873045 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 2.48      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 56\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1167306.06\n",
            "total_reward: 167306.06\n",
            "total_cost: 2008328.50\n",
            "total_trades: 8825\n",
            "Sharpe: 0.475\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 311      |\n",
            "|    iterations         | 7100     |\n",
            "|    time_elapsed       | 114      |\n",
            "|    total_timesteps    | 35500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -42.9    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 7099     |\n",
            "|    policy_loss        | 74.8     |\n",
            "|    reward             | -0.41086 |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 3.35     |\n",
            "------------------------------------\n",
            "day: 628, episode: 57\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1175920.64\n",
            "total_reward: 175920.64\n",
            "total_cost: 2182005.38\n",
            "total_trades: 8929\n",
            "Sharpe: 0.504\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 115         |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | 0.847       |\n",
            "|    reward             | -0.60277295 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.198       |\n",
            "---------------------------------------\n",
            "day: 628, episode: 58\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1147495.33\n",
            "total_reward: 147495.33\n",
            "total_cost: 1988197.83\n",
            "total_trades: 8835\n",
            "Sharpe: 0.428\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 7300       |\n",
            "|    time_elapsed       | 117        |\n",
            "|    total_timesteps    | 36500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -42.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7299       |\n",
            "|    policy_loss        | -49.3      |\n",
            "|    reward             | -1.7264732 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 1.5        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 7400        |\n",
            "|    time_elapsed       | 118         |\n",
            "|    total_timesteps    | 37000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.8       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7399        |\n",
            "|    policy_loss        | -131        |\n",
            "|    reward             | 0.022380808 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 11.1        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 59\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1143184.57\n",
            "total_reward: 143184.57\n",
            "total_cost: 1717905.86\n",
            "total_trades: 8440\n",
            "Sharpe: 0.422\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 7500      |\n",
            "|    time_elapsed       | 120       |\n",
            "|    total_timesteps    | 37500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -42.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 7499      |\n",
            "|    policy_loss        | -57.5     |\n",
            "|    reward             | 1.0890225 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 2.58      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 60\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1123676.54\n",
            "total_reward: 123676.54\n",
            "total_cost: 1529878.55\n",
            "total_trades: 8211\n",
            "Sharpe: 0.367\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 7600        |\n",
            "|    time_elapsed       | 122         |\n",
            "|    total_timesteps    | 38000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7599        |\n",
            "|    policy_loss        | -46.2       |\n",
            "|    reward             | -0.24680367 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 1.7         |\n",
            "---------------------------------------\n",
            "day: 628, episode: 61\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1138288.73\n",
            "total_reward: 138288.73\n",
            "total_cost: 1500942.73\n",
            "total_trades: 8096\n",
            "Sharpe: 0.408\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 7700        |\n",
            "|    time_elapsed       | 123         |\n",
            "|    total_timesteps    | 38500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -42.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7699        |\n",
            "|    policy_loss        | 7.29        |\n",
            "|    reward             | -0.16306524 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.379       |\n",
            "---------------------------------------\n",
            "day: 628, episode: 62\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1142039.54\n",
            "total_reward: 142039.54\n",
            "total_cost: 1469089.23\n",
            "total_trades: 8134\n",
            "Sharpe: 0.418\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 7800       |\n",
            "|    time_elapsed       | 125        |\n",
            "|    total_timesteps    | 39000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7799       |\n",
            "|    policy_loss        | 73.9       |\n",
            "|    reward             | 0.56129664 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 3.4        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 7900        |\n",
            "|    time_elapsed       | 126         |\n",
            "|    total_timesteps    | 39500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -43         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7899        |\n",
            "|    policy_loss        | 28.3        |\n",
            "|    reward             | -0.19931987 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 1.34        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 63\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1154728.16\n",
            "total_reward: 154728.16\n",
            "total_cost: 1456944.84\n",
            "total_trades: 8971\n",
            "Sharpe: 0.449\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 128        |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7999       |\n",
            "|    policy_loss        | 36.8       |\n",
            "|    reward             | -1.7634028 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 1.34       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 64\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1139246.44\n",
            "total_reward: 139246.44\n",
            "total_cost: 1518832.97\n",
            "total_trades: 9222\n",
            "Sharpe: 0.409\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 8100      |\n",
            "|    time_elapsed       | 130       |\n",
            "|    total_timesteps    | 40500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -43.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8099      |\n",
            "|    policy_loss        | 26.2      |\n",
            "|    reward             | 1.8247902 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.541     |\n",
            "-------------------------------------\n",
            "day: 628, episode: 65\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1148791.23\n",
            "total_reward: 148791.23\n",
            "total_cost: 1433195.08\n",
            "total_trades: 9058\n",
            "Sharpe: 0.424\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 131        |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.1      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | -58.7      |\n",
            "|    reward             | -1.7018923 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 2.47       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 133        |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | 106        |\n",
            "|    reward             | 0.59244025 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 7.29       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 66\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1136796.96\n",
            "total_reward: 136796.96\n",
            "total_cost: 1499984.55\n",
            "total_trades: 9179\n",
            "Sharpe: 0.399\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 134         |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -43.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | 35.9        |\n",
            "|    reward             | -0.43050832 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.829       |\n",
            "---------------------------------------\n",
            "day: 628, episode: 67\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1110718.79\n",
            "total_reward: 110718.79\n",
            "total_cost: 1501012.13\n",
            "total_trades: 9170\n",
            "Sharpe: 0.341\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 8500       |\n",
            "|    time_elapsed       | 136        |\n",
            "|    total_timesteps    | 42500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8499       |\n",
            "|    policy_loss        | 126        |\n",
            "|    reward             | -1.4605908 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 10.2       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 68\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1153279.47\n",
            "total_reward: 153279.47\n",
            "total_cost: 1555480.90\n",
            "total_trades: 9057\n",
            "Sharpe: 0.445\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 8600        |\n",
            "|    time_elapsed       | 138         |\n",
            "|    total_timesteps    | 43000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -43.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8599        |\n",
            "|    policy_loss        | -56.7       |\n",
            "|    reward             | -0.32026374 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 2.7         |\n",
            "---------------------------------------\n",
            "day: 628, episode: 69\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1132164.62\n",
            "total_reward: 132164.62\n",
            "total_cost: 1600056.52\n",
            "total_trades: 8894\n",
            "Sharpe: 0.390\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 8700       |\n",
            "|    time_elapsed       | 139        |\n",
            "|    total_timesteps    | 43500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.2      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8699       |\n",
            "|    policy_loss        | -19.8      |\n",
            "|    reward             | 0.22617333 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 1.23       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 311         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 141         |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -43.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | -34.1       |\n",
            "|    reward             | -0.93146056 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.863       |\n",
            "---------------------------------------\n",
            "day: 628, episode: 70\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1118971.37\n",
            "total_reward: 118971.37\n",
            "total_cost: 1502788.07\n",
            "total_trades: 8898\n",
            "Sharpe: 0.361\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 311        |\n",
            "|    iterations         | 8900       |\n",
            "|    time_elapsed       | 143        |\n",
            "|    total_timesteps    | 44500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8899       |\n",
            "|    policy_loss        | 50.1       |\n",
            "|    reward             | -1.3398306 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 1.96       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 71\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1115421.96\n",
            "total_reward: 115421.96\n",
            "total_cost: 1617813.13\n",
            "total_trades: 8827\n",
            "Sharpe: 0.352\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 311       |\n",
            "|    iterations         | 9000      |\n",
            "|    time_elapsed       | 144       |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -43.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8999      |\n",
            "|    policy_loss        | 75.3      |\n",
            "|    reward             | -1.104419 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 4.16      |\n",
            "-------------------------------------\n",
            "day: 628, episode: 72\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1154947.19\n",
            "total_reward: 154947.19\n",
            "total_cost: 1622414.91\n",
            "total_trades: 8598\n",
            "Sharpe: 0.435\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 309         |\n",
            "|    iterations         | 9100        |\n",
            "|    time_elapsed       | 147         |\n",
            "|    total_timesteps    | 45500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -43.3       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9099        |\n",
            "|    policy_loss        | -45.9       |\n",
            "|    reward             | -0.16870828 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 1.88        |\n",
            "---------------------------------------\n",
            "day: 628, episode: 73\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1110824.11\n",
            "total_reward: 110824.11\n",
            "total_cost: 1800052.98\n",
            "total_trades: 8704\n",
            "Sharpe: 0.342\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 9200       |\n",
            "|    time_elapsed       | 148        |\n",
            "|    total_timesteps    | 46000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9199       |\n",
            "|    policy_loss        | 3.96       |\n",
            "|    reward             | -0.1343653 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.217      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 9300       |\n",
            "|    time_elapsed       | 150        |\n",
            "|    total_timesteps    | 46500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9299       |\n",
            "|    policy_loss        | 29.1       |\n",
            "|    reward             | 0.43085387 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.458      |\n",
            "--------------------------------------\n",
            "day: 628, episode: 74\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1151624.25\n",
            "total_reward: 151624.25\n",
            "total_cost: 1636210.46\n",
            "total_trades: 9015\n",
            "Sharpe: 0.434\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 309       |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 152       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -43.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | -4.17     |\n",
            "|    reward             | 2.5443013 |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 0.649     |\n",
            "-------------------------------------\n",
            "day: 628, episode: 75\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1153085.42\n",
            "total_reward: 153085.42\n",
            "total_cost: 1685718.35\n",
            "total_trades: 9154\n",
            "Sharpe: 0.431\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 309      |\n",
            "|    iterations         | 9500     |\n",
            "|    time_elapsed       | 153      |\n",
            "|    total_timesteps    | 47500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -43.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9499     |\n",
            "|    policy_loss        | -51.2    |\n",
            "|    reward             | 2.089907 |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 1.49     |\n",
            "------------------------------------\n",
            "day: 628, episode: 76\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1138298.65\n",
            "total_reward: 138298.65\n",
            "total_cost: 1693011.79\n",
            "total_trades: 9059\n",
            "Sharpe: 0.402\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 155        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | 14.5       |\n",
            "|    reward             | -0.0229923 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.957      |\n",
            "--------------------------------------\n",
            "day: 628, episode: 77\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1143066.20\n",
            "total_reward: 143066.20\n",
            "total_cost: 1852631.86\n",
            "total_trades: 9194\n",
            "Sharpe: 0.410\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 156        |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.7      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | 41.5       |\n",
            "|    reward             | 0.06350097 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.909      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 9800       |\n",
            "|    time_elapsed       | 158        |\n",
            "|    total_timesteps    | 49000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.7      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9799       |\n",
            "|    policy_loss        | 68.1       |\n",
            "|    reward             | 0.92969143 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 2.07       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 78\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1124476.65\n",
            "total_reward: 124476.65\n",
            "total_cost: 1694220.12\n",
            "total_trades: 8765\n",
            "Sharpe: 0.371\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 9900       |\n",
            "|    time_elapsed       | 160        |\n",
            "|    total_timesteps    | 49500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.7      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9899       |\n",
            "|    policy_loss        | -98.2      |\n",
            "|    reward             | -1.0944754 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 5.57       |\n",
            "--------------------------------------\n",
            "day: 628, episode: 79\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1122992.09\n",
            "total_reward: 122992.09\n",
            "total_cost: 1513601.88\n",
            "total_trades: 8902\n",
            "Sharpe: 0.366\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 309        |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 161        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -43.8      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9999       |\n",
            "|    policy_loss        | 115        |\n",
            "|    reward             | 0.70701486 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 9.66       |\n",
            "--------------------------------------\n",
            "A2C Validation from 2023-07-06 to 2023-08-30\n",
            "day: 38, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1020292.25\n",
            "total_reward: 20292.25\n",
            "total_cost: 1528016.44\n",
            "total_trades: 589\n",
            "Sharpe: 1.487\n",
            "=================================\n",
            "DDPG Training: \n",
            "Using cuda device\n",
            "day: 628, episode: 81\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1209428.75\n",
            "total_reward: 209428.75\n",
            "total_cost: 10262402.67\n",
            "total_trades: 11902\n",
            "Sharpe: 0.601\n",
            "=================================\n",
            "day: 628, episode: 82\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 83\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 84\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 4           |\n",
            "|    fps             | 165         |\n",
            "|    time_elapsed    | 15          |\n",
            "|    total_timesteps | 2516        |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -13.9       |\n",
            "|    critic_loss     | 1.68e+03    |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 1887        |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 85\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 86\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 87\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 88\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 8           |\n",
            "|    fps             | 147         |\n",
            "|    time_elapsed    | 34          |\n",
            "|    total_timesteps | 5032        |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -14.4       |\n",
            "|    critic_loss     | 26.4        |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 4403        |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 89\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 90\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 91\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 92\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 12          |\n",
            "|    fps             | 141         |\n",
            "|    time_elapsed    | 53          |\n",
            "|    total_timesteps | 7548        |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -12.7       |\n",
            "|    critic_loss     | 0.206       |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 6919        |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 93\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 94\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 95\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 96\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 16          |\n",
            "|    fps             | 139         |\n",
            "|    time_elapsed    | 72          |\n",
            "|    total_timesteps | 10064       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -11.2       |\n",
            "|    critic_loss     | 9.39        |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 9435        |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 97\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 98\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 99\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 100\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 20          |\n",
            "|    fps             | 137         |\n",
            "|    time_elapsed    | 91          |\n",
            "|    total_timesteps | 12580       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -9.92       |\n",
            "|    critic_loss     | 0.106       |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 11951       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 101\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 102\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 103\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 104\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 24          |\n",
            "|    fps             | 136         |\n",
            "|    time_elapsed    | 110         |\n",
            "|    total_timesteps | 15096       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -8.67       |\n",
            "|    critic_loss     | 0.112       |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 14467       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 105\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 106\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 107\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 108\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 28          |\n",
            "|    fps             | 136         |\n",
            "|    time_elapsed    | 129         |\n",
            "|    total_timesteps | 17612       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -7.56       |\n",
            "|    critic_loss     | 0.165       |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 16983       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 109\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 110\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 111\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 112\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 32          |\n",
            "|    fps             | 135         |\n",
            "|    time_elapsed    | 148         |\n",
            "|    total_timesteps | 20128       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -6.33       |\n",
            "|    critic_loss     | 1.14        |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 19499       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 113\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 114\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 115\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 116\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 36          |\n",
            "|    fps             | 135         |\n",
            "|    time_elapsed    | 167         |\n",
            "|    total_timesteps | 22644       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -5.38       |\n",
            "|    critic_loss     | 0.201       |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 22015       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 117\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 118\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 119\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 120\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 40          |\n",
            "|    fps             | 134         |\n",
            "|    time_elapsed    | 186         |\n",
            "|    total_timesteps | 25160       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -4.89       |\n",
            "|    critic_loss     | 0.0509      |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 24531       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 121\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 122\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 123\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 124\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 44          |\n",
            "|    fps             | 134         |\n",
            "|    time_elapsed    | 205         |\n",
            "|    total_timesteps | 27676       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -4.28       |\n",
            "|    critic_loss     | 0.0582      |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 27047       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 125\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 126\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 127\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 128\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 48          |\n",
            "|    fps             | 134         |\n",
            "|    time_elapsed    | 224         |\n",
            "|    total_timesteps | 30192       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -3.74       |\n",
            "|    critic_loss     | 0.0468      |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 29563       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 129\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 130\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 131\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 132\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 52          |\n",
            "|    fps             | 134         |\n",
            "|    time_elapsed    | 243         |\n",
            "|    total_timesteps | 32708       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -3.3        |\n",
            "|    critic_loss     | 0.0346      |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 32079       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 133\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 134\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 135\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 136\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 56          |\n",
            "|    fps             | 133         |\n",
            "|    time_elapsed    | 263         |\n",
            "|    total_timesteps | 35224       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -2.74       |\n",
            "|    critic_loss     | 0.0645      |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 34595       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 137\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 138\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 139\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 140\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 60          |\n",
            "|    fps             | 133         |\n",
            "|    time_elapsed    | 282         |\n",
            "|    total_timesteps | 37740       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -2.45       |\n",
            "|    critic_loss     | 0.0358      |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 37111       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 141\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 142\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 143\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 144\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 64          |\n",
            "|    fps             | 133         |\n",
            "|    time_elapsed    | 301         |\n",
            "|    total_timesteps | 40256       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -2.16       |\n",
            "|    critic_loss     | 0.0379      |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 39627       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 145\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 146\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 147\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 148\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 68          |\n",
            "|    fps             | 133         |\n",
            "|    time_elapsed    | 319         |\n",
            "|    total_timesteps | 42772       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -1.94       |\n",
            "|    critic_loss     | 0.0229      |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 42143       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 149\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 150\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 151\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 152\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 72          |\n",
            "|    fps             | 133         |\n",
            "|    time_elapsed    | 339         |\n",
            "|    total_timesteps | 45288       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -1.77       |\n",
            "|    critic_loss     | 0.0415      |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 44659       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 153\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 154\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 155\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 156\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 76          |\n",
            "|    fps             | 133         |\n",
            "|    time_elapsed    | 357         |\n",
            "|    total_timesteps | 47804       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -1.52       |\n",
            "|    critic_loss     | 0.0276      |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 47175       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "day: 628, episode: 157\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 158\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 159\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "day: 628, episode: 160\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1134208.62\n",
            "total_reward: 134208.62\n",
            "total_cost: 1190111.71\n",
            "total_trades: 10687\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    episodes        | 80          |\n",
            "|    fps             | 133         |\n",
            "|    time_elapsed    | 377         |\n",
            "|    total_timesteps | 50320       |\n",
            "| train/             |             |\n",
            "|    actor_loss      | -1.4        |\n",
            "|    critic_loss     | 1.96        |\n",
            "|    learning_rate   | 0.001       |\n",
            "|    n_updates       | 49691       |\n",
            "|    reward          | -0.11328679 |\n",
            "------------------------------------\n",
            "DDPG Validation from 2023-07-06 to 2023-08-30\n",
            "day: 38, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1018608.51\n",
            "total_reward: 18608.51\n",
            "total_cost: 1157440.51\n",
            "total_trades: 654\n",
            "Sharpe: 1.227\n",
            "=================================\n",
            "PPO Training: \n",
            "Using cuda device\n",
            "day: 628, episode: 162\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1135975.49\n",
            "total_reward: 135975.49\n",
            "total_cost: 67828562.41\n",
            "total_trades: 16143\n",
            "Sharpe: 0.413\n",
            "=================================\n",
            "day: 628, episode: 163\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 888121.87\n",
            "total_reward: -111878.13\n",
            "total_cost: 67565202.36\n",
            "total_trades: 16209\n",
            "Sharpe: -0.198\n",
            "=================================\n",
            "day: 628, episode: 164\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1103181.66\n",
            "total_reward: 103181.66\n",
            "total_cost: 72426674.46\n",
            "total_trades: 16408\n",
            "Sharpe: 0.329\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 417        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 4          |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.13196293 |\n",
            "-----------------------------------\n",
            "day: 628, episode: 165\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1034685.29\n",
            "total_reward: 34685.29\n",
            "total_cost: 67913065.82\n",
            "total_trades: 16313\n",
            "Sharpe: 0.165\n",
            "=================================\n",
            "day: 628, episode: 166\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1079239.48\n",
            "total_reward: 79239.48\n",
            "total_cost: 69315777.18\n",
            "total_trades: 16275\n",
            "Sharpe: 0.266\n",
            "=================================\n",
            "day: 628, episode: 167\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 971760.62\n",
            "total_reward: -28239.38\n",
            "total_cost: 68729509.36\n",
            "total_trades: 16093\n",
            "Sharpe: 0.013\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 388         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015732586 |\n",
            "|    clip_fraction        | 0.189       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0225     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.02        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0391     |\n",
            "|    reward               | 1.3736845   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 6.48        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 168\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1038173.61\n",
            "total_reward: 38173.61\n",
            "total_cost: 67519024.21\n",
            "total_trades: 16240\n",
            "Sharpe: 0.174\n",
            "=================================\n",
            "day: 628, episode: 169\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1070875.20\n",
            "total_reward: 70875.20\n",
            "total_cost: 69573623.68\n",
            "total_trades: 16273\n",
            "Sharpe: 0.250\n",
            "=================================\n",
            "day: 628, episode: 170\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 960077.35\n",
            "total_reward: -39922.65\n",
            "total_cost: 69317807.86\n",
            "total_trades: 16336\n",
            "Sharpe: -0.022\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 379         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017551608 |\n",
            "|    clip_fraction        | 0.199       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.0506      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.7         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0373     |\n",
            "|    reward               | -0.16243401 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 6.87        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 171\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1237359.25\n",
            "total_reward: 237359.25\n",
            "total_cost: 70164831.77\n",
            "total_trades: 16524\n",
            "Sharpe: 0.643\n",
            "=================================\n",
            "day: 628, episode: 172\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1131469.67\n",
            "total_reward: 131469.67\n",
            "total_cost: 69147224.50\n",
            "total_trades: 16213\n",
            "Sharpe: 0.384\n",
            "=================================\n",
            "day: 628, episode: 173\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1094566.36\n",
            "total_reward: 94566.36\n",
            "total_cost: 69677421.43\n",
            "total_trades: 16323\n",
            "Sharpe: 0.302\n",
            "=================================\n",
            "day: 628, episode: 174\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1211709.99\n",
            "total_reward: 211709.99\n",
            "total_cost: 67961581.23\n",
            "total_trades: 16328\n",
            "Sharpe: 0.567\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 375         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016003769 |\n",
            "|    clip_fraction        | 0.193       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.0923      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.19        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0295     |\n",
            "|    reward               | -0.24899098 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 7.83        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 175\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1048551.68\n",
            "total_reward: 48551.68\n",
            "total_cost: 66591860.69\n",
            "total_trades: 16078\n",
            "Sharpe: 0.197\n",
            "=================================\n",
            "day: 628, episode: 176\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1131457.29\n",
            "total_reward: 131457.29\n",
            "total_cost: 66506619.55\n",
            "total_trades: 16071\n",
            "Sharpe: 0.401\n",
            "=================================\n",
            "day: 628, episode: 177\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 901661.93\n",
            "total_reward: -98338.07\n",
            "total_cost: 68203433.02\n",
            "total_trades: 16078\n",
            "Sharpe: -0.162\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 373         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 27          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021435622 |\n",
            "|    clip_fraction        | 0.202       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.078       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.64        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.027      |\n",
            "|    reward               | 1.0976428   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.19        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 178\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1208160.18\n",
            "total_reward: 208160.18\n",
            "total_cost: 70184359.96\n",
            "total_trades: 16293\n",
            "Sharpe: 0.554\n",
            "=================================\n",
            "day: 628, episode: 179\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1140776.78\n",
            "total_reward: 140776.78\n",
            "total_cost: 67742591.99\n",
            "total_trades: 16216\n",
            "Sharpe: 0.414\n",
            "=================================\n",
            "day: 628, episode: 180\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1049069.79\n",
            "total_reward: 49069.79\n",
            "total_cost: 69815917.15\n",
            "total_trades: 16178\n",
            "Sharpe: 0.200\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 372         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023022324 |\n",
            "|    clip_fraction        | 0.284       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | 0.107       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.79        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.034      |\n",
            "|    reward               | -2.926083   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 5.41        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 181\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 995187.97\n",
            "total_reward: -4812.03\n",
            "total_cost: 67984491.93\n",
            "total_trades: 16245\n",
            "Sharpe: 0.070\n",
            "=================================\n",
            "day: 628, episode: 182\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1068691.36\n",
            "total_reward: 68691.36\n",
            "total_cost: 67291437.55\n",
            "total_trades: 16133\n",
            "Sharpe: 0.243\n",
            "=================================\n",
            "day: 628, episode: 183\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1089120.69\n",
            "total_reward: 89120.69\n",
            "total_cost: 66462467.34\n",
            "total_trades: 15977\n",
            "Sharpe: 0.290\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022298845 |\n",
            "|    clip_fraction        | 0.239       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | 0.154       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.69        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0305     |\n",
            "|    reward               | 0.23107493  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.03        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 184\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 969545.62\n",
            "total_reward: -30454.38\n",
            "total_cost: 65528816.52\n",
            "total_trades: 15969\n",
            "Sharpe: 0.012\n",
            "=================================\n",
            "day: 628, episode: 185\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1059637.11\n",
            "total_reward: 59637.11\n",
            "total_cost: 67471006.78\n",
            "total_trades: 16111\n",
            "Sharpe: 0.224\n",
            "=================================\n",
            "day: 628, episode: 186\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1084052.62\n",
            "total_reward: 84052.62\n",
            "total_cost: 65521899.53\n",
            "total_trades: 16056\n",
            "Sharpe: 0.272\n",
            "=================================\n",
            "day: 628, episode: 187\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1262199.25\n",
            "total_reward: 262199.25\n",
            "total_cost: 67404851.49\n",
            "total_trades: 16193\n",
            "Sharpe: 0.632\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 370        |\n",
            "|    iterations           | 8          |\n",
            "|    time_elapsed         | 44         |\n",
            "|    total_timesteps      | 16384      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02840382 |\n",
            "|    clip_fraction        | 0.283      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.4      |\n",
            "|    explained_variance   | 0.183      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 2.21       |\n",
            "|    n_updates            | 70         |\n",
            "|    policy_gradient_loss | -0.0248    |\n",
            "|    reward               | 0.58460295 |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 5.32       |\n",
            "----------------------------------------\n",
            "day: 628, episode: 188\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1160645.66\n",
            "total_reward: 160645.66\n",
            "total_cost: 65385213.97\n",
            "total_trades: 15921\n",
            "Sharpe: 0.438\n",
            "=================================\n",
            "day: 628, episode: 189\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 998504.37\n",
            "total_reward: -1495.63\n",
            "total_cost: 65851517.43\n",
            "total_trades: 16036\n",
            "Sharpe: 0.081\n",
            "=================================\n",
            "day: 628, episode: 190\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 972014.81\n",
            "total_reward: -27985.19\n",
            "total_cost: 64828093.43\n",
            "total_trades: 16008\n",
            "Sharpe: 0.017\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 369         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 49          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024316411 |\n",
            "|    clip_fraction        | 0.228       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.5       |\n",
            "|    explained_variance   | 0.206       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.7         |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0229     |\n",
            "|    reward               | 0.023974285 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6           |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 191\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1037499.06\n",
            "total_reward: 37499.06\n",
            "total_cost: 64135256.62\n",
            "total_trades: 16037\n",
            "Sharpe: 0.172\n",
            "=================================\n",
            "day: 628, episode: 192\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1047949.02\n",
            "total_reward: 47949.02\n",
            "total_cost: 62617030.99\n",
            "total_trades: 15842\n",
            "Sharpe: 0.197\n",
            "=================================\n",
            "day: 628, episode: 193\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1015010.32\n",
            "total_reward: 15010.32\n",
            "total_cost: 65311248.12\n",
            "total_trades: 16062\n",
            "Sharpe: 0.119\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 368        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 55         |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02501509 |\n",
            "|    clip_fraction        | 0.281      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.5      |\n",
            "|    explained_variance   | 0.248      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 1.22       |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.0226    |\n",
            "|    reward               | 2.0205717  |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 5.22       |\n",
            "----------------------------------------\n",
            "day: 628, episode: 194\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 998918.06\n",
            "total_reward: -1081.94\n",
            "total_cost: 62923364.81\n",
            "total_trades: 15988\n",
            "Sharpe: 0.089\n",
            "=================================\n",
            "day: 628, episode: 195\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1053520.60\n",
            "total_reward: 53520.60\n",
            "total_cost: 66345142.01\n",
            "total_trades: 16202\n",
            "Sharpe: 0.210\n",
            "=================================\n",
            "day: 628, episode: 196\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1045037.18\n",
            "total_reward: 45037.18\n",
            "total_cost: 65089271.80\n",
            "total_trades: 16036\n",
            "Sharpe: 0.189\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 361         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027181689 |\n",
            "|    clip_fraction        | 0.277       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.5       |\n",
            "|    explained_variance   | 0.17        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.73        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0251     |\n",
            "|    reward               | -2.0847874  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 4.99        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 197\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1040206.52\n",
            "total_reward: 40206.52\n",
            "total_cost: 66711526.68\n",
            "total_trades: 16166\n",
            "Sharpe: 0.178\n",
            "=================================\n",
            "day: 628, episode: 198\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1056950.79\n",
            "total_reward: 56950.79\n",
            "total_cost: 66806492.53\n",
            "total_trades: 16200\n",
            "Sharpe: 0.220\n",
            "=================================\n",
            "day: 628, episode: 199\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 901063.09\n",
            "total_reward: -98936.91\n",
            "total_cost: 62464474.31\n",
            "total_trades: 15804\n",
            "Sharpe: -0.165\n",
            "=================================\n",
            "day: 628, episode: 200\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1097946.66\n",
            "total_reward: 97946.66\n",
            "total_cost: 65722799.93\n",
            "total_trades: 16217\n",
            "Sharpe: 0.308\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 362         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 67          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023272127 |\n",
            "|    clip_fraction        | 0.294       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.5       |\n",
            "|    explained_variance   | 0.187       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.81        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0193     |\n",
            "|    reward               | 0.7586934   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.23        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 201\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1135100.02\n",
            "total_reward: 135100.02\n",
            "total_cost: 59177868.02\n",
            "total_trades: 15611\n",
            "Sharpe: 0.393\n",
            "=================================\n",
            "day: 628, episode: 202\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1139503.90\n",
            "total_reward: 139503.90\n",
            "total_cost: 62226842.54\n",
            "total_trades: 15943\n",
            "Sharpe: 0.396\n",
            "=================================\n",
            "day: 628, episode: 203\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1120102.82\n",
            "total_reward: 120102.82\n",
            "total_cost: 62999187.75\n",
            "total_trades: 15945\n",
            "Sharpe: 0.351\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 362         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 73          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028833533 |\n",
            "|    clip_fraction        | 0.323       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.6       |\n",
            "|    explained_variance   | 0.185       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.66        |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0235     |\n",
            "|    reward               | -1.1999491  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 4.42        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 204\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1088013.63\n",
            "total_reward: 88013.63\n",
            "total_cost: 61979549.95\n",
            "total_trades: 15824\n",
            "Sharpe: 0.281\n",
            "=================================\n",
            "day: 628, episode: 205\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1261157.09\n",
            "total_reward: 261157.09\n",
            "total_cost: 65746481.14\n",
            "total_trades: 16092\n",
            "Sharpe: 0.645\n",
            "=================================\n",
            "day: 628, episode: 206\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1098844.09\n",
            "total_reward: 98844.09\n",
            "total_cost: 60875080.19\n",
            "total_trades: 15752\n",
            "Sharpe: 0.304\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 362        |\n",
            "|    iterations           | 14         |\n",
            "|    time_elapsed         | 79         |\n",
            "|    total_timesteps      | 28672      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.033034   |\n",
            "|    clip_fraction        | 0.34       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.7      |\n",
            "|    explained_variance   | 0.154      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 2.48       |\n",
            "|    n_updates            | 130        |\n",
            "|    policy_gradient_loss | -0.0194    |\n",
            "|    reward               | -0.4320852 |\n",
            "|    std                  | 1.02       |\n",
            "|    value_loss           | 5.54       |\n",
            "----------------------------------------\n",
            "day: 628, episode: 207\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 979471.61\n",
            "total_reward: -20528.39\n",
            "total_cost: 59543287.22\n",
            "total_trades: 15655\n",
            "Sharpe: 0.036\n",
            "=================================\n",
            "day: 628, episode: 208\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1186913.05\n",
            "total_reward: 186913.05\n",
            "total_cost: 61106647.50\n",
            "total_trades: 15709\n",
            "Sharpe: 0.491\n",
            "=================================\n",
            "day: 628, episode: 209\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1172418.60\n",
            "total_reward: 172418.60\n",
            "total_cost: 59942007.34\n",
            "total_trades: 15521\n",
            "Sharpe: 0.456\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 363         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027954182 |\n",
            "|    clip_fraction        | 0.311       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.7       |\n",
            "|    explained_variance   | 0.234       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.1         |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0233     |\n",
            "|    reward               | -0.482361   |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 5.46        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 210\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1264212.92\n",
            "total_reward: 264212.92\n",
            "total_cost: 61205484.15\n",
            "total_trades: 15893\n",
            "Sharpe: 0.649\n",
            "=================================\n",
            "day: 628, episode: 211\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1093876.41\n",
            "total_reward: 93876.41\n",
            "total_cost: 60521660.00\n",
            "total_trades: 15761\n",
            "Sharpe: 0.290\n",
            "=================================\n",
            "day: 628, episode: 212\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 876812.61\n",
            "total_reward: -123187.39\n",
            "total_cost: 59049765.34\n",
            "total_trades: 15676\n",
            "Sharpe: -0.203\n",
            "=================================\n",
            "day: 628, episode: 213\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1198182.42\n",
            "total_reward: 198182.42\n",
            "total_cost: 50716136.84\n",
            "total_trades: 14827\n",
            "Sharpe: 0.497\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 363         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.03203973  |\n",
            "|    clip_fraction        | 0.357       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.7       |\n",
            "|    explained_variance   | 0.302       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.6         |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0226     |\n",
            "|    reward               | -0.47798592 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 4.9         |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 214\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1142018.26\n",
            "total_reward: 142018.26\n",
            "total_cost: 50207452.05\n",
            "total_trades: 14948\n",
            "Sharpe: 0.362\n",
            "=================================\n",
            "day: 628, episode: 215\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1153022.87\n",
            "total_reward: 153022.87\n",
            "total_cost: 53649678.38\n",
            "total_trades: 15310\n",
            "Sharpe: 0.371\n",
            "=================================\n",
            "day: 628, episode: 216\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1067716.60\n",
            "total_reward: 67716.60\n",
            "total_cost: 57873394.49\n",
            "total_trades: 15535\n",
            "Sharpe: 0.237\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 363         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 95          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028014608 |\n",
            "|    clip_fraction        | 0.3         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.8       |\n",
            "|    explained_variance   | 0.357       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.12        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0184     |\n",
            "|    reward               | -0.53270084 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 4.89        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 217\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1098028.85\n",
            "total_reward: 98028.85\n",
            "total_cost: 51326874.64\n",
            "total_trades: 15124\n",
            "Sharpe: 0.279\n",
            "=================================\n",
            "day: 628, episode: 218\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1086145.46\n",
            "total_reward: 86145.46\n",
            "total_cost: 47591375.96\n",
            "total_trades: 14823\n",
            "Sharpe: 0.261\n",
            "=================================\n",
            "day: 628, episode: 219\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1228281.97\n",
            "total_reward: 228281.97\n",
            "total_cost: 52418272.79\n",
            "total_trades: 15061\n",
            "Sharpe: 0.537\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 101         |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021093782 |\n",
            "|    clip_fraction        | 0.282       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.8       |\n",
            "|    explained_variance   | 0.134       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.57        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    reward               | -0.76195544 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 7.51        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 220\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1105675.18\n",
            "total_reward: 105675.18\n",
            "total_cost: 52431722.05\n",
            "total_trades: 14986\n",
            "Sharpe: 0.297\n",
            "=================================\n",
            "day: 628, episode: 221\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1071708.49\n",
            "total_reward: 71708.49\n",
            "total_cost: 56749996.24\n",
            "total_trades: 15295\n",
            "Sharpe: 0.246\n",
            "=================================\n",
            "day: 628, episode: 222\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1129212.27\n",
            "total_reward: 129212.27\n",
            "total_cost: 47761934.00\n",
            "total_trades: 14594\n",
            "Sharpe: 0.333\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020509198 |\n",
            "|    clip_fraction        | 0.238       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.8       |\n",
            "|    explained_variance   | 0.148       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.25        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0147     |\n",
            "|    reward               | 0.2367248   |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 9.9         |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 223\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1317009.92\n",
            "total_reward: 317009.92\n",
            "total_cost: 54880817.30\n",
            "total_trades: 15156\n",
            "Sharpe: 0.719\n",
            "=================================\n",
            "day: 628, episode: 224\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1318988.70\n",
            "total_reward: 318988.70\n",
            "total_cost: 50975360.86\n",
            "total_trades: 14879\n",
            "Sharpe: 0.692\n",
            "=================================\n",
            "day: 628, episode: 225\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1139524.09\n",
            "total_reward: 139524.09\n",
            "total_cost: 53796152.58\n",
            "total_trades: 15150\n",
            "Sharpe: 0.379\n",
            "=================================\n",
            "day: 628, episode: 226\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1223494.26\n",
            "total_reward: 223494.26\n",
            "total_cost: 43927358.66\n",
            "total_trades: 14429\n",
            "Sharpe: 0.462\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 112         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024321351 |\n",
            "|    clip_fraction        | 0.264       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.8       |\n",
            "|    explained_variance   | 0.344       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.61        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0223     |\n",
            "|    reward               | -0.6748862  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 7.35        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 227\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1128520.09\n",
            "total_reward: 128520.09\n",
            "total_cost: 47019991.52\n",
            "total_trades: 14613\n",
            "Sharpe: 0.328\n",
            "=================================\n",
            "day: 628, episode: 228\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1177390.65\n",
            "total_reward: 177390.65\n",
            "total_cost: 46763613.63\n",
            "total_trades: 14443\n",
            "Sharpe: 0.417\n",
            "=================================\n",
            "day: 628, episode: 229\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1157147.42\n",
            "total_reward: 157147.42\n",
            "total_cost: 41602309.66\n",
            "total_trades: 14030\n",
            "Sharpe: 0.374\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 117         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021326736 |\n",
            "|    clip_fraction        | 0.254       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.9       |\n",
            "|    explained_variance   | 0.305       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.03        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.0193     |\n",
            "|    reward               | -0.18907186 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 8.28        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 230\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1154423.28\n",
            "total_reward: 154423.28\n",
            "total_cost: 43386018.62\n",
            "total_trades: 14199\n",
            "Sharpe: 0.365\n",
            "=================================\n",
            "day: 628, episode: 231\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1159800.47\n",
            "total_reward: 159800.47\n",
            "total_cost: 51464176.31\n",
            "total_trades: 14885\n",
            "Sharpe: 0.388\n",
            "=================================\n",
            "day: 628, episode: 232\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1076741.43\n",
            "total_reward: 76741.43\n",
            "total_cost: 41162108.12\n",
            "total_trades: 14004\n",
            "Sharpe: 0.244\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 123         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015885651 |\n",
            "|    clip_fraction        | 0.168       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42         |\n",
            "|    explained_variance   | 0.313       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.42        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0172     |\n",
            "|    reward               | -1.4193112  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 8.72        |\n",
            "-----------------------------------------\n",
            "day: 628, episode: 233\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1076059.12\n",
            "total_reward: 76059.12\n",
            "total_cost: 50247715.01\n",
            "total_trades: 14783\n",
            "Sharpe: 0.245\n",
            "=================================\n",
            "day: 628, episode: 234\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1222675.55\n",
            "total_reward: 222675.55\n",
            "total_cost: 54060022.39\n",
            "total_trades: 15265\n",
            "Sharpe: 0.516\n",
            "=================================\n",
            "day: 628, episode: 235\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1202880.82\n",
            "total_reward: 202880.82\n",
            "total_cost: 45197378.91\n",
            "total_trades: 14446\n",
            "Sharpe: 0.500\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 365        |\n",
            "|    iterations           | 23         |\n",
            "|    time_elapsed         | 128        |\n",
            "|    total_timesteps      | 47104      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02042504 |\n",
            "|    clip_fraction        | 0.181      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -42        |\n",
            "|    explained_variance   | 0.352      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 3.67       |\n",
            "|    n_updates            | 220        |\n",
            "|    policy_gradient_loss | -0.0127    |\n",
            "|    reward               | 0.08456657 |\n",
            "|    std                  | 1.03       |\n",
            "|    value_loss           | 9.39       |\n",
            "----------------------------------------\n",
            "day: 628, episode: 236\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1101189.06\n",
            "total_reward: 101189.06\n",
            "total_cost: 45622445.65\n",
            "total_trades: 14480\n",
            "Sharpe: 0.286\n",
            "=================================\n",
            "day: 628, episode: 237\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1166372.71\n",
            "total_reward: 166372.71\n",
            "total_cost: 39481883.12\n",
            "total_trades: 13897\n",
            "Sharpe: 0.388\n",
            "=================================\n",
            "day: 628, episode: 238\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1307239.69\n",
            "total_reward: 307239.69\n",
            "total_cost: 54479569.75\n",
            "total_trades: 14970\n",
            "Sharpe: 0.671\n",
            "=================================\n",
            "day: 628, episode: 239\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1178702.34\n",
            "total_reward: 178702.34\n",
            "total_cost: 50034085.04\n",
            "total_trades: 14785\n",
            "Sharpe: 0.424\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 365        |\n",
            "|    iterations           | 24         |\n",
            "|    time_elapsed         | 134        |\n",
            "|    total_timesteps      | 49152      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02183829 |\n",
            "|    clip_fraction        | 0.221      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -42        |\n",
            "|    explained_variance   | 0.413      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 2.7        |\n",
            "|    n_updates            | 230        |\n",
            "|    policy_gradient_loss | -0.0155    |\n",
            "|    reward               | 1.1660192  |\n",
            "|    std                  | 1.03       |\n",
            "|    value_loss           | 6.48       |\n",
            "----------------------------------------\n",
            "day: 628, episode: 240\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1224568.76\n",
            "total_reward: 224568.76\n",
            "total_cost: 45481881.14\n",
            "total_trades: 14545\n",
            "Sharpe: 0.462\n",
            "=================================\n",
            "day: 628, episode: 241\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1152408.42\n",
            "total_reward: 152408.42\n",
            "total_cost: 39841979.94\n",
            "total_trades: 13810\n",
            "Sharpe: 0.358\n",
            "=================================\n",
            "day: 628, episode: 242\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1091262.36\n",
            "total_reward: 91262.36\n",
            "total_cost: 46740792.10\n",
            "total_trades: 14636\n",
            "Sharpe: 0.272\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 139         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021352222 |\n",
            "|    clip_fraction        | 0.208       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -42.1       |\n",
            "|    explained_variance   | 0.424       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.26        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0174     |\n",
            "|    reward               | -0.36303535 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 8.34        |\n",
            "-----------------------------------------\n",
            "PPO Validation from 2023-07-06 to 2023-08-30\n",
            "day: 38, episode: 1\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1011374.11\n",
            "total_reward: 11374.11\n",
            "total_cost: 5171368.03\n",
            "total_trades: 970\n",
            "Sharpe: 0.898\n",
            "=================================\n",
            "Ensemble Model Training: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "UVrc6_3lpBgC",
        "outputId": "777d80c1-002c-4669-9244-56f605bec205"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   iteration  Start Date    End Date model_order  a2c_sharpe  ddpg_sharpe  \\\n",
              "0        126  2023-01-03  2023-04-04         a2c    0.078500    -0.002748   \n",
              "1        189  2023-04-04  2023-07-06         a2c    0.208445     0.203326   \n",
              "2        252  2023-07-06  2023-08-30         a2c    0.187309     0.154612   \n",
              "\n",
              "   ppo_sharpe  \n",
              "0    0.053433  \n",
              "1    0.084563  \n",
              "2    0.113118  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53bbb685-083c-4da3-9e59-1d85979b477a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iteration</th>\n",
              "      <th>Start Date</th>\n",
              "      <th>End Date</th>\n",
              "      <th>model_order</th>\n",
              "      <th>a2c_sharpe</th>\n",
              "      <th>ddpg_sharpe</th>\n",
              "      <th>ppo_sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126</td>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>2023-04-04</td>\n",
              "      <td>a2c</td>\n",
              "      <td>0.078500</td>\n",
              "      <td>-0.002748</td>\n",
              "      <td>0.053433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>189</td>\n",
              "      <td>2023-04-04</td>\n",
              "      <td>2023-07-06</td>\n",
              "      <td>a2c</td>\n",
              "      <td>0.208445</td>\n",
              "      <td>0.203326</td>\n",
              "      <td>0.084563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>252</td>\n",
              "      <td>2023-07-06</td>\n",
              "      <td>2023-08-30</td>\n",
              "      <td>a2c</td>\n",
              "      <td>0.187309</td>\n",
              "      <td>0.154612</td>\n",
              "      <td>0.113118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53bbb685-083c-4da3-9e59-1d85979b477a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53bbb685-083c-4da3-9e59-1d85979b477a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53bbb685-083c-4da3-9e59-1d85979b477a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88831887-0417-446b-8e48-93c9aaa5b5c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88831887-0417-446b-8e48-93c9aaa5b5c2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88831887-0417-446b-8e48-93c9aaa5b5c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8d5a735e-4ead-49bd-8823-d6fa01f6aa47\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8d5a735e-4ead-49bd-8823-d6fa01f6aa47 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}